{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8995eeac-c4f2-412a-85ff-118fe0977139",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/envs/autoLiRPA/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx2pytorch import ConvertModel\n",
    "from auto_LiRPA import BoundedModule, BoundedTensor, PerturbationLpNorm\n",
    "\n",
    "from vnnlib.compat import read_vnnlib_simple\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import csv\n",
    "\n",
    "import os\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8aeb1a-ec64-4099-9e22-4d2d4484688b",
   "metadata": {},
   "source": [
    "# Loading ONNX and VNNLib Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c1a82ed-410e-45bb-8309-390af59f692c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_onnx_model(onnx_path, input_shape):\n",
    "    onnx_model = onnx.load(onnx_path)\n",
    "    torch_model = ConvertModel(onnx_model)\n",
    "    \n",
    "    x_concrete = torch.zeros(input_shape)\n",
    "    model = BoundedModule(torch_model, x_concrete)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f98348bc-a6ca-41a1-8491-41dfbc1759d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_vnnlib_spec(vnnlib_path, input_shape, n_out):\n",
    "    n_in = np.prod(input_shape)\n",
    "    res = read_vnnlib_simple(vnnlib_path, n_in, n_out)\n",
    "    bnds, spec = res[0]\n",
    "    \n",
    "    bnds = np.array(bnds)\n",
    "    lbs = bnds[:,0]\n",
    "    ubs = bnds[:,1]\n",
    "    \n",
    "    data_min = torch.tensor(lbs, dtype=torch.float32).reshape(input_shape)\n",
    "    data_max = torch.tensor(ubs, dtype=torch.float32).reshape(input_shape)\n",
    "    center = 0.5*(data_min + data_max)\n",
    "\n",
    "    ptb = PerturbationLpNorm(x_L=data_min, x_U=data_max)\n",
    "    x = BoundedTensor(center, ptb)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "764a36c2-3378-4bfb-a997-7b5cc1e96903",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "onnx_path = 'example_specs/mnist-net_256x4.onnx'\n",
    "vnnlib_path = 'example_specs/prop_0_spiral_25.vnnlib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fab04bf-c040-4b7e-ab18-93d7414134fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/anaconda3/envs/autoLiRPA/lib/python3.10/site-packages/onnx2pytorch/convert/layer.py:29: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1654951016690/work/torch/csrc/utils/tensor_numpy.cpp:172.)\n",
      "  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n",
      "/home/philipp/anaconda3/envs/autoLiRPA/lib/python3.10/site-packages/onnx2pytorch/convert/model.py:167: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not self.experimental and inputs[0].shape[self.batch_dim] > 1:\n"
     ]
    }
   ],
   "source": [
    "model = load_onnx_model(onnx_path, [1,1,1,784])\n",
    "x = load_vnnlib_spec(vnnlib_path, [1,1,1,784], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ab3486-51a1-48ce-aa12-d8937dc4da0d",
   "metadata": {},
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ae127f-1b84-42e2-954e-d65dcffde529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_layers(model):\n",
    "    return [l for l in model.nodes() if l.perturbed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cd1e80e-10db-4e9b-9c23-394d829d580e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_intermediate_bounds(model):\n",
    "    \"\"\"\n",
    "    Returns a dictionary containing the concrete lower and upper bounds of each layer.\n",
    "    \n",
    "    Implemented own method to filter out bounds for weight matrices.\n",
    "    \n",
    "    Only call this method after compute_bounds()!\n",
    "    \"\"\"\n",
    "    od = OrderedDict()\n",
    "    for l in get_layers(model):\n",
    "        if hasattr(l, 'lower'):\n",
    "            od[l.name] = (l.lower, l.upper)\n",
    "            \n",
    "    return od"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f560f8c-df6b-4ac1-833c-834e07349be7",
   "metadata": {},
   "source": [
    "# Get Intermediate Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d908f042-6132-4fac-92cc-d9c01e158c20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-447.2314, -373.2225, -492.4267, -520.7729, -479.3799, -425.8518,\n",
       "          -413.6321, -447.6174, -532.3359, -408.0772]], grad_fn=<AddBackward0>),\n",
       " tensor([[356.4533, 318.0782, 320.3526, 274.7251, 371.1610, 338.5822, 395.8803,\n",
       "          377.8232, 375.9247, 400.2977]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_bounds(x=(x,), method='ibp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5fb62c8-e2d4-46bd-9304-161aac9aebde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/0: torch.Size([1, 1, 1, 784])\n",
      "/21: torch.Size([1, 784])\n",
      "/input: torch.Size([1, 256])\n",
      "/23: torch.Size([1, 256])\n",
      "/input.3: torch.Size([1, 256])\n",
      "/25: torch.Size([1, 256])\n",
      "/input.7: torch.Size([1, 256])\n",
      "/27: torch.Size([1, 256])\n",
      "/input.11: torch.Size([1, 256])\n",
      "/29: torch.Size([1, 256])\n",
      "/30: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "bounds_dict = get_intermediate_bounds(model)\n",
    "for k, (lbs, ubs) in bounds_dict.items():\n",
    "    print(f\"{k}: {lbs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23b50fbc-87e5-4727-bff6-59fe510773ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-447.2314, -373.2225, -492.4267, -520.7729, -479.3799, -425.8518,\n",
       "          -413.6321, -447.6174, -532.3359, -408.0772]], grad_fn=<AddBackward0>),\n",
       " tensor([[356.4533, 318.0782, 320.3526, 274.7251, 371.1610, 338.5822, 395.8803,\n",
       "          377.8232, 375.9247, 400.2977]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds_dict['/30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "708a54d3-a379-4d9f-b1fa-29d0600d15d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4672, -0.4103, -0.4026, -0.3573, -0.4667, -0.4770, -0.3886, -0.4031,\n",
       "          -0.5523, -0.4308]], grad_fn=<ViewBackward0>),\n",
       " tensor([[0.6201, 0.4692, 0.6307, 0.4833, 1.8194, 0.5396, 0.9479, 0.4172, 0.6483,\n",
       "          0.6467]], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_bounds(x=(x,), method='crown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "873f7e73-c1a6-4067-8511-bb7240ae6c83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-447.2314, -373.2225, -492.4267, -520.7729, -479.3799, -425.8518,\n",
       "          -413.6321, -447.6174, -532.3359, -408.0772]], grad_fn=<AddBackward0>),\n",
       " tensor([[356.4533, 318.0782, 320.3526, 274.7251, 371.1610, 338.5822, 395.8803,\n",
       "          377.8232, 375.9247, 400.2977]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds_dict['/30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80db1299-3f22-4b4e-aa48-92b2b4f33099",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4672, -0.4103, -0.4026, -0.3573, -0.4667, -0.4770, -0.3886, -0.4031,\n",
       "          -0.5523, -0.4308]], grad_fn=<ViewBackward0>),\n",
       " tensor([[0.6201, 0.4692, 0.6307, 0.4833, 1.8194, 0.5396, 0.9479, 0.4172, 0.6483,\n",
       "          0.6467]], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds_dict_crown = get_intermediate_bounds(model)\n",
    "bounds_dict_crown['/30']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baad5ac4-ea3b-4026-8026-cfb42669717b",
   "metadata": {},
   "source": [
    "**Attention**: CROWN-bounds are only saved for pre-activation nodes and the output!\n",
    "(in contrast to interval propagation bounds, that are saved for every layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df9b80ac-d1f4-42e3-b524-f029468805e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['/0', '/input', '/input.3', '/input.7', '/input.11', '/30'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds_dict_crown.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fdd5318-b352-42f2-b5f6-d423faa1063f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-171.4623, -160.4540, -304.7760, -128.2996, -153.7493, -117.9111,\n",
      "         -123.5061, -278.8083, -158.6687, -207.4034]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[-1.8260, -3.1913, -2.1607, -2.8250, -4.0157, -2.1657, -0.7982, -1.6259,\n",
      "         -1.0763, -5.0089]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lbs11_ibp, ubs11_ibp = bounds_dict['/input.11']\n",
    "lbs11_crown, ubs11_crown = bounds_dict_crown['/input.11']\n",
    "\n",
    "print(lbs11_ibp[:,:10])\n",
    "print(lbs11_crown[:,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd89d77-3247-41b2-9750-761c8db65dd4",
   "metadata": {},
   "source": [
    "# Sampling via CROWN\n",
    "\n",
    "In order to use CROWN to calculate bounds for the sampled directions, we make use of the possibility to supply\n",
    "- a constraint matrix (which we use to represent the sampled directions) and\n",
    "- to specify the output layer (which we just set to the layer, for which we want to sample)\n",
    "\n",
    "The shape of the constraint matrix is `(batch, n_directions, n_neurons)`, where we just set `batch=1`.\n",
    "\n",
    "The output layer is specified via the node names in the node dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26b77cc7-aef4-4b38-aa22-f1fefa101b86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ -3.5966,   3.4826,   0.1199,  -2.3320, -73.6734]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([[ 13.9218, 105.1290,  19.2300,  36.2667,   3.3111]],\n",
       "        grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batch = 1\n",
    "n_dirs = 5\n",
    "n_neurons = 256\n",
    "C = torch.randn(n_batch, n_dirs, n_neurons)\n",
    "\n",
    "model.compute_bounds(x=(x,), final_node_name='/input.11', C=C, method='crown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e104ab9-2483-4d38-a689-d9e30bd0e89a",
   "metadata": {},
   "source": [
    "We can also use $\\alpha$-CROWN to optimize the bounds of the directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00566dcc-eb57-447a-9eef-5872290cc4da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ -2.8655,  18.5538,   0.2205,   5.4271, -68.6798]]),\n",
       " tensor([[ 4.0163, 98.9213,  7.0998, 34.7713, -8.0158]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_bounds(x=(x,), final_node_name='/input.11', C=C, method='alpha-crown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cec03c-35cd-4ac8-a910-d84bb8c17d80",
   "metadata": {},
   "source": [
    "When using more iterations, the bounds may get slightly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51f598e9-f0f3-4bb0-827a-673e37122841",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_mode': 'patches',\n",
       " 'sparse_intermediate_bounds': True,\n",
       " 'sparse_conv_intermediate_bounds': True,\n",
       " 'sparse_intermediate_bounds_with_ibp': True,\n",
       " 'sparse_features_alpha': True,\n",
       " 'sparse_spec_alpha': True,\n",
       " 'minimum_sparsity': 0.9,\n",
       " 'enable_opt_interm_bounds': False,\n",
       " 'crown_batch_size': inf,\n",
       " 'forward_refinement': False,\n",
       " 'dynamic_forward': False,\n",
       " 'forward_max_dim': 1000000000,\n",
       " 'use_full_conv_alpha': True,\n",
       " 'disabled_optimization': [],\n",
       " 'use_full_conv_alpha_thresh': 512,\n",
       " 'verbosity': 0,\n",
       " 'optimize_graph': {'optimizer': None},\n",
       " 'optimize_bound_args': {'enable_alpha_crown': True,\n",
       "  'enable_beta_crown': False,\n",
       "  'apply_output_constraints_to': None,\n",
       "  'iteration': 20,\n",
       "  'use_shared_alpha': False,\n",
       "  'optimizer': 'adam',\n",
       "  'keep_best': True,\n",
       "  'fix_interm_bounds': True,\n",
       "  'lr_alpha': 0.5,\n",
       "  'lr_beta': 0.05,\n",
       "  'lr_cut_beta': 0.005,\n",
       "  'init_alpha': True,\n",
       "  'lr_coeffs': 0.01,\n",
       "  'intermediate_refinement_layers': [-1],\n",
       "  'loss_reduction_func': <function auto_LiRPA.utils.<lambda>(x)>,\n",
       "  'stop_criterion_func': <function auto_LiRPA.optimized_bounds.<lambda>(x)>,\n",
       "  'lr_decay': 0.98,\n",
       "  'early_stop_patience': 10,\n",
       "  'start_save_best': 0.5,\n",
       "  'use_float64_in_last_iteration': False,\n",
       "  'pruning_in_iteration': False,\n",
       "  'pruning_in_iteration_threshold': 0.2,\n",
       "  'multi_spec_keep_func': <function auto_LiRPA.utils.multi_spec_keep_func_all(x)>,\n",
       "  'deterministic': False},\n",
       " 'final_shape': torch.Size([1, 5])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bound_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47d2abd9-95e9-4786-9678-35ae926a1968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_params(model, use_shared_alpha=False, iteration=20, early_stop_patience=10):\n",
    "    model.bound_opts['optimize_bound_args']['use_shared_alpha'] = use_shared_alpha\n",
    "    model.bound_opts['optimize_bound_args']['iteration'] = iteration\n",
    "    model.bound_opts['optimize_bound_args']['early_stop_patience'] = early_stop_patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d1d6c7a-74d1-4990-8407-e07237a8e2bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ -2.8637,  18.6105,   0.2209,   5.4440, -68.6639]]),\n",
       " tensor([[ 3.9676, 98.8920,  7.0489, 34.7632, -8.0771]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_params(model, iteration=100)\n",
    "model.compute_bounds(x=(x,), final_node_name='/input.11', C=C, method='alpha-crown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01023109-244c-4c86-8c4b-8a28e343bd4a",
   "metadata": {},
   "source": [
    "# Converting Bounds to Points\n",
    "\n",
    "CROWN only gives us **bounds** for linear combinations of neuron inputs that we specified in the matrix `C`. \n",
    "However, we need **points** - not the bounds.\n",
    "Therefore, we also save the parameters of the backsubstituted inequalities and obtain the points in the input space that maximize/minimize the corresponding linear inequalities.\n",
    "These maximizers/minimizers are then substituted into the inequalities for the neuron-inputs.\n",
    "\n",
    "To obtain the coefficients of the inequalities, we need to set \n",
    "- `return_A = True` and also specify which coefficients we need by setting\n",
    "- `needed_A_dict = {<layer_i> : [<layer_j>, <layer_k>]}` which will return the matrix of coefficients when substituting back from `layer_i` to `layer_j` and the matrix when substituting back from `layer_i` to `layer_k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "10414ae8-19dd-4ae4-b465-e58700244672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lbs11crown, ubs11crown, A_dict = model.compute_bounds(x=(x,), final_node_name='/input.11', method='alpha-crown', return_A=True, needed_A_dict={'/input.11': ['/0']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd6119d-76e1-4bab-96ba-96f9addb94c8",
   "metadata": {},
   "source": [
    "The stored coefficients have shape `(batch, spec, *input_size)`. \n",
    "\n",
    "So if the input had shape `(1,1,1,784)` (which is `(batch, input_size1, input_size2, input_size3)`) and the matrix of specifications had `5` inequalities, the stored coefficients will have shape `(1, 5, 1, 1, 784)` (which is `(batch, spec, input_size1, input_size2, input_size3)`.\n",
    "\n",
    "If no matrix of specifications is given, the `spec` dimension just has the shape of the layer (i.e. if it has 256 neurons, we have `spec = 256`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "649cba12-ada4-49d3-a8c4-de90131efa65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape =  torch.Size([1, 256, 1, 1, 784])\n"
     ]
    }
   ],
   "source": [
    "lA_neurons = A_dict['/input.11']['/0']['lA']\n",
    "lb_neurons = A_dict['/input.11']['/0']['lbias']\n",
    "\n",
    "uA_neurons = A_dict['/input.11']['/0']['uA']\n",
    "ub_neurons = A_dict['/input.11']['/0']['ubias']\n",
    "\n",
    "print(\"A.shape = \", lA_neurons.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0feb7d7-8994-49f0-96b6-e0f3e809a6b6",
   "metadata": {},
   "source": [
    "After obtaining the coefficients for the **neurons**, we now obtain the coefficients for the sampled **directions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46372323-d51a-4268-b973-6e4cbd71353b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lbs11crown, ubs11crown, A_dict = model.compute_bounds(x=(x,), final_node_name='/input.11', C=C, method='alpha-crown', return_A=True, needed_A_dict={'/input.11': ['/0']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a3771fc-0a8f-4d5c-aadd-cb023d368776",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape =  torch.Size([1, 5, 1, 1, 784])\n"
     ]
    }
   ],
   "source": [
    "lA = A_dict['/input.11']['/0']['lA']\n",
    "lb = A_dict['/input.11']['/0']['lbias']\n",
    "\n",
    "uA = A_dict['/input.11']['/0']['uA']\n",
    "ub = A_dict['/input.11']['/0']['ubias']\n",
    "\n",
    "print(\"A.shape = \", lA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a49a3d5f-a77a-4f60-8c16-52dbfd3e15a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten2matrix(A_tensor, batch_id=0):\n",
    "    \"\"\"\n",
    "    Returns matrix of shape (spec, input_flat) corresponding to batch_id of the A_tensor.\n",
    "    \"\"\"\n",
    "    # reshape to (batch, spec, input_flat), then take specific batch (0th batch)\n",
    "    A_mat = A_tensor.reshape(A_tensor.shape[0], A_tensor.shape[1], -1)[batch_id, :]    \n",
    "    return A_mat\n",
    "\n",
    "def flatten2vector(b_tensor, batch_id=0):\n",
    "    \"\"\"\n",
    "    Returns flat input vector corresponding to the specified batch.\n",
    "    \"\"\"\n",
    "    b_vec = b_tensor.reshape(b_tensor.shape[0], -1)[batch_id, :]\n",
    "    return b_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbf0208-141b-4fb5-bbee-0f5dff32a142",
   "metadata": {},
   "source": [
    "The following cell is just to demonstrate that we get the same bounds as for the specification, if we calculate them by hand.\n",
    "(minor differences are expected due to randomization in the SGD procedure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ebbd482d-1c93-4222-a099-96ff45f52e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -2.8642,  18.5939,   0.2207,   5.4452, -68.6601])\n"
     ]
    }
   ],
   "source": [
    "lA_mat = flatten2matrix(lA)\n",
    "lb_vec = flatten2vector(lb)\n",
    "\n",
    "uA_mat = flatten2matrix(uA)\n",
    "ub_vec = flatten2vector(ub)\n",
    "\n",
    "x_L_vec = flatten2vector(x.ptb.x_L)\n",
    "x_U_vec = flatten2vector(x.ptb.x_U)\n",
    "\n",
    "lA_neg = torch.minimum(torch.zeros(1), lA_mat)\n",
    "lA_pos = torch.maximum(torch.zeros(1), lA_mat)\n",
    "\n",
    "uA_neg = torch.minimum(torch.zeros(1), uA_mat)\n",
    "uA_pos = torch.maximum(torch.zeros(1), uA_mat)\n",
    "\n",
    "lo = lA_pos.matmul(x_L_vec) + lA_neg.matmul(x_U_vec) + lb_vec\n",
    "\n",
    "print(lo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aa1783-5563-4b76-8fe9-18151b9e39f4",
   "metadata": {},
   "source": [
    "Now get the inputs that are used to calculate the lower bound of the output.\n",
    "\n",
    "For computation of lower bounds:\n",
    "- if the coefficient of input $x_i$ is negative, we take the *upper* bound of $x_i$\n",
    "- if the coefficient of input $x_i$ is positive, we take the *lower* bound of the input\n",
    "\n",
    "to calculate the lower bound of the specification output\n",
    "\n",
    "Vice-versa for computation of the upper bound on the specification output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "78d70273-f627-4bae-bce6-1291e39b07b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_lo = x_L_vec * (lA_mat > 0) + x_U_vec * (lA_mat < 0)\n",
    "x_up = x_U_vec * (uA_mat > 0) + x_L_vec * (uA_mat < 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c979a3-ff11-4b74-8b21-f11675fb6996",
   "metadata": {},
   "source": [
    "Then calculate bounds of the neuron inputs using these obtained values of the $x_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9a4dc14b-a0dd-4ba2-b997-e6bcd93cc003",
   "metadata": {},
   "outputs": [],
   "source": [
    "lA_neurons_mat = flatten2matrix(lA_neurons)\n",
    "lb_neurons_vec = flatten2vector(lb_neurons)\n",
    "\n",
    "uA_neurons_mat = flatten2matrix(uA_neurons)\n",
    "ub_neurons_vec = flatten2vector(ub_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "22718fed-07ad-4be5-8ee3-5546d77fdb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_neurons_subs = x_lo.matmul(lA_neurons_mat.T) + lb_neurons_vec\n",
    "u_neurons_subs = x_lo.matmul(uA_neurons_mat.T) + ub_neurons_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "380ccade-f427-4fd7-8dcc-e191fefa1641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8823, -1.9052, -1.3219,  ..., -6.1794, -2.7905, -0.5578],\n",
       "        [-0.8823, -1.9052, -1.3219,  ..., -6.1794, -2.7905, -0.5578],\n",
       "        [-0.8823, -1.9052, -1.3219,  ..., -6.1794, -2.7905, -0.5578],\n",
       "        [-0.8807, -1.8992, -1.3147,  ..., -6.1559, -2.7797, -0.5579],\n",
       "        [-0.9500, -2.4437, -1.9653,  ..., -8.3334, -3.7501, -0.4112]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_neurons_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f92ed381-642f-4458-9afe-5d6a9f536a31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3018, -0.5380,  0.0490,  ..., -1.9711, -0.6990, -0.1242],\n",
       "        [-0.3018, -0.5380,  0.0490,  ..., -1.9711, -0.6990, -0.1242],\n",
       "        [-0.3018, -0.5380,  0.0490,  ..., -1.9711, -0.6990, -0.1242],\n",
       "        [-0.3014, -0.5367,  0.0505,  ..., -1.9666, -0.6968, -0.1245],\n",
       "        [-0.4520, -1.0317, -0.4799,  ..., -3.6531, -1.4987, -0.1012]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_neurons_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c6ff1dc6-db54-4650-a098-28ecad405dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-154.4405, -154.4405, -154.4405, -153.7955, -165.0589],\n",
       "        [-122.0603, -122.0603, -122.0603, -121.5373, -109.7246],\n",
       "        [-171.8250, -171.8250, -171.8250, -171.0766, -185.8952],\n",
       "        [-154.2048, -154.2048, -154.2048, -153.5711, -156.8310],\n",
       "        [-200.7205, -200.7205, -200.7205, -199.8855, -230.7391]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_mat = flatten2matrix(C)\n",
    "\n",
    "# multiply each row of the specification (i.e. each direction) with each column of l_neurons_subs.T\n",
    "# (i.e. the rows of l_neurons_subs, which are the minimizers of the respective directions).\n",
    "torch.maximum(torch.zeros(1), C_mat).matmul(l_neurons_subs.T) + torch.minimum(torch.zeros(1), C_mat).matmul(u_neurons_subs.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "06ba861d-e084-4991-90b9-f9ccd8b9b9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "273678cb-2076-4b59-b59d-ae2d0341b66b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_neurons_subs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf75f87b-7619-4dcb-be07-9dd69df5a779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac242f06-5fcb-439e-b427-1df802612528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a79a531d-69b5-4305-9d49-b978047e153d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.4035, -44.7540, -81.8630, -27.9624,   2.5924]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roots()[0].perturbation.concretize(x, A, sign=-1) + A_dict['/input.11']['/0']['lbias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60929f-8bd9-4e58-83b2-4438b66aec45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f3f461-9dd2-4107-9e84-f639d6d8dd20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1bb7905-d221-4ce7-ad3e-1dd276037107",
   "metadata": {},
   "source": [
    "# Building LP Model\n",
    "\n",
    "There is at least some code available to build LP and MILP models, but it doesn't seem to be maintained/is broken now. Maybe we can repair and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "15fab111-98b9-4717-8725-92b94fced7b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'CONTINUOUS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_solver_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/autoLiRPA/lib/python3.10/site-packages/auto_LiRPA-0.4.0-py3.10.egg/auto_LiRPA/solver_module.py:50\u001b[0m, in \u001b[0;36mbuild_solver_module\u001b[0;34m(self, x, C, interm_bounds, final_node_name, model_type, solver_pkg)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# if isinstance(root[i], BoundInput) and not isinstance(root[i], BoundParams):\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(roots[i]) \u001b[38;5;129;01mis\u001b[39;00m BoundInput:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# create input vars for gurobi self.model\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     inp_gurobi_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_solver_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroots\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# regular weights\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     roots[i]\u001b[38;5;241m.\u001b[39msolver_vars \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m~/anaconda3/envs/autoLiRPA/lib/python3.10/site-packages/auto_LiRPA-0.4.0-py3.10.egg/auto_LiRPA/solver_module.py:97\u001b[0m, in \u001b[0;36m_build_solver_input\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     95\u001b[0m inp_gurobi_vars \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# zero var will be shared within the solver model\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m zero_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39maddVar(lb\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ub\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, vtype\u001b[38;5;241m=\u001b[39m\u001b[43mgrb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGRB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCONTINUOUS\u001b[49m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzero\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     98\u001b[0m one_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39maddVar(lb\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ub\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, vtype\u001b[38;5;241m=\u001b[39mgrb\u001b[38;5;241m.\u001b[39mGRB\u001b[38;5;241m.\u001b[39mCONTINUOUS, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     99\u001b[0m neg_one_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39maddVar(lb\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, ub\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, vtype\u001b[38;5;241m=\u001b[39mgrb\u001b[38;5;241m.\u001b[39mGRB\u001b[38;5;241m.\u001b[39mCONTINUOUS, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_one\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'CONTINUOUS'"
     ]
    }
   ],
   "source": [
    "model.build_solver_module(model_type='lp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cd596ff5-2235-431d-afc4-e2cc608ce858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gurobipy as grb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "be9cf783-6807-4e40-991e-6974109ad9ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-11-27\n"
     ]
    }
   ],
   "source": [
    "model.model = grb.Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179d2d7-87f3-448a-a1ca-f3552ff0fa5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoLiRPA",
   "language": "python",
   "name": "autolirpa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
