{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:19.794670050Z",
     "start_time": "2024-05-09T19:20:18.898799006Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import contextlib\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from script.NeuralNets.Networks import SequentialNN\n",
    "from script.settings import device, data_type\n",
    "import script.DHOV.MultiDHOV as multidhov\n",
    "import gurobipy as grp\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from script.NeuralNets.ICNNFactory import ICNNFactory\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from script.DHOV.Sampling.PerGroupLineSearchSampling import PerGroupLineSearchSamplingStrategy\n",
    "from script.DHOV.Sampling.PerGroupSamplingStrategy import PerGroupSamplingStrategy\n",
    "from script.DHOV.Sampling.PerGroupFeasibleSamplingStrategy import PerGroupFeasibleSamplingStrategy\n",
    "from script.DHOV.Sampling.ZonotopeSamplingStrategy import ZonotopeSamplingStrategy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx2pytorch import ConvertModel\n",
    "from auto_LiRPA import BoundedModule, BoundedTensor, PerturbationLpNorm\n",
    "\n",
    "from vnnlib.compat import read_vnnlib_simple\n",
    "from collections import OrderedDict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.033552134Z",
     "start_time": "2024-05-09T19:20:19.829851853Z"
    }
   },
   "id": "f0822bc3823089a5",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "onnx_name = \"mnist_relu_9_200.onnx\"\n",
    "vnnlib_name = \"1000_mnist_eps_015\"\n",
    "\n",
    "onnx_path = 'nets/' + onnx_name\n",
    "vnnlib_dir_path = \"specs/\" + vnnlib_name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.035550561Z",
     "start_time": "2024-05-09T19:20:20.034764632Z"
    }
   },
   "id": "2cac90c448c123e2",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cpu_core_count = os.cpu_count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.036987069Z",
     "start_time": "2024-05-09T19:20:20.035749011Z"
    }
   },
   "id": "ac9c32e3a6d0eda8",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import the onnx model and convert it to a SequentialNN\n",
    "It has to bee a SequentialNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43857ff221b9ea71"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The SequentialNN needs to have one additional output layer, as its last layer never has relu activation but the imported network has. The last layer then gets initialized with the identity matrix and gets skipped during the verification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72bcacbdec4990e4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ufuk/miniconda3/envs/autolirpa_icnn/lib/python3.10/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load(onnx_path)\n",
    "pytorch_model = ConvertModel(onnx_model)\n",
    "nn = SequentialNN([28 * 28 * 1, 200, 200, 200, 200, 200, 200, 200, 200, 10, 10])\n",
    "\n",
    "\n",
    "parameter_list_onnx = list(pytorch_model.parameters())\n",
    "parameter_list_sequential = list(nn.parameters())\n",
    "for i in range(0, len(parameter_list_onnx), 2):\n",
    "    parameter_list_sequential[i].data = parameter_list_onnx[i].data\n",
    "    parameter_list_sequential[i+1].data = parameter_list_onnx[i+1].data\n",
    "parameter_list_sequential[-2].data = torch.eye(10, dtype=data_type)\n",
    "parameter_list_sequential[-1].data = torch.zeros(10, dtype=data_type)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.047404004Z",
     "start_time": "2024-05-09T19:20:20.038052317Z"
    }
   },
   "id": "7ece6141625b3884",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "parameter_list = list(pytorch_model.parameters()) # don't use nn here as we have added an extra layer\n",
    "output_size = 10\n",
    "number_layer = (len(parameter_list) - 2) // 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.092096324Z",
     "start_time": "2024-05-09T19:20:20.048106713Z"
    }
   },
   "id": "2e0b30bcf0bc5ed3",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data to apply the verification process for"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32ac993914cba497"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + .05  # revert normalization for viewing\n",
    "    npimg = img.to(\"cpu\").numpy()\n",
    "    plt.imshow(npimg, cmap=\"gray\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.092567193Z",
     "start_time": "2024-05-09T19:20:20.089860197Z"
    }
   },
   "id": "813c48a4e74d2cfd",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transform = Compose([ToTensor()])\n",
    "training_data = MNIST(root=\"../../../mnist\", train=True, download=True, transform=transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.092923483Z",
     "start_time": "2024-05-09T19:20:20.089934117Z"
    }
   },
   "id": "e93b71692992f90e",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def accuracy_test(model, converted_model, data):\n",
    "    total_correct = 0\n",
    "    total_wrong = 0\n",
    "    for image, label in data:\n",
    "        test_image = torch.unsqueeze(image, 0).to(dtype=data_type).to(device)   \n",
    "        model_test = model(test_image)\n",
    "        converted_test = converted_model(test_image)\n",
    "        if not torch.isclose(model_test, converted_test).all():\n",
    "            print(\"is not close\")\n",
    "            break\n",
    "        if torch.argmax(model_test).item() == label:\n",
    "            total_correct += 1\n",
    "        else:\n",
    "            total_wrong += 1\n",
    "    \n",
    "    print(\"is close\")    \n",
    "    print(f\"accuracy {total_correct/ len(training_data)}\")\n",
    "    \n",
    "\n",
    "\n",
    "do_test = False\n",
    "if do_test:\n",
    "    accuracy_test(pytorch_model, nn, training_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.093243942Z",
     "start_time": "2024-05-09T19:20:20.089955397Z"
    }
   },
   "id": "7708d17e62f8ed3c",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def add_output_constraints(model, nn_layer_out_bounds, label, output_vars, sovler_bound=1e-3):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param model: the optimization problem in gurobi encoding the NN\n",
    "    :param nn_layer_out_bounds: torch.Tensor, approximating the upper and lower bounding the output layer of the NN\n",
    "    :param label: index of the label or target neuron which is compared against\n",
    "    :param output_vars: the gurobi variables from the model of the NN describing the output neurons of the NN\n",
    "    :param sovler_bound: provides a bound for the gurobi solver. If this bound is achieved, the optimizer stops\n",
    "    \"\"\"\n",
    "    \n",
    "    out_lb = nn_layer_out_bounds[-1][0].detach().cpu().numpy()\n",
    "    out_ub = nn_layer_out_bounds[-1][1].detach().cpu().numpy()\n",
    "    \n",
    "    difference_lb = out_lb - out_ub[label]\n",
    "    difference_ub = out_ub - out_lb[label]\n",
    "    difference_lb = difference_lb.tolist()\n",
    "    difference_ub = difference_ub.tolist()\n",
    "    \n",
    "    difference_lb.pop(label)\n",
    "    difference_ub.pop(label)\n",
    "    \n",
    "    min_diff = min(difference_lb)\n",
    "    max_diff = max(difference_ub)\n",
    "    \n",
    "    difference = model.addVars(9, lb=difference_lb, ub=difference_ub, name=\"diff_var\")\n",
    "    model.addConstrs((difference[i] == output_vars.tolist()[i] - output_vars.tolist()[label] for i in range(0, label)), name=\"diff_const0\")\n",
    "    model.addConstrs((difference[i - 1] == output_vars.tolist()[i] - output_vars.tolist()[label] for i in range(label + 1, 10)), name=\"diff_const1\")\n",
    "\n",
    "    max_var = model.addVar(lb=min_diff, ub=max_diff, name=\"max_var\")\n",
    "    model.addConstr(max_var == grp.max_(difference))\n",
    "\n",
    "    if sovler_bound != None:\n",
    "        model.setParam(\"BestObjStop\", sovler_bound)\n",
    "\n",
    "    model.update()\n",
    "    model.setObjective(max_var, grp.GRB.MAXIMIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.094653700Z",
     "start_time": "2024-05-09T19:20:20.091958514Z"
    }
   },
   "id": "18307fa1201eb3d6",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_output_vars_dhov(model, output_size, output_layer_index):\n",
    "    output_vars = []\n",
    "    for i in range(output_size):\n",
    "        output_vars.append(model.getVarByName(\"output_layer_[{}]_[{}]\".format(output_layer_index, i)))\n",
    "    output_vars = grp.MVar.fromlist(output_vars)\n",
    "    return output_vars"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.120312825Z",
     "start_time": "2024-05-09T19:20:20.093694362Z"
    }
   },
   "id": "d30a13deca625b13",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def optimize_model(model, output_vars, start_overall_time, time_limit=60*60, verbose=True, csv_to_write_to=None, csv_row_name=\"No name\"):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param model: the optimization problem in gurobi encoding the NN and the objective \n",
    "    :param output_vars: the gurobi variables from the model of the NN describing the output neurons of the NN\n",
    "    :return True if verification was successful, else false \n",
    "    \"\"\"\n",
    "    \n",
    "    model.setParam(\"TimeLimit\", time_limit)\n",
    "    \n",
    "    start_solving_time = time.time()\n",
    "    model.update()\n",
    "    model.optimize()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    time_just_solving = end_time - start_solving_time\n",
    "    time_overall = end_time - start_overall_time\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"time for verification {}\".format(time_just_solving))\n",
    "        print(\"overall time {}\".format(time_overall))\n",
    "    \n",
    "    if model.Status == grp.GRB.OPTIMAL or model.Status == grp.GRB.USER_OBJ_LIMIT:\n",
    "                    \n",
    "        max_var = model.getVarByName(\"max_var\").getAttr(\"x\")\n",
    "        verification_successful = max_var < 0\n",
    "        \n",
    "        if csv_to_write_to is not None:\n",
    "            new_row = [csv_row_name, \"finished\", time_just_solving, time_overall, verification_successful, max_var]\n",
    "            with open(csv_to_write_to, 'a', newline='') as file_obj:\n",
    "                writer_object = csv.writer(file_obj)\n",
    "             \n",
    "                writer_object.writerow(new_row)\n",
    "                file_obj.close()\n",
    "        \n",
    "        if verbose:\n",
    "            for i, var in enumerate(output_vars.tolist()):\n",
    "                print(\"var {}: {}\".format(i, var.getAttr(\"x\")))\n",
    "                \n",
    "            if verification_successful:\n",
    "                print(\"property verified with max difference {}\".format(max_var))\n",
    "                return True\n",
    "            else:\n",
    "                 print(\"property NOT verified with max difference {}\".format(max_var))\n",
    "                \n",
    "                \n",
    "        \n",
    "        \n",
    "        return verification_successful\n",
    "    \n",
    "    elif model.Status == grp.GRB.TIME_LIMIT:        \n",
    "        \n",
    "        max_var_upper_bound = model.getAttr(\"ObjBound\")\n",
    "        \n",
    "        verification_failed_with_upper_bound = max_var_upper_bound > 0\n",
    "        \n",
    "        if verbose:\n",
    "            if verification_failed_with_upper_bound:\n",
    "                print(\"property NOT verified with upper bound for max difference {}\".format(max_var_upper_bound))\n",
    "            else:\n",
    "                print(\"time out and upper bound could not disprove the setting\")\n",
    "            \n",
    "        if csv_to_write_to is not None:\n",
    "            new_row = [csv_row_name, \"time_out\", time_just_solving, time_overall, verification_failed_with_upper_bound, max_var_upper_bound]\n",
    "            with open(csv_to_write_to, 'a', newline='') as file_obj:\n",
    "                writer_object = csv.writer(file_obj)\n",
    "             \n",
    "                writer_object.writerow(new_row)\n",
    "                file_obj.close()\n",
    "                \n",
    "                \n",
    "        return verification_failed_with_upper_bound\n",
    "\n",
    "    elif model.Status == grp.GRB.INFEASIBLE:\n",
    "        \n",
    "        if csv_to_write_to is not None:\n",
    "            new_row = [csv_row_name, \"infeasible\", time_just_solving, time_overall, False]\n",
    "            with open(csv_to_write_to, 'a', newline='') as file_obj:\n",
    "                writer_object = csv.writer(file_obj)\n",
    "             \n",
    "                writer_object.writerow(new_row)\n",
    "                file_obj.close()\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"model infeasible\")\n",
    "    \n",
    "            model.computeIIS()\n",
    "            print(\"constraint\")\n",
    "            all_constr = model.getConstrs()\n",
    "    \n",
    "            for const in all_constr:\n",
    "                if const.IISConstr:\n",
    "                    print(\"{}\".format(const))\n",
    "    \n",
    "            print(\"lower bound\")\n",
    "            all_var = model.getVars()\n",
    "            for var in all_var:\n",
    "                if var.IISLB:\n",
    "                    print(\"{}, lb: {}, ub: {}\".format(var, var.getAttr(\"lb\"), var.getAttr(\"ub\")))\n",
    "    \n",
    "            print(\"upper bound\")\n",
    "            all_var = model.getVars()\n",
    "            for var in all_var:\n",
    "                if var.IISUB:\n",
    "                    print(\"{}, lb: {}, ub: {}\".format(var, var.getAttr(\"lb\"), var.getAttr(\"ub\")))\n",
    "                \n",
    "        \n",
    "\n",
    "    return False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.120676305Z",
     "start_time": "2024-05-09T19:20:20.114772832Z"
    }
   },
   "id": "dc139c863ddc89fa",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_vnnlib_bounds(vnnlib_path, input_shape, n_out):\n",
    "    n_in = np.prod(input_shape)\n",
    "    res = read_vnnlib_simple(vnnlib_path, n_in, n_out)\n",
    "    bnds, spec = res[0]\n",
    "    \n",
    "    bnds = np.array(bnds)\n",
    "    lbs = bnds[:,0]\n",
    "    ubs = bnds[:,1]\n",
    "    \n",
    "    data_min = torch.tensor(lbs, dtype=data_type).reshape(input_shape).to(device)\n",
    "    data_max = torch.tensor(ubs, dtype=data_type).reshape(input_shape).to(device)\n",
    "\n",
    "    return [data_min, data_max]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.120972914Z",
     "start_time": "2024-05-09T19:20:20.114827582Z"
    }
   },
   "id": "ee77c603c2d29b5c",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "# get bounds with crown"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b09947b5d45122e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def onnx_to_bounded_model(onnx_path, input_shape):\n",
    "    onnx_model = onnx.load(onnx_path)\n",
    "    torch_model = ConvertModel(onnx_model)\n",
    "    \n",
    "    x_concrete = torch.zeros(input_shape)\n",
    "    model = BoundedModule(torch_model, x_concrete)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.121257154Z",
     "start_time": "2024-05-09T19:20:20.114849902Z"
    }
   },
   "id": "554027a243f269d8",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_vnnlib_spec_for_auto_lirpa(vnnlib_path, input_shape, n_out):\n",
    "    n_in = np.prod(input_shape)\n",
    "    res = read_vnnlib_simple(vnnlib_path, n_in, n_out)\n",
    "    bnds, spec = res[0]\n",
    "    \n",
    "    bnds = np.array(bnds)\n",
    "    lbs = bnds[:,0]\n",
    "    ubs = bnds[:,1]\n",
    "    \n",
    "    data_min = torch.tensor(lbs, dtype=data_type).reshape(input_shape)\n",
    "    data_max = torch.tensor(ubs, dtype=data_type).reshape(input_shape)\n",
    "    center = 0.5*(data_min + data_max)\n",
    "\n",
    "    ptb = PerturbationLpNorm(x_L=data_min, x_U=data_max)\n",
    "    x = BoundedTensor(center, ptb)\n",
    "    \n",
    "    return x, center"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.121536314Z",
     "start_time": "2024-05-09T19:20:20.114869172Z"
    }
   },
   "id": "b42ade07de97121a",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_layers(model):\n",
    "    return [l for l in model.nodes() if l.perturbed]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.121823973Z",
     "start_time": "2024-05-09T19:20:20.114930432Z"
    }
   },
   "id": "236afc883215fbaf",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_intermediate_bounds(model):\n",
    "    \"\"\"\n",
    "    Returns a dictionary containing the concrete lower and upper bounds of each layer.\n",
    "    \n",
    "    Implemented own method to filter out bounds for weight matrices.\n",
    "    \n",
    "    Only call this method after compute_bounds()!\n",
    "    \"\"\"\n",
    "    od = OrderedDict()\n",
    "    for l in get_layers(model):\n",
    "        if hasattr(l, 'lower'):\n",
    "            od[l.name] = (l.lower, l.upper)\n",
    "            \n",
    "    return od"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.122225483Z",
     "start_time": "2024-05-09T19:20:20.114949082Z"
    }
   },
   "id": "5e6033fd22f9b945",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_bounds_auto_lirpa(x: BoundedTensor, model: BoundedModule, method=\"crown\"):\n",
    "    model.compute_bounds(x=(x,), method=method, bound_lower=True, bound_upper=True)\n",
    "    bounds_dict_crown = get_intermediate_bounds(model)\n",
    "    crown_bounds_affine_out = []\n",
    "    prev_key = None\n",
    "    for i, key in enumerate(bounds_dict_crown.keys()):\n",
    "        if i == 0: # use this if ibp is used (or i % 2 == 1:)\n",
    "            continue\n",
    "        elif method == \"alpha-crown\" and \"59\" in key:\n",
    "            # todo WTF, why do i need to do this?\n",
    "            lb, ub = bounds_dict_crown[key][0], bounds_dict_crown[prev_key][1]\n",
    "            crown_bounds_affine_out.append([lb.type(data_type).view(-1).to(device), ub.type(data_type).view(-1).to(device)])\n",
    "        else: \n",
    "            lb, ub = bounds_dict_crown[key]\n",
    "            crown_bounds_affine_out.append([lb.type(data_type).view(-1).to(device), ub.type(data_type).view(-1).to(device)])\n",
    "        prev_key = key\n",
    "        \n",
    "    crown_bounds_layer_out = []\n",
    "    relu = torch.nn.ReLU()\n",
    "    for i, (lb, ub) in enumerate(crown_bounds_affine_out):\n",
    "        if i == len(crown_bounds_affine_out) - 1:\n",
    "            crown_bounds_layer_out.append([lb, ub])\n",
    "        else:\n",
    "            lb_layer = relu(lb)\n",
    "            ub_layer = relu(ub)\n",
    "            crown_bounds_layer_out.append([lb_layer, ub_layer])\n",
    "            \n",
    "    return crown_bounds_affine_out, crown_bounds_layer_out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.122701542Z",
     "start_time": "2024-05-09T19:20:20.114967212Z"
    }
   },
   "id": "41468184eb04a1b1",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create new csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d53a434138b1b701"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_csv_file(csv_file_path, settings):\n",
    "    data = [['Input name', 'State of optimization', 'time for just solving', \"time overall\", \"was successful?\", \"max distance\", settings]]\n",
    "    # File path for the CSV file\n",
    "    if os.path.isfile(csv_file_path):\n",
    "        raise RuntimeError(\"File name {} already exists\".format(csv_file_path))\n",
    "    \n",
    "    # Open the file in write mode\n",
    "    with open(csv_file_path, mode='a+', newline='') as file_obj:\n",
    "        # Create a csv.writer object\n",
    "        writer_object = csv.writer(file_obj)\n",
    "        # Write data to the CSV file\n",
    "        writer_object.writerows(data)\n",
    "     \n",
    "    # Print a confirmation message\n",
    "    print(f\"CSV file '{csv_file_path}' created successfully.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.123163561Z",
     "start_time": "2024-05-09T19:20:20.114986742Z"
    }
   },
   "id": "2f97d8bc608761dc",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def check_if_image_is_labeled_correctly(nn_model, image, label):\n",
    "    test_image = torch.unsqueeze(image, 0).to(dtype=data_type).to(device)\n",
    "    output = nn_model(test_image)\n",
    "    return torch.argmax(output).item() == label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.123643751Z",
     "start_time": "2024-05-09T19:20:20.115015652Z"
    }
   },
   "id": "c4e068c1d61a4714",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def check_if_auto_lirpa_already_verifies(x, output_size, label, method=\"crown\"):\n",
    "    c_matrix = torch.zeros((1, output_size - 1, output_size))\n",
    "    for i in range(output_size - 1):\n",
    "        if i < label:\n",
    "            index = i\n",
    "        elif i >= label:\n",
    "            index = i + 1\n",
    "        \n",
    "        c_matrix[0][i][index] = 1\n",
    "        c_matrix[0][i][label] = -1\n",
    "    \n",
    "    lb, ub = model.compute_bounds(x=(x,), C=c_matrix, method=method)\n",
    "    \n",
    "    return ub.max() < 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:20:20.124136450Z",
     "start_time": "2024-05-09T19:20:20.116843479Z"
    }
   },
   "id": "4db18c087bbe41ee",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Do Verification SNR with MILP in last layer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3acab87b527a78c2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file '02_throw_away_result_snv+milp_mnist_9x200_eps_015.csv' created successfully.\n",
      "2 ================================================\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = \"01_result_snv+milp_mnist_9x200_eps_015.csv\"\n",
    "\n",
    "crown_method = \"alpha-crown\"\n",
    "tighten_bounds = True\n",
    "time_out = 60*60\n",
    "time_per_neuron_refinement = 1\n",
    "allow_heuristic_timeout_estimate = True\n",
    "settings = \"crown_method: {}, tighten_bounds: {}, time_out: {}, time_per_neuron_refinement: {}, allow_heuristic_timeout_estimate: {}\".format(crown_method, tighten_bounds, time_out, time_per_neuron_refinement, allow_heuristic_timeout_estimate)\n",
    "create_csv_file(csv_file_path, settings)\n",
    "\n",
    "\n",
    "for num, vnnlib_path in enumerate(sorted(os.listdir(vnnlib_dir_path))): \n",
    "    \n",
    "    if num == 50:\n",
    "        break\n",
    "    \n",
    "    print(\"{} ================================================\".format(num))\n",
    "    \n",
    "    full_path = vnnlib_dir_path + \"/\" + vnnlib_path\n",
    "    input_bounds = load_vnnlib_bounds(full_path, [784,], 10)\n",
    "    model = onnx_to_bounded_model(onnx_path, [1,1,1,784])\n",
    "    image, label = training_data[num]\n",
    "    x, center = load_vnnlib_spec_for_auto_lirpa(full_path, [1,1,1,784], 10)\n",
    "    \n",
    "    if not check_if_image_is_labeled_correctly(nn, image, label):\n",
    "        print(\"skipped because wrong classification from the network\")\n",
    "        \n",
    "        new_row = [vnnlib_path, \"wrong classification\"]\n",
    "        with open(csv_file_path, 'a', newline='') as file_obj:\n",
    "            writer_object = csv.writer(file_obj)\n",
    "         \n",
    "            writer_object.writerow(new_row)\n",
    "            file_obj.close()\n",
    "            \n",
    "            \n",
    "        continue\n",
    "    \n",
    "    if check_if_auto_lirpa_already_verifies(x, 10, label, method=crown_method):\n",
    "        print(\"skipped because auto lirpa already verified\")\n",
    "        \n",
    "        new_row = [vnnlib_path, \"lirpa classified\"]\n",
    "        with open(csv_file_path, 'a', newline='') as file_obj:\n",
    "            writer_object = csv.writer(file_obj)\n",
    "         \n",
    "            writer_object.writerow(new_row)\n",
    "            file_obj.close()\n",
    "            \n",
    "        continue\n",
    "    \n",
    "    overall_time = time.time()\n",
    "    # weirdly the box bounds are faster for snr+milp\n",
    "    bounds_affine_out, bounds_layer_out = get_bounds_auto_lirpa(x, model, method=crown_method)\n",
    "    \n",
    "    # we need to pick these parameters, but for the SNR+MILP case these don't matter\n",
    "    sampling_strategy = PerGroupLineSearchSamplingStrategy(center, input_bounds, nn, sample_count=100)\n",
    "    group_size = 20\n",
    "    net_size = [5, 1]\n",
    "    icnn_factory = ICNNFactory(\"logical\", net_size, always_use_logical_layer=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    dhov_verifier = multidhov.MultiDHOV()\n",
    "    \n",
    "    # block prints\n",
    "    with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n",
    "        dhov_verifier.start_verification(nn, center, icnn_factory, group_size, input_bounds, sampling_strategy, \n",
    "                                         init_affine_bounds=bounds_affine_out, init_layer_bounds=bounds_layer_out,\n",
    "                                         skip_last_layer=True,\n",
    "                                         tighten_bounds=tighten_bounds, \n",
    "                                         layers_as_snr=[0, 1, 2, 3, 4, 5, 6, 7], \n",
    "                                         layers_as_milp=[8],\n",
    "                                         time_out=time_out,\n",
    "                                         time_per_neuron_refinement=time_per_neuron_refinement,\n",
    "                                         allow_heuristic_timeout_estimate=allow_heuristic_timeout_estimate,)\n",
    "    \n",
    "\n",
    "    \n",
    "    dhov_model = dhov_verifier.nn_encoding_model.copy()\n",
    "    dhov_model.setParam(grp.GRB.Param.Threads, cpu_core_count)\n",
    "    dhov_model.update()\n",
    "    dhov_out_vars = get_output_vars_dhov(dhov_model, output_size, number_layer)\n",
    "    \n",
    "    add_output_constraints(dhov_model, dhov_verifier.bounds_layer_out, label, dhov_out_vars)\n",
    "    \n",
    "    optimize_model(dhov_model, dhov_out_vars, overall_time, verbose=False, csv_to_write_to=csv_file_path, csv_row_name=vnnlib_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T21:09:50.897888414Z",
     "start_time": "2024-05-09T21:07:11.498152399Z"
    }
   },
   "id": "5fa48a5e8cadf1f2",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'csv_file_path = \"result_dhov_20_3000_mnist_9x200_eps_015.csv\"\\nnew_row = [\"prop_004_0.015.vnnlib\", \"time_out of DHOV\", \"-\", 3600, False]\\nwith open(csv_file_path, \\'a\\', newline=\\'\\') as file_obj:\\n    writer_object = csv.writer(file_obj)\\n \\n    writer_object.writerow(new_row)\\n    file_obj.close()'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"csv_file_path = \"result_dhov_20_3000_mnist_9x200_eps_015.csv\"\n",
    "new_row = [\"prop_004_0.015.vnnlib\", \"time_out of DHOV\", \"-\", 3600, False]\n",
    "with open(csv_file_path, 'a', newline='') as file_obj:\n",
    "    writer_object = csv.writer(file_obj)\n",
    " \n",
    "    writer_object.writerow(new_row)\n",
    "    file_obj.close()\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T18:53:56.812491652Z",
     "start_time": "2024-05-09T18:53:56.806513549Z"
    }
   },
   "id": "723f3aea6fd6e15d",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Do DHOV Verification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81f784dcbd39453c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ufuk/Documents/Programming/ICNN_verification/script/DHOV/MultiDHOV.py:152: UserWarning: value for group number multiplier is given with grouping method consecutive. consecutive grouping does not use variable number of groups\n",
      "  warnings.warn(\"value for group number multiplier is given with grouping method consecutive. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "approximation of layer: 0\n",
      "    number of fixed neurons for current layer: 93\n",
      "        time for sampling: 0.017266273498535156\n",
      "    layer progress, group 1 of 6 \n",
      "        time for training: 2.291013717651367\n",
      "    layer progress, group 2 of 6 \n",
      "        time for training: 1.6846094131469727\n",
      "    layer progress, group 3 of 6 \n",
      "        time for training: 2.161262035369873\n",
      "    layer progress, group 4 of 6 \n",
      "        time for training: 2.286400556564331\n",
      "    layer progress, group 5 of 6 \n",
      "        time for training: 2.1636698246002197\n",
      "    layer progress, group 6 of 6 \n",
      "        time for training: 1.9968247413635254\n",
      "        actual verification time 0.08064818382263184\n",
      "        actual verification time 0.7546164989471436\n",
      "        actual verification time 0.7408585548400879\n",
      "        actual verification time 0.7820949554443359\n",
      "        actual verification time 0.7918167114257812\n",
      "        actual verification time 0.8432378768920898\n",
      "        time for verification: 1.2418174743652344\n",
      "total time for current layer: 14.001005411148071\n",
      "\n",
      "approximation of layer: 1\n",
      "    number of fixed neurons for current layer: 65\n",
      "        time for sampling: 4.251301527023315\n",
      "    layer progress, group 1 of 7 \n",
      "        time for training: 1.8323721885681152\n",
      "    layer progress, group 2 of 7 \n",
      "        time for training: 2.185317277908325\n",
      "    layer progress, group 3 of 7 \n",
      "        time for training: 2.335876703262329\n",
      "    layer progress, group 4 of 7 \n",
      "        time for training: 0.7076125144958496\n",
      "    layer progress, group 5 of 7 \n",
      "        time for training: 2.1058144569396973\n",
      "    layer progress, group 6 of 7 \n",
      "        time for training: 2.109342336654663\n",
      "    layer progress, group 7 of 7 \n",
      "        time for training: 2.148115634918213\n",
      "        actual verification time 2.43319034576416\n",
      "        actual verification time 2.9370996952056885\n",
      "        actual verification time 4.919707298278809\n",
      "        actual verification time 5.507568359375\n",
      "        actual verification time 6.121764421463013\n",
      "        actual verification time 7.0287697315216064\n",
      "        actual verification time 15.904086828231812\n",
      "        time for verification: 16.33993101119995\n",
      "total time for current layer: 34.20142197608948\n",
      "\n",
      "approximation of layer: 2\n",
      "    number of fixed neurons for current layer: 0\n",
      "        time for sampling: 6.672326564788818\n",
      "    layer progress, group 1 of 10 \n",
      "        time for training: 0.7201800346374512\n",
      "    layer progress, group 2 of 10 \n",
      "        time for training: 0.7079493999481201\n",
      "    layer progress, group 3 of 10 \n",
      "        time for training: 0.7107467651367188\n",
      "    layer progress, group 4 of 10 \n",
      "        time for training: 0.7663006782531738\n",
      "    layer progress, group 5 of 10 \n",
      "        time for training: 0.7488610744476318\n",
      "    layer progress, group 6 of 10 \n",
      "        time for training: 0.7037708759307861\n",
      "    layer progress, group 7 of 10 \n",
      "        time for training: 0.7060093879699707\n",
      "    layer progress, group 8 of 10 \n",
      "        time for training: 0.7018506526947021\n",
      "    layer progress, group 9 of 10 \n",
      "        time for training: 0.7018871307373047\n",
      "    layer progress, group 10 of 10 \n",
      "        time for training: 0.7008264064788818\n",
      "        actual verification time (time limit) 30.037400484085083\n",
      "        actual verification time (time limit) 30.035170793533325            enlarge with 10.623832455543395        actual verification time (time limit) 30.035722255706787        actual verification time (time limit) 30.025402545928955\n",
      "\n",
      "\n",
      "            enlarge with 12.033489124768627            enlarge with 22.278852428823136            enlarge with 11.384062116201731        actual verification time (time limit) 30.05139183998108\n",
      "\n",
      "\n",
      "\n",
      "        actual verification time (time limit) 30.030986309051514\n",
      "\n",
      "\n",
      "            enlarge with 12.457470509882812\n",
      "\n",
      "            enlarge with 15.09014244823585\n",
      "        actual verification time (time limit) 30.027781009674072\n",
      "            enlarge with 15.942624163348928        actual verification time (time limit) 30.033388376235962        actual verification time (time limit) 30.033326625823975\n",
      "\n",
      "\n",
      "            enlarge with 8.310894532737642            enlarge with 11.473238903846374        actual verification time (time limit) 30.037982940673828\n",
      "            enlarge with 7.328402797079156\n",
      "        time for verification: 30.533655881881714\n",
      "total time for current layer: 44.64026355743408\n",
      "\n",
      "approximation of layer: 3\n",
      "    number of fixed neurons for current layer: 0\n",
      "        time for sampling: 7.390317916870117\n",
      "    layer progress, group 1 of 10 \n",
      "        time for training: 0.6686875820159912\n",
      "    layer progress, group 2 of 10 \n",
      "        time for training: 0.7278561592102051\n",
      "    layer progress, group 3 of 10 \n",
      "        time for training: 0.6916086673736572\n",
      "    layer progress, group 4 of 10 \n",
      "        time for training: 0.7325115203857422\n",
      "    layer progress, group 5 of 10 \n",
      "        time for training: 0.7354660034179688\n",
      "    layer progress, group 6 of 10 \n",
      "        time for training: 0.7382602691650391\n",
      "    layer progress, group 7 of 10 \n",
      "        time for training: 0.898383617401123\n",
      "    layer progress, group 8 of 10 \n",
      "        time for training: 0.7464251518249512\n",
      "    layer progress, group 9 of 10 \n",
      "        time for training: 0.7706584930419922\n",
      "    layer progress, group 10 of 10 \n",
      "        time for training: 0.7572126388549805\n",
      "        actual verification time (time limit) 30.041569471359253        actual verification time (time limit) 30.02707600593567\n",
      "\n",
      "        actual verification time (time limit) 30.028560638427734            enlarge with 15.94727909736591        actual verification time (time limit) 30.03687572479248        actual verification time (time limit) 30.04861569404602\n",
      "\n",
      "            enlarge with 19.67826333755729\n",
      "\n",
      "            enlarge with 16.945628929146665        actual verification time (time limit) 30.05183982849121            enlarge with 19.089884429889565        actual verification time (time limit) 30.031124591827393        actual verification time (time limit) 30.028113842010498\n",
      "\n",
      "            enlarge with 15.728131740671257\n",
      "        actual verification time (time limit) 30.0317165851593        actual verification time (time limit) 30.029793739318848\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            enlarge with 19.24502643224695\n",
      "            enlarge with 14.275702847280884            enlarge with 15.469725099690638\n",
      "            enlarge with 13.325937247350314\n",
      "            enlarge with 17.647258639648324\n",
      "\n",
      "        time for verification: 30.544610261917114\n",
      "total time for current layer: 45.66685128211975\n",
      "\n",
      "approximation of layer: 4\n",
      "    number of fixed neurons for current layer: 0\n",
      "        time for sampling: 8.11400318145752\n",
      "    layer progress, group 1 of 10 \n",
      "        time for training: 0.6864871978759766\n",
      "    layer progress, group 2 of 10 \n",
      "        time for training: 0.7105753421783447\n",
      "    layer progress, group 3 of 10 \n",
      "        time for training: 0.7091770172119141\n",
      "    layer progress, group 4 of 10 \n",
      "        time for training: 0.7098367214202881\n",
      "    layer progress, group 5 of 10 \n",
      "        time for training: 0.6596333980560303\n",
      "    layer progress, group 6 of 10 \n",
      "        time for training: 0.726146936416626\n",
      "    layer progress, group 7 of 10 \n",
      "        time for training: 0.7075269222259521\n",
      "    layer progress, group 8 of 10 \n",
      "        time for training: 0.704634428024292\n",
      "    layer progress, group 9 of 10 \n",
      "        time for training: 0.8021562099456787\n",
      "    layer progress, group 10 of 10 \n",
      "        time for training: 0.6526477336883545\n",
      "        actual verification time (time limit) 30.00522756576538        actual verification time (time limit) 30.006653308868408        actual verification time (time limit) 30.007004499435425\n",
      "\n",
      "            enlarge with 18.834369749525457\n",
      "            enlarge with 19.301543567217465\n",
      "        actual verification time (time limit) 30.011417388916016\n",
      "        actual verification time (time limit) 30.007919311523438            enlarge with 23.94504825772803\n",
      "        actual verification time (time limit) 30.015539169311523\n",
      "\n",
      "            enlarge with 21.246732831603033            enlarge with 19.87141005978084\n",
      "            enlarge with 20.94221529582414\n",
      "\n",
      "\n",
      "        actual verification time (time limit) 30.00341272354126        actual verification time (time limit) 30.003689527511597\n",
      "\n",
      "            enlarge with 18.759794798700913            enlarge with 21.725251496110406\n",
      "        actual verification time (time limit) 30.00465226173401\n",
      "\n",
      "            enlarge with 22.9746331643851\n",
      "        actual verification time (time limit) 30.005915880203247\n",
      "            enlarge with 20.975290390280783\n",
      "        time for verification: 30.52874183654785\n",
      "total time for current layer: 45.972344398498535\n",
      "\n",
      "approximation of layer: 5\n",
      "    number of fixed neurons for current layer: 0\n",
      "        time for sampling: 8.743897438049316\n",
      "    layer progress, group 1 of 10 \n",
      "        time for training: 0.7167823314666748\n",
      "    layer progress, group 2 of 10 \n",
      "        time for training: 0.7052340507507324\n",
      "    layer progress, group 3 of 10 \n",
      "        time for training: 0.655573844909668\n",
      "    layer progress, group 4 of 10 \n",
      "        time for training: 0.7102901935577393\n",
      "    layer progress, group 5 of 10 \n",
      "        time for training: 0.7586939334869385\n",
      "    layer progress, group 6 of 10 \n",
      "        time for training: 0.7041068077087402\n",
      "    layer progress, group 7 of 10 \n",
      "        time for training: 0.6954617500305176\n",
      "    layer progress, group 8 of 10 \n",
      "        time for training: 0.7005579471588135\n",
      "    layer progress, group 9 of 10 \n",
      "        time for training: 0.6985197067260742\n",
      "    layer progress, group 10 of 10 \n",
      "        time for training: 0.7053689956665039\n",
      "        actual verification time (time limit) 30.012827157974243        actual verification time (time limit) 30.014608144760132\n",
      "        actual verification time (time limit) 30.012433528900146        actual verification time (time limit) 30.02175545692444\n",
      "\n",
      "        actual verification time (time limit) 30.025837898254395            enlarge with 22.75010299633382            enlarge with 22.51488363194536\n",
      "\n",
      "\n",
      "\n",
      "        actual verification time (time limit) 30.02916669845581            enlarge with 20.635344091442374\n",
      "\n",
      "        actual verification time (time limit) 30.005177974700928            enlarge with 20.69809824838101        actual verification time (time limit) 30.007564544677734        actual verification time (time limit) 30.007381439208984            enlarge with 24.497180840368515\n",
      "            enlarge with 21.798587407808395\n",
      "        actual verification time (time limit) 30.005795001983643\n",
      "\n",
      "\n",
      "            enlarge with 27.931516081503005            enlarge with 27.016271362240715            enlarge with 22.791791916995315\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            enlarge with 24.255928281229643\n",
      "        time for verification: 30.580604553222656\n",
      "total time for current layer: 46.64341163635254\n",
      "\n",
      "approximation of layer: 6\n",
      "    number of fixed neurons for current layer: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mStopIteration\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/autolirpa_icnn/lib/python3.10/site-packages/vnnlib/tokenizer.py:49\u001B[0m, in \u001B[0;36m__iter__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mStopIteration\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mStopIteration\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/autolirpa_icnn/lib/python3.10/site-packages/vnnlib/tokenizer.py:49\u001B[0m, in \u001B[0;36m__iter__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mStopIteration\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 74\u001B[0m\n\u001B[1;32m     72\u001B[0m dhov_verifier \u001B[38;5;241m=\u001B[39m multidhov\u001B[38;5;241m.\u001B[39mMultiDHOV()\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(os\u001B[38;5;241m.\u001B[39mdevnull, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f: \u001B[38;5;66;03m# , contextlib.redirect_stdout(f):\u001B[39;00m\n\u001B[0;32m---> 74\u001B[0m         return_without_time_out \u001B[38;5;241m=\u001B[39m \u001B[43mdhov_verifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_verification\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcenter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43micnn_factory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_bounds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampling_strategy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43minit_affine_bounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbounds_affine_out\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43minit_layer_bounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbounds_layer_out\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43mskip_last_layer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43micnn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43micnn_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     80\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43muse_over_approximation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43mtighten_bounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtighten_bounds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     82\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43muse_fixed_neurons_in_grouping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     83\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43mlayers_as_snr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     84\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43mlayers_as_milp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     85\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43mforce_inclusion_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43mpreemptive_stop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     87\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43mgrouping_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mconsecutive\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     88\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43mgroup_num_multiplier\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     89\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSdLBFGS\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     90\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43minit_network\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     91\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43madapt_lambda\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mincluded\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43mencode_icnn_enlargement_as_lp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43mencode_relu_enlargement_as_lp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     94\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43mtime_out\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_out\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43mtime_per_neuron_refinement\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_per_neuron_refinement\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43mtime_per_icnn_refinement\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_per_icnn_refinement\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     97\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43mallow_heuristic_timeout_estimate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_heuristic_timeout_estimate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     98\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[43mbreak_after\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_training_loss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_new_bounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_optimization_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_last_loss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_without_time_out:\n\u001B[1;32m    101\u001B[0m     new_row \u001B[38;5;241m=\u001B[39m [vnnlib_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtime_out of DHOV\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m\"\u001B[39m, time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m overall_time, \u001B[38;5;28;01mFalse\u001B[39;00m]\n",
      "File \u001B[0;32m~/Documents/Programming/ICNN_verification/script/DHOV/MultiDHOV.py:350\u001B[0m, in \u001B[0;36mMultiDHOV.start_verification\u001B[0;34m(self, nn, input, icnn_factory, group_size, input_bounds, sampling_strategy, icnn_batch_size, icnn_epochs, hyper_lambda, init_affine_bounds, init_layer_bounds, break_after, tighten_bounds, use_fixed_neurons_in_grouping, layers_as_milp, layers_as_snr, use_over_approximation, skip_last_layer, time_per_neuron_refinement, time_per_icnn_refinement, preemptive_stop, store_samples, encode_icnn_enlargement_as_lp, encode_relu_enlargement_as_lp, force_inclusion_steps, grouping_method, group_num_multiplier, init_network, adapt_lambda, optimizer, time_out, allow_heuristic_timeout_estimate, print_training_loss, print_last_loss, print_optimization_steps, print_new_bounds)\u001B[0m\n\u001B[1;32m    347\u001B[0m gurobi_model \u001B[38;5;241m=\u001B[39m nn_encoding_model\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m    349\u001B[0m t \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m--> 350\u001B[0m included_space, ambient_space \u001B[38;5;241m=\u001B[39m \u001B[43msampling_strategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msampling_by_round\u001B[49m\u001B[43m(\u001B[49m\u001B[43maffine_w\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maffine_b\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mall_group_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m                                                                    \u001B[49m\u001B[43mgurobi_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcurrent_layer_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m                                                                    \u001B[49m\u001B[43mbounds_affine_out\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbounds_layer_out\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[43m                                                                    \u001B[49m\u001B[43mlist_of_icnns\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        time for sampling: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m t))\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m time_out_start \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m time_out:\n",
      "File \u001B[0;32m~/Documents/Programming/ICNN_verification/script/DHOV/Sampling/SamplingStrategy.py:94\u001B[0m, in \u001B[0;36mSamplingStrategy.sampling_by_round\u001B[0;34m(self, affine_w, affine_b, all_group_indices, gurobi_model, current_layer_index, bounds_affine_out, bounds_layer_out, list_of_icnns)\u001B[0m\n\u001B[1;32m     91\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampling_strategy_for_first_layer()\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m current_layer_index \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m---> 94\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sampling_strategy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mround_index must be a positive integer or zero. Got: \u001B[39m\u001B[38;5;124m\"\u001B[39m, current_layer_index)\n",
      "File \u001B[0;32m~/Documents/Programming/ICNN_verification/script/DHOV/Sampling/PerGroupLineSearchSampling.py:30\u001B[0m, in \u001B[0;36mPerGroupLineSearchSamplingStrategy._sampling_strategy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_sampling_strategy\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 30\u001B[0m     sample_space \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sample_group_line_search_lp\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_current_included_sample_count\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m                                                     \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_current_group_indices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_current_affine_w\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[43m                                                     \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_current_all_group_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[43m                                                     \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_current_layer_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_current_list_of_icnns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m                                                     \u001B[49m\u001B[43mrand_samples_percent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrand_samples_percent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m                                                     \u001B[49m\u001B[43mrand_sample_alternation_percent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrand_sample_alternation_percent\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_sample_space \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply_relu_transform(sample_space)\n",
      "File \u001B[0;32m~/Documents/Programming/ICNN_verification/script/DHOV/Sampling/PerGroupLineSearchSampling.py:95\u001B[0m, in \u001B[0;36mPerGroupLineSearchSamplingStrategy._sample_group_line_search_lp\u001B[0;34m(self, amount, nn_model, group_indices, affine_w, all_group_indices, current_layer_index, list_of_icnns, rand_samples_percent, rand_sample_alternation_percent)\u001B[0m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     93\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loss_for_boundary_without_icnn(nn_until_current_layer, input_samples, cs,\n\u001B[1;32m     94\u001B[0m                                                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_bounds)\n\u001B[0;32m---> 95\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     97\u001B[0m adapted_input_samples \u001B[38;5;241m=\u001B[39m input_samples\n",
      "File \u001B[0;32m~/miniconda3/envs/autolirpa_icnn/lib/python3.10/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/autolirpa_icnn/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "csv_file_path = \"result_dhov_mnist_9x200_eps_015.csv\"\n",
    "\n",
    "\n",
    "group_size = 20\n",
    "sample_count = 3000\n",
    "crown_method = \"alpha-crown\"\n",
    "tighten_bounds = True\n",
    "time_out = 60*60\n",
    "time_per_neuron_refinement = 1\n",
    "time_per_icnn_refinement = 30\n",
    "allow_heuristic_timeout_estimate = True\n",
    "settings = \"group_size: {}, sample_count: {}, crown_method: {}, tighten_bounds: {}, time_out: {}, time_per_neuron_refinement: {}, time_per_icnn_refinement: {}, allow_heuristic_timeout_estimate: {}\".format(\n",
    "    group_size, sample_count, crown_method, tighten_bounds, time_out, time_per_neuron_refinement, time_per_icnn_refinement, allow_heuristic_timeout_estimate)\n",
    "\n",
    "create_csv_file(csv_file_path, settings)\n",
    "\n",
    "for num, vnnlib_path in enumerate(sorted(os.listdir(vnnlib_dir_path))):\n",
    "        \n",
    "    if num == 50:\n",
    "        break\n",
    "        \n",
    "    print(\"{} ================================================\".format(num))\n",
    "    \n",
    "    full_path = vnnlib_dir_path + \"/\" + vnnlib_path\n",
    "    input_bounds = load_vnnlib_bounds(full_path, [784,], 10)\n",
    "    model = onnx_to_bounded_model(onnx_path, [1,1,1,784])\n",
    "    image, label = training_data[num]\n",
    "    x, center = load_vnnlib_spec_for_auto_lirpa(full_path, [1,1,1,784], 10)\n",
    "    \n",
    "    if not check_if_image_is_labeled_correctly(nn, image, label):\n",
    "        print(\"skipped because wrong classification from the network\")\n",
    "        \n",
    "        new_row = [vnnlib_path, \"wrong classification\"]\n",
    "        with open(csv_file_path, 'a', newline='') as file_obj:\n",
    "            writer_object = csv.writer(file_obj)\n",
    "         \n",
    "            writer_object.writerow(new_row)\n",
    "            file_obj.close()\n",
    "            \n",
    "            \n",
    "        continue\n",
    "    \n",
    "    if check_if_auto_lirpa_already_verifies(x, 10, label, method=crown_method):\n",
    "        print(\"skipped because auto lirpa already verified\")\n",
    "        \n",
    "        new_row = [vnnlib_path, \"lirpa classified\"]\n",
    "        with open(csv_file_path, 'a', newline='') as file_obj:\n",
    "            writer_object = csv.writer(file_obj)\n",
    "         \n",
    "            writer_object.writerow(new_row)\n",
    "            file_obj.close()\n",
    "            \n",
    "        continue\n",
    "    \n",
    "    overall_time = time.time()\n",
    "    \n",
    "    bounds_affine_out, bounds_layer_out = get_bounds_auto_lirpa(x, model, method=crown_method)\n",
    "    sampling_strategy = PerGroupLineSearchSamplingStrategy(center, input_bounds, nn, sample_count=sample_count)\n",
    "    net_size = [5, 1]\n",
    "    #icnn_factory = ICNNFactory(\"approx_max\", net_size, maximum_function=\"SMU\", function_parameter=0.3)\n",
    "    icnn_factory = ICNNFactory(\"logical\", net_size, always_use_logical_layer=False)\n",
    "    #icnn_factory = ICNNFactory(\"standard\", net_size, adapt_layer_for_init=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    dhov_verifier = multidhov.MultiDHOV()\n",
    "    with open(os.devnull, \"w\") as f: # , contextlib.redirect_stdout(f):\n",
    "            return_without_time_out = dhov_verifier.start_verification(nn, center, icnn_factory, group_size, input_bounds, sampling_strategy, \n",
    "                                                                    init_affine_bounds=bounds_affine_out, \n",
    "                                                                    init_layer_bounds=bounds_layer_out, \n",
    "                                                                    skip_last_layer=True,\n",
    "                                                                    icnn_epochs=200, \n",
    "                                                                    icnn_batch_size=10000, \n",
    "                                                                    use_over_approximation=True, \n",
    "                                                                    tighten_bounds=tighten_bounds, \n",
    "                                                                    use_fixed_neurons_in_grouping=False, \n",
    "                                                                    layers_as_snr=[], \n",
    "                                                                    layers_as_milp=[8], \n",
    "                                                                    force_inclusion_steps=3, \n",
    "                                                                    preemptive_stop=True, \n",
    "                                                                    grouping_method=\"consecutive\", \n",
    "                                                                    group_num_multiplier=5,\n",
    "                                                                    optimizer=\"SdLBFGS\", \n",
    "                                                                    init_network=True, \n",
    "                                                                    adapt_lambda=\"included\",\n",
    "                                                                    encode_icnn_enlargement_as_lp=False, \n",
    "                                                                    encode_relu_enlargement_as_lp=False,\n",
    "                                                                    time_out=time_out,\n",
    "                                                                    time_per_neuron_refinement=time_per_neuron_refinement,\n",
    "                                                                    time_per_icnn_refinement=time_per_icnn_refinement,\n",
    "                                                                    allow_heuristic_timeout_estimate=allow_heuristic_timeout_estimate,\n",
    "                                                                    break_after=None, print_training_loss=False, print_new_bounds=False, store_samples=False, print_optimization_steps=False, print_last_loss=False)\n",
    "    \n",
    "    if not return_without_time_out:\n",
    "        new_row = [vnnlib_path, \"time_out of DHOV\", \"-\", time.time() - overall_time, False]\n",
    "        with open(csv_file_path, 'a', newline='') as file_obj:\n",
    "            writer_object = csv.writer(file_obj)\n",
    "         \n",
    "            writer_object.writerow(new_row)\n",
    "            file_obj.close()\n",
    "        continue\n",
    "        \n",
    "    dhov_model = dhov_verifier.nn_encoding_model.copy()\n",
    "    dhov_model.setParam(grp.GRB.Param.Threads, cpu_core_count)\n",
    "    dhov_model.update()\n",
    "    dhov_out_vars = get_output_vars_dhov(dhov_model, output_size, number_layer)\n",
    "    \n",
    "    add_output_constraints(dhov_model, dhov_verifier.bounds_layer_out, label, dhov_out_vars)\n",
    "    \n",
    "    optimize_model(dhov_model, dhov_out_vars, overall_time, verbose=False, csv_to_write_to=csv_file_path, csv_row_name=vnnlib_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T21:43:17.226804698Z",
     "start_time": "2024-05-09T21:39:14.144086118Z"
    }
   },
   "id": "f62c64884d022034",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"done\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-04T12:38:32.613032644Z"
    }
   },
   "id": "a444d3433f05a154"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
