{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from script.NeuralNets.Networks import SequentialNN, ICNN, ICNNApproxMax, ICNNLogical\n",
    "from script.settings import device, data_type\n",
    "import script.DHOV.MultiDHOV as multidhov\n",
    "from script.Verification.Verifier import SingleNeuronVerifier, MILPVerifier, DHOVVerifier\n",
    "import gurobipy as grp\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from script.NeuralNets.ICNNFactory import ICNNFactory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def add_max_constr(model, neuron_name):\n",
    "    neuron_var = model.getVarByName(neuron_name)\n",
    "    model.setObjective(neuron_var, grp.GRB.MAXIMIZE)\n",
    "\n",
    "def add_min_constr(model, neuron):\n",
    "    neuron_var = model.getVarByName(neuron)\n",
    "    model.setObjective(neuron_var, grp.GRB.MINIMIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def optimize_model(model, neuron_name):\n",
    "    model.update()\n",
    "    model.optimize()\n",
    "    if model.Status == grp.GRB.OPTIMAL:\n",
    "        print(\"opt value: {}\".format(model.getVarByName(neuron_name).getAttr(\"x\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def icnn_model(icnn, nn, input_x, eps, layer_index, from_neuron, to_neuron, print_log=False):\n",
    "    m = grp.Model()\n",
    "    if not print_log:\n",
    "        m.Params.LogToConsole = 0\n",
    "\n",
    "    input_flattened = torch.flatten(input_x)\n",
    "    bounds_affine_out, bounds_layer_out = nn.calculate_box_bounds(\n",
    "        [input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "\n",
    "    parameter_list = list(nn.parameters())\n",
    "\n",
    "    input_size = len(parameter_list[2*layer_index])\n",
    "    lb = bounds_layer_out[layer_index][0].detach().cpu().numpy()\n",
    "    ub = bounds_layer_out[layer_index][1].detach().cpu().numpy()\n",
    "    in_var = m.addMVar(input_size, lb=lb, ub=ub, name=\"icnn_var\")\n",
    "\n",
    "    low = bounds_layer_out[layer_index][0][from_neuron: to_neuron]\n",
    "    up = bounds_layer_out[layer_index][1][from_neuron: to_neuron]\n",
    "    constraint_bounds_affine_out, constraint_bounds_layer_out = icnn.calculate_box_bounds([low, up])\n",
    "    icnn.add_max_output_constraints(m, in_var[from_neuron: to_neuron], constraint_bounds_affine_out, constraint_bounds_layer_out)\n",
    "\n",
    "    return m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\"\"\"W1 = [1. 1.; 1. -1.]\n",
    "    b1 = [0., 0.]\n",
    "    W2 = [1. 1.; 1. -1.]\n",
    "    b2 = [-0.5, 0.]\n",
    "    W3 = [-1. 1.; 1. 1.]\n",
    "    b3 = [3., 0.] \"\"\"\n",
    "\n",
    "\"\"\"nn = SequentialNN([2, 2, 2, 2])\n",
    "\n",
    "with torch.no_grad():\n",
    "    parameter_list = list(nn.parameters())\n",
    "    parameter_list[0].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[1].data = torch.tensor([0, 0], dtype=data_type).to(device)\n",
    "    parameter_list[2].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[3].data = torch.tensor([-0.5, 0], dtype=data_type).to(device)\n",
    "    parameter_list[4].data = torch.tensor([[-1, 1], [1, 1]], dtype=data_type).to(device)\n",
    "    parameter_list[5].data = torch.tensor([3, 0], dtype=data_type).to(device)\n",
    "\n",
    "test_image = torch.tensor([[0, 0]], dtype=data_type).to(device)\"\"\"\n",
    "\n",
    "transform = Compose([ToTensor(),\n",
    "                         Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "                        )\n",
    "\n",
    "training_data = CIFAR10(root=\"../../cifar\", train=True, download=True, transform=transform)\n",
    "images, labels = training_data.__getitem__(0)\n",
    "test_image, test_label = torch.unsqueeze(images, 0).to(dtype=data_type).to(device), torch.unsqueeze(\n",
    "    torch.tensor(labels), 0).to(dtype=data_type).to(device)\n",
    "\n",
    "nn = SequentialNN([32 * 32 * 3, 1024, 512, 10])\n",
    "nn.load_state_dict(torch.load(\"../../cifar_fc.pth\", map_location=torch.device(device)), strict=False)\n",
    "parameter_list = list(nn.parameters())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "eps = 0.01\n",
    "layer_index = 1\n",
    "neuron_index = 0\n",
    "neuron_name = \"relu_var{}[{}]\".format(2*layer_index, neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for SNV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-11-12\n"
     ]
    }
   ],
   "source": [
    "snv_verifier = SingleNeuronVerifier(nn, test_image, eps, print_log=False)\n",
    "snv_verifier.generate_constraints_for_net()\n",
    "snv_model = snv_verifier.model\n",
    "snv_model.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "snv_copy = snv_model.copy()\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "add_min_constr(snv_copy, neuron_name)\n",
    "optimize_model(snv_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 1.279494932358921\n"
     ]
    }
   ],
   "source": [
    "snv_copy = snv_model.copy()\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "add_max_constr(snv_copy, neuron_name)\n",
    "optimize_model(snv_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for MILP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "milp_verifier = MILPVerifier(nn, test_image, eps, print_log=False)\n",
    "milp_verifier.generate_constraints_for_net(until_layer_neuron=[1,0])\n",
    "milp_model = milp_verifier.model\n",
    "milp_model.update()\n",
    "\n",
    "\"\"\"all_var = milp_model.getVars()\n",
    "for var in all_var:\n",
    "    print(var)\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "milp_copy = milp_model.copy()\n",
    "milp_copy.Params.LogToConsole = 1\n",
    "add_min_constr(milp_copy, neuron_name)\n",
    "optimize_model(milp_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "milp_copy = milp_model.copy()\n",
    "milp_copy.Params.LogToConsole = 1\n",
    "add_max_constr(milp_copy, neuron_name)\n",
    "optimize_model(milp_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for DHOV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "approximation of layer: 0\n",
      "    number of fixed neurons for current layer: 571\n",
      "    layer progress, group 1 of 151 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ufuk\\Documents\\Programming\\ICNN_verification\\script\\Optimizer\\sdlbfgs.py:83: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1420.)\n",
      "  p.data.add_(step_size, update[offset:offset + numel].view_as(p.data))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time for training: 3.0272462368011475\n",
      "        actual verification time 0.07059526443481445\n",
      "        time for verification: 0.13103437423706055\n",
      "    layer progress, group 2 of 151 \n",
      "        time for training: 2.8659238815307617\n",
      "        actual verification time 0.07064962387084961\n",
      "        time for verification: 0.1311168670654297\n",
      "    layer progress, group 3 of 151 \n",
      "        time for training: 2.9476892948150635\n",
      "        actual verification time 0.050406455993652344\n",
      "        time for verification: 0.10087132453918457\n",
      "    layer progress, group 4 of 151 \n",
      "        time for training: 2.80519437789917\n",
      "        actual verification time 0.07060742378234863\n",
      "        time for verification: 0.13116168975830078\n",
      "    layer progress, group 5 of 151 \n",
      "        time for training: 2.774810314178467\n",
      "        actual verification time 0.0625753402709961\n",
      "        time for verification: 0.11305022239685059\n",
      "    layer progress, group 6 of 151 \n",
      "        time for training: 2.8360042572021484\n",
      "        actual verification time 0.08274245262145996\n",
      "        time for verification: 0.1513066291809082\n",
      "    layer progress, group 7 of 151 \n",
      "        time for training: 2.7441718578338623\n",
      "        actual verification time 0.0625910758972168\n",
      "        time for verification: 0.11099052429199219\n",
      "    layer progress, group 8 of 151 \n",
      "        time for training: 2.755657196044922\n",
      "        actual verification time 0.06055045127868652\n",
      "        time for verification: 0.10093116760253906\n",
      "    layer progress, group 9 of 151 \n",
      "        time for training: 2.8851611614227295\n",
      "        actual verification time 0.06276512145996094\n",
      "        time for verification: 0.1352095603942871\n",
      "    layer progress, group 10 of 151 \n",
      "        time for training: 3.0856544971466064\n",
      "        actual verification time 0.07064652442932129\n",
      "        time for verification: 0.1130983829498291\n",
      "    layer progress, group 11 of 151 \n",
      "        time for training: 2.694190502166748\n",
      "        actual verification time 0.08072614669799805\n",
      "        time for verification: 0.1291360855102539\n",
      "    layer progress, group 12 of 151 \n",
      "        time for training: 2.7672388553619385\n",
      "        actual verification time 0.07067275047302246\n",
      "        time for verification: 0.11105084419250488\n",
      "    layer progress, group 13 of 151 \n",
      "        time for training: 2.794722318649292\n",
      "        actual verification time 0.0786750316619873\n",
      "        time for verification: 0.12909793853759766\n",
      "    layer progress, group 14 of 151 \n",
      "        time for training: 2.7760231494903564\n",
      "        actual verification time 0.10083532333374023\n",
      "        time for verification: 0.1533060073852539\n",
      "    layer progress, group 15 of 151 \n",
      "        time for training: 2.8237223625183105\n",
      "        actual verification time 0.05047726631164551\n",
      "        time for verification: 0.11302924156188965\n",
      "    layer progress, group 16 of 151 \n",
      "        time for training: 2.8662614822387695\n",
      "        actual verification time 0.0706174373626709\n",
      "        time for verification: 0.13112926483154297\n",
      "    layer progress, group 17 of 151 \n",
      "        time for training: 2.733924627304077\n",
      "        actual verification time 0.052454233169555664\n",
      "        time for verification: 0.12102341651916504\n",
      "    layer progress, group 18 of 151 \n",
      "        time for training: 2.80556058883667\n",
      "        actual verification time 0.0705711841583252\n",
      "        time for verification: 0.12912440299987793\n",
      "    layer progress, group 19 of 151 \n",
      "        time for training: 2.786456346511841\n",
      "        actual verification time 0.056061506271362305\n",
      "        time for verification: 0.11452078819274902\n",
      "    layer progress, group 20 of 151 \n",
      "        time for training: 2.9921934604644775\n",
      "        actual verification time 0.050405263900756836\n",
      "        time for verification: 0.11089611053466797\n",
      "    layer progress, group 21 of 151 \n",
      "        time for training: 3.3158366680145264\n",
      "        actual verification time 0.07067036628723145\n",
      "        time for verification: 0.12115287780761719\n",
      "    layer progress, group 22 of 151 \n",
      "        time for training: 3.0050761699676514\n",
      "        actual verification time 0.05851125717163086\n",
      "        time for verification: 0.12903571128845215\n",
      "    layer progress, group 23 of 151 \n",
      "        time for training: 2.898144483566284\n",
      "        actual verification time 0.08277726173400879\n",
      "        time for verification: 0.14126968383789062\n",
      "    layer progress, group 24 of 151 \n",
      "        time for training: 3.0644073486328125\n",
      "        actual verification time 0.06049537658691406\n",
      "        time for verification: 0.1240243911743164\n",
      "    layer progress, group 25 of 151 \n",
      "        time for training: 2.883665084838867\n",
      "        actual verification time 0.0506291389465332\n",
      "        time for verification: 0.10104632377624512\n",
      "    layer progress, group 26 of 151 \n",
      "        time for training: 2.7959768772125244\n",
      "        actual verification time 0.08073973655700684\n",
      "        time for verification: 0.16130995750427246\n",
      "    layer progress, group 27 of 151 \n",
      "        time for training: 2.8948750495910645\n",
      "        actual verification time 0.07063746452331543\n",
      "        time for verification: 0.12110185623168945\n",
      "    layer progress, group 28 of 151 \n",
      "        time for training: 2.881991147994995\n",
      "        actual verification time 0.07264566421508789\n",
      "        time for verification: 0.12312674522399902\n",
      "    layer progress, group 29 of 151 \n",
      "        time for training: 2.9549717903137207\n",
      "        actual verification time 0.06852531433105469\n",
      "        time for verification: 0.13106250762939453\n",
      "    layer progress, group 30 of 151 \n",
      "        time for training: 2.716203451156616\n",
      "        actual verification time 0.08073639869689941\n",
      "        time for verification: 0.14126253128051758\n",
      "    layer progress, group 31 of 151 \n",
      "        time for training: 3.1502156257629395\n",
      "        actual verification time 0.06278753280639648\n",
      "        time for verification: 0.12151813507080078\n",
      "    layer progress, group 32 of 151 \n",
      "        time for training: 3.4171669483184814\n",
      "        actual verification time 0.08081674575805664\n",
      "        time for verification: 0.14140105247497559\n",
      "    layer progress, group 33 of 151 \n",
      "        time for training: 3.850571393966675\n",
      "        actual verification time 0.0889120101928711\n",
      "        time for verification: 0.17989802360534668\n",
      "    layer progress, group 34 of 151 \n",
      "        time for training: 4.105395317077637\n",
      "        actual verification time 0.07277750968933105\n",
      "        time for verification: 0.15146231651306152\n",
      "    layer progress, group 35 of 151 \n",
      "        time for training: 3.8316702842712402\n",
      "        actual verification time 0.08100652694702148\n",
      "        time for verification: 0.1620786190032959\n",
      "    layer progress, group 36 of 151 \n",
      "        time for training: 3.818068027496338\n",
      "        actual verification time 0.14139580726623535\n",
      "        time for verification: 0.21208810806274414\n",
      "    layer progress, group 37 of 151 \n",
      "        time for training: 3.7890512943267822\n",
      "        actual verification time 0.10134077072143555\n",
      "        time for verification: 0.21254730224609375\n",
      "    layer progress, group 38 of 151 \n",
      "        time for training: 4.023608207702637\n",
      "        actual verification time 0.07085251808166504\n",
      "        time for verification: 0.1597461700439453\n",
      "    layer progress, group 39 of 151 \n",
      "        time for training: 3.7197728157043457\n",
      "        actual verification time 0.09097552299499512\n",
      "        time for verification: 0.16170716285705566\n",
      "    layer progress, group 40 of 151 \n",
      "        time for training: 3.516923666000366\n",
      "        actual verification time 0.08299040794372559\n",
      "        time for verification: 0.16170811653137207\n",
      "    layer progress, group 41 of 151 \n",
      "        time for training: 3.565333604812622\n",
      "        actual verification time 0.12121891975402832\n",
      "        time for verification: 0.1939525604248047\n",
      "    layer progress, group 42 of 151 \n",
      "        time for training: 3.5338945388793945\n",
      "        actual verification time 0.05058693885803223\n",
      "        time for verification: 0.12343311309814453\n",
      "    layer progress, group 43 of 151 \n",
      "        time for training: 3.535682201385498\n",
      "        actual verification time 0.0627126693725586\n",
      "        time for verification: 0.139420747756958\n",
      "    layer progress, group 44 of 151 \n",
      "        time for training: 3.5680339336395264\n",
      "        actual verification time 0.10106706619262695\n",
      "        time for verification: 0.17976021766662598\n",
      "    layer progress, group 45 of 151 \n",
      "        time for training: 3.5790374279022217\n",
      "        actual verification time 0.07063984870910645\n",
      "        time for verification: 0.13931632041931152\n",
      "    layer progress, group 46 of 151 \n",
      "        time for training: 3.609083890914917\n",
      "        actual verification time 0.07071828842163086\n",
      "        time for verification: 0.14137864112854004\n",
      "    layer progress, group 47 of 151 \n",
      "        time for training: 3.5426063537597656\n",
      "        actual verification time 0.060628414154052734\n",
      "        time for verification: 0.12324357032775879\n",
      "    layer progress, group 48 of 151 \n",
      "        time for training: 3.5228662490844727\n",
      "        actual verification time 0.12132000923156738\n",
      "        time for verification: 0.19199466705322266\n",
      "    layer progress, group 49 of 151 \n",
      "        time for training: 3.5032544136047363\n",
      "        actual verification time 0.08084678649902344\n",
      "        time for verification: 0.15367794036865234\n",
      "    layer progress, group 50 of 151 \n",
      "        time for training: 3.5961835384368896\n",
      "        actual verification time 0.1191866397857666\n",
      "        time for verification: 0.18989348411560059\n",
      "    layer progress, group 51 of 151 \n",
      "        time for training: 3.4184939861297607\n",
      "        actual verification time 0.1030721664428711\n",
      "        time for verification: 0.1817941665649414\n",
      "    layer progress, group 52 of 151 \n",
      "        time for training: 3.4948790073394775\n",
      "        actual verification time 0.06056952476501465\n",
      "        time for verification: 0.13127470016479492\n",
      "    layer progress, group 53 of 151 \n",
      "        time for training: 3.625638008117676\n",
      "        actual verification time 0.07080578804016113\n",
      "        time for verification: 0.15369105339050293\n",
      "    layer progress, group 54 of 151 \n",
      "        time for training: 3.6566476821899414\n",
      "        actual verification time 0.08292531967163086\n",
      "        time for verification: 0.1616227626800537\n",
      "    layer progress, group 55 of 151 \n",
      "        time for training: 3.5661802291870117\n",
      "        actual verification time 0.09297752380371094\n",
      "        time for verification: 0.1818392276763916\n",
      "    layer progress, group 56 of 151 \n",
      "        time for training: 3.496173143386841\n",
      "        actual verification time 0.10305476188659668\n",
      "        time for verification: 0.17174720764160156\n",
      "    layer progress, group 57 of 151 \n",
      "        time for training: 3.5560882091522217\n",
      "        actual verification time 0.11114859580993652\n",
      "        time for verification: 0.17181754112243652\n",
      "    layer progress, group 58 of 151 \n",
      "        time for training: 3.516155481338501\n",
      "        actual verification time 0.07365894317626953\n",
      "        time for verification: 0.1353285312652588\n",
      "    layer progress, group 59 of 151 \n",
      "        time for training: 3.4728362560272217\n",
      "        actual verification time 0.06270694732666016\n",
      "        time for verification: 0.12130618095397949\n",
      "    layer progress, group 60 of 151 \n",
      "        time for training: 3.6569983959198\n",
      "        actual verification time 0.09900379180908203\n",
      "        time for verification: 0.172088623046875\n",
      "    layer progress, group 61 of 151 \n",
      "        time for training: 3.5349819660186768\n",
      "        actual verification time 0.08086109161376953\n",
      "        time for verification: 0.14348554611206055\n",
      "    layer progress, group 62 of 151 \n",
      "        time for training: 3.819965124130249\n",
      "        actual verification time 0.10779857635498047\n",
      "        time for verification: 0.20897293090820312\n",
      "    layer progress, group 63 of 151 \n",
      "        time for training: 3.651747941970825\n",
      "        actual verification time 0.07070803642272949\n",
      "        time for verification: 0.14145207405090332\n",
      "    layer progress, group 64 of 151 \n",
      "        time for training: 3.5170772075653076\n",
      "        actual verification time 0.10099530220031738\n",
      "        time for verification: 0.16162610054016113\n",
      "    layer progress, group 65 of 151 \n",
      "        time for training: 3.57705020904541\n",
      "        actual verification time 0.08086037635803223\n",
      "        time for verification: 0.1495044231414795\n",
      "    layer progress, group 66 of 151 \n",
      "        time for training: 3.6496293544769287\n",
      "        actual verification time 0.07075929641723633\n",
      "        time for verification: 0.1414964199066162\n",
      "    layer progress, group 67 of 151 \n",
      "        time for training: 3.4266560077667236\n",
      "        actual verification time 0.08291125297546387\n",
      "        time for verification: 0.1515500545501709\n",
      "    layer progress, group 68 of 151 \n",
      "        time for training: 3.6573169231414795\n",
      "        actual verification time 0.08086585998535156\n",
      "        time for verification: 0.14140057563781738\n",
      "    layer progress, group 69 of 151 \n",
      "        time for training: 3.6157124042510986\n",
      "        actual verification time 0.0707695484161377\n",
      "        time for verification: 0.14142394065856934\n",
      "    layer progress, group 70 of 151 \n",
      "        time for training: 3.5567336082458496\n",
      "        actual verification time 0.06260919570922852\n",
      "        time for verification: 0.13126087188720703\n",
      "    layer progress, group 71 of 151 \n",
      "        time for training: 3.475945234298706\n",
      "        actual verification time 0.08078622817993164\n",
      "        time for verification: 0.16160368919372559\n",
      "    layer progress, group 72 of 151 \n",
      "        time for training: 3.589076042175293\n",
      "        actual verification time 0.10114932060241699\n",
      "        time for verification: 0.17194032669067383\n",
      "    layer progress, group 73 of 151 \n",
      "        time for training: 3.5570175647735596\n",
      "        actual verification time 0.07279229164123535\n",
      "        time for verification: 0.13144922256469727\n",
      "    layer progress, group 74 of 151 \n",
      "        time for training: 3.3962697982788086\n",
      "        actual verification time 0.10101842880249023\n",
      "        time for verification: 0.16160154342651367\n",
      "    layer progress, group 75 of 151 \n",
      "        time for training: 3.5366010665893555\n",
      "        actual verification time 0.07072925567626953\n",
      "        time for verification: 0.14949750900268555\n",
      "    layer progress, group 76 of 151 \n",
      "        time for training: 3.5701637268066406\n",
      "        actual verification time 0.09093022346496582\n",
      "        time for verification: 0.1616349220275879\n",
      "    layer progress, group 77 of 151 \n",
      "        time for training: 3.497704029083252\n",
      "        actual verification time 0.10308480262756348\n",
      "        time for verification: 0.17187285423278809\n",
      "    layer progress, group 78 of 151 \n",
      "        time for training: 3.5991508960723877\n",
      "        actual verification time 0.05856966972351074\n",
      "        time for verification: 0.12926816940307617\n",
      "    layer progress, group 79 of 151 \n",
      "        time for training: 3.4179537296295166\n",
      "        actual verification time 0.12125682830810547\n",
      "        time for verification: 0.1921532154083252\n",
      "    layer progress, group 80 of 151 \n",
      "        time for training: 3.53680419921875\n",
      "        actual verification time 0.0908348560333252\n",
      "        time for verification: 0.1513969898223877\n",
      "    layer progress, group 81 of 151 \n",
      "        time for training: 3.820591688156128\n",
      "        actual verification time 0.10100913047790527\n",
      "        time for verification: 0.17168641090393066\n",
      "    layer progress, group 82 of 151 \n",
      "        time for training: 3.637699604034424\n",
      "        actual verification time 0.10104846954345703\n",
      "        time for verification: 0.17160844802856445\n",
      "    layer progress, group 83 of 151 \n",
      "        time for training: 3.4354376792907715\n",
      "        actual verification time 0.09602546691894531\n",
      "        time for verification: 0.16676902770996094\n",
      "    layer progress, group 84 of 151 \n",
      "        time for training: 3.560807943344116\n",
      "        actual verification time 0.06057024002075195\n",
      "        time for verification: 0.1314387321472168\n",
      "    layer progress, group 85 of 151 \n",
      "        time for training: 3.516279458999634\n",
      "        actual verification time 0.07275009155273438\n",
      "        time for verification: 0.14950275421142578\n",
      "    layer progress, group 86 of 151 \n",
      "        time for training: 3.5987181663513184\n",
      "        actual verification time 0.1010894775390625\n",
      "        time for verification: 0.16171860694885254\n",
      "    layer progress, group 87 of 151 \n",
      "        time for training: 3.648059129714966\n",
      "        actual verification time 0.11118698120117188\n",
      "        time for verification: 0.17177414894104004\n",
      "    layer progress, group 88 of 151 \n",
      "        time for training: 4.074091672897339\n",
      "        actual verification time 0.10105586051940918\n",
      "        time for verification: 0.171952486038208\n",
      "    layer progress, group 89 of 151 \n",
      "        time for training: 3.862095594406128\n",
      "        actual verification time 0.09905362129211426\n",
      "        time for verification: 0.16974735260009766\n",
      "    layer progress, group 90 of 151 \n",
      "        time for training: 3.4883666038513184\n",
      "        actual verification time 0.12127089500427246\n",
      "        time for verification: 0.19199323654174805\n",
      "    layer progress, group 91 of 151 \n",
      "        time for training: 3.526912212371826\n",
      "        actual verification time 0.13139796257019043\n",
      "        time for verification: 0.2000119686126709\n",
      "    layer progress, group 92 of 151 \n",
      "        time for training: 3.547961950302124\n",
      "        actual verification time 0.09099769592285156\n",
      "        time for verification: 0.1516571044921875\n",
      "    layer progress, group 93 of 151 \n",
      "        time for training: 3.678396701812744\n",
      "        actual verification time 0.09310126304626465\n",
      "        time for verification: 0.1718292236328125\n",
      "    layer progress, group 94 of 151 \n",
      "        time for training: 3.467050552368164\n",
      "        actual verification time 0.11109590530395508\n",
      "        time for verification: 0.19195270538330078\n",
      "    layer progress, group 95 of 151 \n",
      "        time for training: 3.476820707321167\n",
      "        actual verification time 0.04242229461669922\n",
      "        time for verification: 0.10098838806152344\n",
      "    layer progress, group 96 of 151 \n",
      "        time for training: 3.4453117847442627\n",
      "        actual verification time 0.0727853775024414\n",
      "        time for verification: 0.15159821510314941\n",
      "    layer progress, group 97 of 151 \n",
      "        time for training: 3.9481115341186523\n",
      "        actual verification time 0.1112065315246582\n",
      "        time for verification: 0.19408679008483887\n",
      "    layer progress, group 98 of 151 \n",
      "        time for training: 3.4955949783325195\n",
      "        actual verification time 0.1515960693359375\n",
      "        time for verification: 0.22228407859802246\n",
      "    layer progress, group 99 of 151 \n",
      "        time for training: 3.4755871295928955\n",
      "        actual verification time 0.08312869071960449\n",
      "        time for verification: 0.2932779788970947\n",
      "    layer progress, group 100 of 151 \n",
      "        time for training: 3.4555552005767822\n",
      "        actual verification time 0.07068133354187012\n",
      "        time for verification: 0.13135623931884766\n",
      "    layer progress, group 101 of 151 \n",
      "        time for training: 3.604551315307617\n",
      "        actual verification time 0.050539255142211914\n",
      "        time for verification: 0.11332392692565918\n",
      "    layer progress, group 102 of 151 \n",
      "        time for training: 3.3663103580474854\n",
      "        actual verification time 0.06261181831359863\n",
      "        time for verification: 0.13124799728393555\n",
      "    layer progress, group 103 of 151 \n",
      "        time for training: 3.525017499923706\n",
      "        actual verification time 0.07071948051452637\n",
      "        time for verification: 0.13134217262268066\n",
      "    layer progress, group 104 of 151 \n",
      "        time for training: 3.47493052482605\n",
      "        actual verification time 0.08087038993835449\n",
      "        time for verification: 0.14350175857543945\n",
      "    layer progress, group 105 of 151 \n",
      "        time for training: 3.506455898284912\n",
      "        actual verification time 0.07920145988464355\n",
      "        time for verification: 0.13991546630859375\n",
      "    layer progress, group 106 of 151 \n",
      "        time for training: 3.588531732559204\n",
      "        actual verification time 0.06064200401306152\n",
      "        time for verification: 0.14145421981811523\n",
      "    layer progress, group 107 of 151 \n",
      "        time for training: 4.186564922332764\n",
      "        actual verification time 0.08085894584655762\n",
      "        time for verification: 0.14166569709777832\n",
      "    layer progress, group 108 of 151 \n",
      "        time for training: 3.5041463375091553\n",
      "        actual verification time 0.05052542686462402\n",
      "        time for verification: 0.1213376522064209\n",
      "    layer progress, group 109 of 151 \n",
      "        time for training: 3.4282052516937256\n",
      "        actual verification time 0.08287882804870605\n",
      "        time for verification: 0.15950989723205566\n",
      "    layer progress, group 110 of 151 \n",
      "        time for training: 3.497997522354126\n",
      "        actual verification time 0.09902453422546387\n",
      "        time for verification: 0.17190265655517578\n",
      "    layer progress, group 111 of 151 \n",
      "        time for training: 3.4867308139801025\n",
      "        actual verification time 0.0728464126586914\n",
      "        time for verification: 0.1336514949798584\n",
      "    layer progress, group 112 of 151 \n",
      "        time for training: 3.6082065105438232\n",
      "        actual verification time 0.09092831611633301\n",
      "        time for verification: 0.151566743850708\n",
      "    layer progress, group 113 of 151 \n",
      "        time for training: 3.4476375579833984\n",
      "        actual verification time 0.07066535949707031\n",
      "        time for verification: 0.14133429527282715\n",
      "    layer progress, group 114 of 151 \n",
      "        time for training: 3.6156415939331055\n",
      "        actual verification time 0.13929271697998047\n",
      "        time for verification: 0.21204781532287598\n",
      "    layer progress, group 115 of 151 \n",
      "        time for training: 3.194997787475586\n",
      "        actual verification time 0.06058239936828613\n",
      "        time for verification: 0.13125300407409668\n",
      "    layer progress, group 116 of 151 \n",
      "        time for training: 3.5977609157562256\n",
      "        actual verification time 0.08089518547058105\n",
      "        time for verification: 0.16179823875427246\n",
      "    layer progress, group 117 of 151 \n",
      "        time for training: 3.526313066482544\n",
      "        actual verification time 0.052613019943237305\n",
      "        time for verification: 0.12149238586425781\n",
      "    layer progress, group 118 of 151 \n",
      "        time for training: 3.566621780395508\n",
      "        actual verification time 0.060715675354003906\n",
      "        time for verification: 0.14152312278747559\n",
      "    layer progress, group 119 of 151 \n",
      "        time for training: 3.4948723316192627\n",
      "        actual verification time 0.09911656379699707\n",
      "        time for verification: 0.17184948921203613\n",
      "    layer progress, group 120 of 151 \n",
      "        time for training: 3.517812490463257\n",
      "        actual verification time 0.09108138084411621\n",
      "        time for verification: 0.1718904972076416\n",
      "    layer progress, group 121 of 151 \n",
      "        time for training: 3.6068739891052246\n",
      "        actual verification time 0.05255627632141113\n",
      "        time for verification: 0.1313028335571289\n",
      "    layer progress, group 122 of 151 \n",
      "        time for training: 3.496633768081665\n",
      "        actual verification time 0.08896064758300781\n",
      "        time for verification: 0.1495218276977539\n",
      "    layer progress, group 123 of 151 \n",
      "        time for training: 3.539527416229248\n",
      "        actual verification time 0.0812678337097168\n",
      "        time for verification: 0.14996337890625\n",
      "    layer progress, group 124 of 151 \n",
      "        time for training: 3.6601812839508057\n",
      "        actual verification time 0.0687558650970459\n",
      "        time for verification: 0.14955615997314453\n",
      "    layer progress, group 125 of 151 \n",
      "        time for training: 3.966458797454834\n",
      "        actual verification time 0.09320735931396484\n",
      "        time for verification: 0.18413662910461426\n",
      "    layer progress, group 126 of 151 \n",
      "        time for training: 3.7928271293640137\n",
      "        actual verification time 0.06068110466003418\n",
      "        time for verification: 0.13138270378112793\n",
      "    layer progress, group 127 of 151 \n",
      "        time for training: 3.4959821701049805\n",
      "        actual verification time 0.05055594444274902\n",
      "        time for verification: 0.11123180389404297\n",
      "    layer progress, group 128 of 151 \n",
      "        time for training: 3.516202926635742\n",
      "        actual verification time 0.11916399002075195\n",
      "        time for verification: 0.21007537841796875\n",
      "    layer progress, group 129 of 151 \n",
      "        time for training: 3.7019388675689697\n",
      "        actual verification time 0.07271504402160645\n",
      "        time for verification: 0.15154695510864258\n",
      "    layer progress, group 130 of 151 \n",
      "        time for training: 3.626514434814453\n",
      "        actual verification time 0.05060458183288574\n",
      "        time for verification: 0.10334014892578125\n",
      "    layer progress, group 131 of 151 \n",
      "        time for training: 3.404555559158325\n",
      "        actual verification time 0.0829167366027832\n",
      "        time for verification: 0.1435544490814209\n",
      "    layer progress, group 132 of 151 \n",
      "        time for training: 3.534851551055908\n",
      "        actual verification time 0.08082890510559082\n",
      "        time for verification: 0.14144086837768555\n",
      "    layer progress, group 133 of 151 \n",
      "        time for training: 3.5667271614074707\n",
      "        actual verification time 0.09092426300048828\n",
      "        time for verification: 0.15164828300476074\n",
      "    layer progress, group 134 of 151 \n",
      "        time for training: 3.576395034790039\n",
      "        actual verification time 0.0909426212310791\n",
      "        time for verification: 0.16967487335205078\n",
      "    layer progress, group 135 of 151 \n",
      "        time for training: 3.657012462615967\n",
      "        actual verification time 0.07281184196472168\n",
      "        time for verification: 0.14441466331481934\n",
      "    layer progress, group 136 of 151 \n",
      "        time for training: 3.39609432220459\n",
      "        actual verification time 0.09092926979064941\n",
      "        time for verification: 0.16164112091064453\n",
      "    layer progress, group 137 of 151 \n",
      "        time for training: 3.615975856781006\n",
      "        actual verification time 0.07082462310791016\n",
      "        time for verification: 0.14948248863220215\n",
      "    layer progress, group 138 of 151 \n",
      "        time for training: 3.5967304706573486\n",
      "        actual verification time 0.05857133865356445\n",
      "        time for verification: 0.13337016105651855\n",
      "    layer progress, group 139 of 151 \n",
      "        time for training: 3.5346121788024902\n",
      "        actual verification time 0.09296703338623047\n",
      "        time for verification: 0.1838383674621582\n",
      "    layer progress, group 140 of 151 \n",
      "        time for training: 3.6255650520324707\n",
      "        actual verification time 0.10108065605163574\n",
      "        time for verification: 0.16423988342285156\n",
      "    layer progress, group 141 of 151 \n",
      "        time for training: 3.5658507347106934\n",
      "        actual verification time 0.07885384559631348\n",
      "        time for verification: 0.1394665241241455\n",
      "    layer progress, group 142 of 151 \n",
      "        time for training: 3.600123405456543\n",
      "        actual verification time 0.10115528106689453\n",
      "        time for verification: 0.1617434024810791\n",
      "    layer progress, group 143 of 151 \n",
      "        time for training: 3.5065770149230957\n",
      "        actual verification time 0.08083367347717285\n",
      "        time for verification: 0.15962958335876465\n",
      "    layer progress, group 144 of 151 \n",
      "        time for training: 3.5086488723754883\n",
      "        actual verification time 0.11139869689941406\n",
      "        time for verification: 0.18228650093078613\n",
      "    layer progress, group 145 of 151 \n",
      "        time for training: 3.5561046600341797\n",
      "        actual verification time 0.1111903190612793\n",
      "        time for verification: 0.18192458152770996\n",
      "    layer progress, group 146 of 151 \n",
      "        time for training: 3.5057315826416016\n",
      "        actual verification time 0.10306453704833984\n",
      "        time for verification: 0.18182134628295898\n",
      "    layer progress, group 147 of 151 \n",
      "        time for training: 3.618093252182007\n",
      "        actual verification time 0.08889174461364746\n",
      "        time for verification: 0.15959715843200684\n",
      "    layer progress, group 148 of 151 \n",
      "        time for training: 3.4786031246185303\n",
      "        actual verification time 0.15164780616760254\n",
      "        time for verification: 0.2224123477935791\n",
      "    layer progress, group 149 of 151 \n",
      "        time for training: 3.596224546432495\n",
      "        actual verification time 0.08286881446838379\n",
      "        time for verification: 0.15161609649658203\n",
      "    layer progress, group 150 of 151 \n",
      "        time for training: 3.475703716278076\n",
      "        actual verification time 0.08899164199829102\n",
      "        time for verification: 0.1701345443725586\n",
      "    layer progress, group 151 of 151 \n",
      "        time for training: 3.68972110748291\n",
      "        actual verification time 0.07905459403991699\n",
      "        time for verification: 0.15183353424072266\n",
      "    time for icnn_bound calculation: 3.8796682357788086\n",
      "    time for regrouping method: 0.12385129928588867\n",
      "\n",
      "approximation of layer: 1\n",
      "    number of fixed neurons for current layer: 0\n",
      "    layer progress, group 1 of 171 \n",
      "        time for training: 5.789642333984375\n",
      "        actual verification time 0.2735428810119629\n",
      "        time for verification: 0.33619141578674316\n",
      "aborting because of force break\n"
     ]
    }
   ],
   "source": [
    "group_size = 3\n",
    "icnn_factory = ICNNFactory(\"logical\", [5, 1], force_positive_init=False, with_two_layers=False,\n",
    "                               init_scaling=10, init_all_with_zeros=False)\n",
    "\n",
    "icnns, all_group_indices, fixed_neuron_per_layer_lower, fixed_neuron_per_layer_upper, bounds_affine_out, bounds_layer_out = \\\n",
    "    multidhov.start_verification(nn, test_image, icnn_factory, group_size, eps=eps, icnn_epochs=100, icnn_batch_size=1000,\n",
    "                                 sample_count=1000, sample_new=False, use_over_approximation=True, break_after=152,\n",
    "                                 sample_over_input_space=False, sample_over_output_space=True, use_icnn_bounds=True, use_fixed_neurons=True,\n",
    "                                 force_inclusion_steps=0, preemptive_stop=False, even_gradient_training=False,\n",
    "                                 keep_ambient_space=True, data_grad_descent_steps=0, train_outer=False,\n",
    "                                 should_plot=\"none\", optimizer=\"SdLBFGS\", init_network=True, adapt_lambda=\"none\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(fixed_neuron_per_layer_lower)\n",
    "print(fixed_neuron_per_layer_upper)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounds affine out \n",
      " [[tensor([ 0.2088,  0.0196, -0.0026,  ..., -1.3163, -0.3677, -0.2236],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>), tensor([ 0.7791,  0.5886,  0.5620,  ..., -0.7273,  0.2118,  0.3357],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)], [tensor([-2.3678, -2.2506, -1.4631, -1.5480, -1.6997, -2.3157, -2.0312, -2.1657,\n",
      "        -2.4451, -2.1094, -2.5736, -1.5114, -1.7204, -1.6585, -1.9900, -2.2936,\n",
      "        -1.8326, -1.9801, -2.0940, -1.9852, -2.4245, -2.3254, -1.7885, -2.0473,\n",
      "        -1.7248, -2.0310, -2.1796, -1.5130, -2.1948, -1.2174, -2.3810, -1.6069,\n",
      "        -2.2250, -1.0840, -2.1734, -1.6119, -2.2030, -2.1282, -2.2584, -2.3525,\n",
      "        -1.9250, -2.2268, -1.9972, -1.8989, -2.1081, -1.8777, -2.4823, -2.0515,\n",
      "        -2.2419, -2.3808, -2.0566, -2.1669, -1.8904, -2.0341, -2.4128, -2.7350,\n",
      "        -2.8463, -1.6933, -2.4030, -2.0562, -1.9528, -2.1218, -2.4711, -2.3628,\n",
      "        -2.2642, -2.0658, -1.8225, -1.7588, -2.5546, -1.6129, -1.8245, -2.1414,\n",
      "        -1.9952, -1.9148, -2.2306, -2.0037, -2.5366, -1.4191, -2.1562, -1.9158,\n",
      "        -2.1424, -1.8178, -2.2539, -2.0352, -2.1833, -1.5824, -2.2810, -1.4759,\n",
      "        -2.3608, -1.8562, -2.4729, -2.1235, -2.2414, -1.7541, -2.2816, -2.0879,\n",
      "        -2.0146, -1.8970, -2.4248, -2.0457, -1.6711, -2.2117, -1.8608, -2.7619,\n",
      "        -1.7872, -1.3919, -1.9690, -1.9393, -2.2661, -1.6468, -2.1895, -2.1893,\n",
      "        -1.9798, -2.1747, -1.8322, -2.2181, -2.1823, -1.9345, -2.2441, -1.9113,\n",
      "        -2.1066, -2.3348, -1.8618, -2.3357, -1.8482, -2.2501, -2.1368, -1.9601,\n",
      "        -1.7689, -2.5784, -2.6144, -2.2968, -2.0713, -2.2545, -2.4273, -2.6481,\n",
      "        -1.8894, -2.2630, -1.9883, -1.8003, -1.3780, -1.8716, -2.0415, -2.0463,\n",
      "        -2.5830, -2.0505, -1.8829, -1.3248, -2.2755, -2.2885, -2.6692, -2.1592,\n",
      "        -1.9485, -1.7881, -1.9013, -2.4198, -1.8273, -1.7009, -1.7606, -1.8754,\n",
      "        -1.7755, -1.9315, -2.2627, -2.0458, -2.3787, -1.7453, -2.1708, -2.3769,\n",
      "        -1.7394, -2.0193, -1.3378, -2.1757, -1.9578, -2.4132, -2.0921, -2.1697,\n",
      "        -2.3222, -2.1388, -1.9731, -2.4500, -1.7567, -2.0712, -1.8797, -2.4587,\n",
      "        -2.4395, -2.0947, -1.4238, -1.6812, -2.0884, -2.0478, -2.1802, -2.1793,\n",
      "        -1.7242, -2.2525, -2.0815, -2.1800, -2.2343, -2.2170, -2.2868, -2.3326,\n",
      "        -2.0985, -1.9025, -2.6216, -2.6766, -2.8230, -2.0409, -1.9765, -2.5223,\n",
      "        -2.5186, -2.3216, -2.1099, -1.8069, -1.8001, -1.8937, -2.3844, -1.5554,\n",
      "        -1.7413, -1.9307, -1.7702, -2.1569, -2.5157, -1.9025, -2.8545, -2.3963,\n",
      "        -1.9962, -2.0257, -2.0677, -1.7343, -1.7432, -1.9814, -2.0761, -1.9112,\n",
      "        -1.9711, -2.5830, -1.7412, -2.0081, -1.8990, -2.3547, -1.9318, -1.6319,\n",
      "        -1.3847, -2.1291, -2.3581, -2.3676, -2.3591, -1.6119, -1.5264, -2.2582,\n",
      "        -1.9452, -2.0983, -1.5434, -2.4950, -2.3965, -2.1024, -2.1247, -2.0916,\n",
      "        -2.4071, -1.6716, -2.2409, -2.0783, -1.9700, -1.7985, -1.9317, -1.9193,\n",
      "        -2.8491, -2.1171, -2.0579, -2.2669, -1.9235, -1.8752, -2.1481, -1.7179,\n",
      "        -2.2722, -2.0011, -2.3476, -1.9064, -2.6052, -1.9573, -2.5701, -2.5449,\n",
      "        -2.2295, -2.4069, -1.8491, -1.6295, -2.2801, -2.3843, -1.8899, -2.2901,\n",
      "        -2.2081, -2.2685, -2.5606, -2.3657, -2.0694, -1.8586, -2.1898, -2.7850,\n",
      "        -2.6666, -2.2256, -1.8080, -2.3675, -2.0387, -1.7699, -1.7594, -1.9638,\n",
      "        -1.7930, -2.5955, -2.2309, -2.1528, -2.1117, -1.1386, -1.7030, -2.1813,\n",
      "        -2.1974, -2.0460, -2.0127, -2.1019, -1.7086, -1.7625, -1.2394, -1.9954,\n",
      "        -2.0407, -2.5292, -2.1938, -2.6148, -1.9193, -1.8724, -2.0353, -1.8261,\n",
      "        -1.7046, -1.8707, -1.7427, -2.3210, -2.0953, -2.0234, -1.8730, -1.9157,\n",
      "        -2.1633, -2.2956, -1.8241, -1.9183, -1.9252, -2.2855, -1.7693, -2.0694,\n",
      "        -2.2078, -2.2395, -1.8100, -1.8931, -2.4937, -1.6027, -1.7344, -2.4556,\n",
      "        -1.7214, -2.1970, -1.7753, -2.5441, -2.1143, -1.7223, -2.5505, -1.8186,\n",
      "        -2.3532, -1.9206, -2.3041, -2.0582, -1.8424, -1.8498, -2.1913, -2.2310,\n",
      "        -2.1394, -2.0301, -2.6459, -1.6225, -2.2951, -2.5787, -2.3691, -2.5596,\n",
      "        -2.5056, -2.1484, -1.7632, -2.2438, -2.3388, -2.1026, -2.3081, -1.9033,\n",
      "        -2.3444, -1.8191, -1.9034, -1.3551, -2.2204, -1.6438, -2.2685, -1.7940,\n",
      "        -1.6682, -2.2030, -2.1190, -2.3994, -2.0798, -2.8044, -1.7596, -2.6453,\n",
      "        -1.6814, -2.1698, -1.7821, -1.6353, -2.7215, -1.7791, -2.2148, -2.1106,\n",
      "        -1.8514, -2.5463, -2.1293, -1.9078, -2.0379, -2.4073, -2.1459, -2.1028,\n",
      "        -2.7059, -2.1078, -2.5884, -1.8202, -2.0828, -2.1631, -2.0025, -1.8010,\n",
      "        -1.8327, -2.1799, -1.9555, -1.9659, -2.4192, -1.6459, -1.8146, -1.9345,\n",
      "        -2.6203, -1.9685, -2.5791, -2.2627, -2.0145, -1.9692, -2.2245, -1.6481,\n",
      "        -1.9672, -2.0471, -2.0556, -2.2650, -2.1470, -2.2929, -2.2956, -1.7933,\n",
      "        -2.4848, -1.8552, -1.7189, -2.2088, -2.2806, -1.4828, -1.8546, -2.1495,\n",
      "        -2.3400, -2.2611, -1.9456, -2.0526, -2.1521, -2.4529, -1.5742, -2.0786,\n",
      "        -1.8988, -1.7005, -2.1786, -2.0611, -2.4032, -1.8272, -2.2149, -2.3349,\n",
      "        -2.3801, -2.3148, -1.7153, -2.4166, -1.9706, -2.0655, -2.4320, -1.9155,\n",
      "        -2.3920, -2.0351, -1.7001, -2.1501, -1.9242, -2.3359, -1.5724, -1.7956,\n",
      "        -2.7937, -1.9470, -2.2252, -2.0580, -2.5420, -2.0681, -1.8897, -1.9469,\n",
      "        -1.9611, -1.8518, -2.0844, -2.6111, -1.7594, -2.0141, -1.9591, -1.8939,\n",
      "        -2.2650, -1.9786, -1.4302, -2.2497, -2.2228, -2.7537, -2.2954, -2.2246],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>), tensor([2.1985, 2.2024, 3.5789, 3.2989, 3.1727, 2.7257, 3.1589, 2.9706, 2.3492,\n",
      "        2.3374, 2.2188, 3.5131, 2.9834, 3.2893, 2.7698, 2.7456, 3.0551, 2.7703,\n",
      "        2.4261, 2.7636, 2.3316, 2.5707, 3.1093, 2.7213, 3.2009, 2.8840, 2.6372,\n",
      "        3.2359, 2.7661, 3.7934, 1.9150, 3.2887, 2.6867, 3.5916, 2.4751, 3.0572,\n",
      "        2.5368, 2.8881, 2.4758, 2.3354, 2.7308, 2.2997, 2.9015, 2.8642, 2.6307,\n",
      "        2.6679, 2.1138, 2.7184, 2.5877, 2.4363, 2.8510, 2.2290, 2.7605, 2.9352,\n",
      "        2.5532, 2.4591, 2.0163, 3.2752, 2.3035, 2.7828, 2.5608, 2.5729, 2.1703,\n",
      "        2.6810, 2.4530, 2.5627, 2.7323, 3.0748, 2.3498, 3.0908, 2.9539, 2.4527,\n",
      "        2.4962, 2.8960, 2.6532, 2.6162, 2.2160, 3.6041, 3.0032, 2.8227, 2.6230,\n",
      "        3.2652, 2.3000, 2.5879, 2.6289, 3.2825, 2.4289, 3.2062, 2.0722, 2.9592,\n",
      "        2.0333, 2.4219, 2.9470, 3.5575, 2.5283, 2.6129, 2.5972, 2.9534, 2.9723,\n",
      "        2.5614, 2.8972, 2.7913, 2.9018, 1.8760, 3.3864, 3.4564, 2.7306, 3.0458,\n",
      "        2.2486, 3.0729, 2.5512, 2.5311, 2.8378, 2.2285, 3.0569, 2.5264, 2.6175,\n",
      "        2.5961, 2.5296, 2.6409, 2.6287, 2.5965, 2.9409, 2.4046, 2.7446, 2.3342,\n",
      "        2.9047, 2.5440, 3.0772, 1.9716, 2.1576, 2.7586, 2.4789, 2.6533, 2.2112,\n",
      "        1.8408, 2.9815, 2.7088, 2.7785, 2.7992, 3.3071, 3.1239, 2.4893, 3.1774,\n",
      "        2.4032, 2.8245, 2.6077, 3.3692, 2.4308, 2.2467, 1.9323, 2.7972, 2.7219,\n",
      "        3.2780, 2.9485, 1.9737, 2.9057, 3.7385, 3.2042, 2.6872, 2.8178, 2.6760,\n",
      "        2.4202, 2.7386, 2.2116, 2.8576, 3.0162, 2.2776, 3.1711, 2.4163, 3.9645,\n",
      "        2.4481, 2.7093, 2.1543, 2.6305, 2.5179, 2.1667, 2.6047, 2.6598, 2.0520,\n",
      "        3.2499, 2.4984, 3.2387, 1.9903, 2.1779, 2.6996, 3.1079, 3.0683, 2.8121,\n",
      "        2.5086, 2.6226, 2.2937, 2.8322, 2.4843, 2.4434, 2.6396, 2.6338, 2.3789,\n",
      "        2.7651, 2.4555, 2.8191, 2.7082, 1.9177, 1.8043, 2.0851, 2.5194, 2.5843,\n",
      "        2.2937, 2.0311, 2.0399, 2.4141, 2.8709, 2.6827, 3.2072, 2.4175, 2.9141,\n",
      "        2.7656, 2.7763, 2.8114, 2.5082, 1.9327, 2.6724, 2.2971, 2.3961, 2.4524,\n",
      "        2.7674, 2.5349, 3.2752, 2.6632, 2.7877, 2.4443, 2.6509, 2.4466, 2.1202,\n",
      "        2.9781, 2.3353, 2.5709, 2.1044, 2.5156, 2.9475, 3.4756, 2.5669, 2.3189,\n",
      "        2.3897, 2.2457, 3.0801, 3.5114, 2.4983, 2.5862, 2.5761, 3.1905, 2.3847,\n",
      "        2.0487, 2.6576, 2.6359, 3.1154, 2.4759, 2.8485, 3.0165, 2.8262, 2.6906,\n",
      "        2.8355, 2.7099, 2.5992, 1.6763, 2.7652, 2.6295, 2.3402, 2.8419, 2.9079,\n",
      "        2.4964, 2.8957, 2.8146, 2.8652, 2.3430, 2.9373, 1.6113, 2.4700, 1.9122,\n",
      "        2.3025, 2.5531, 2.2747, 2.6465, 2.9438, 2.1805, 2.2151, 3.0780, 2.2498,\n",
      "        2.4682, 2.1720, 1.9502, 2.3754, 3.0590, 2.9243, 2.5663, 2.1819, 1.9129,\n",
      "        2.4948, 2.9328, 2.1700, 2.6950, 2.9161, 3.1480, 2.9733, 2.6979, 1.7689,\n",
      "        2.1127, 2.9371, 2.5969, 3.9292, 3.1885, 2.4670, 2.7131, 2.7215, 2.7180,\n",
      "        2.5085, 3.2214, 3.0689, 3.8328, 2.5023, 2.7257, 2.1245, 2.3074, 2.0151,\n",
      "        2.5359, 2.9857, 2.3858, 2.7070, 2.9559, 2.5780, 2.9495, 2.1060, 2.3754,\n",
      "        2.7490, 2.9435, 2.4471, 2.6938, 2.2222, 2.7023, 2.6875, 2.6380, 2.3804,\n",
      "        2.8629, 2.6581, 2.5343, 2.1080, 3.1665, 2.9870, 2.4671, 3.0791, 2.9258,\n",
      "        2.0098, 2.9876, 2.4583, 3.1908, 1.8993, 2.4326, 3.2955, 2.3088, 2.7669,\n",
      "        2.3705, 2.6104, 2.2965, 2.8599, 3.0404, 3.1265, 2.3486, 2.6209, 2.5314,\n",
      "        2.9598, 2.1777, 3.2833, 2.4826, 2.1495, 2.1120, 2.6329, 2.0196, 2.5830,\n",
      "        2.9953, 2.7731, 2.1109, 2.6253, 2.6458, 3.1792, 2.3662, 2.9563, 2.5534,\n",
      "        3.6706, 2.4945, 3.0791, 2.2953, 2.7153, 3.2815, 2.2885, 2.4486, 2.0401,\n",
      "        3.1391, 2.0505, 3.0785, 2.2818, 2.9539, 2.3042, 2.9556, 2.9958, 1.6933,\n",
      "        2.8548, 2.2854, 2.5816, 3.0564, 2.0341, 2.3031, 2.5163, 2.3943, 2.1332,\n",
      "        2.5911, 2.6126, 2.3571, 2.4486, 1.9534, 3.2738, 2.5618, 2.5262, 2.7043,\n",
      "        2.9916, 3.1165, 2.2164, 3.1818, 2.5545, 2.2131, 3.1386, 3.0965, 2.8530,\n",
      "        1.9496, 2.5144, 2.0527, 2.6682, 2.6472, 2.7935, 2.5063, 3.1373, 3.1121,\n",
      "        2.6312, 2.4272, 2.1223, 2.9568, 2.5563, 2.5324, 3.5180, 2.0442, 2.8928,\n",
      "        3.0702, 2.2026, 2.4208, 3.1787, 2.5664, 2.6002, 2.0378, 2.5944, 2.5661,\n",
      "        2.8763, 2.4492, 2.1314, 3.1454, 2.7629, 3.0102, 3.0103, 2.5855, 2.3826,\n",
      "        2.2292, 2.7869, 2.7408, 1.9706, 2.4204, 2.4976, 3.1486, 2.0788, 2.7363,\n",
      "        2.4180, 2.0303, 2.9344, 2.0718, 2.6562, 3.4177, 3.0537, 2.7972, 2.2466,\n",
      "        3.6124, 3.4383, 1.8691, 2.8082, 2.1992, 2.7259, 1.9714, 2.4989, 2.9801,\n",
      "        3.0282, 2.6700, 2.6769, 2.3750, 2.2532, 3.5080, 2.4676, 2.6120, 2.4669,\n",
      "        2.5763, 2.6182, 3.6755, 2.8927, 2.4527, 1.9694, 3.1698, 2.4372],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)], [tensor([-35.7740, -45.8241, -38.7560, -31.5890, -35.1164, -38.4393, -42.1957,\n",
      "        -46.6409, -48.8005, -44.3439], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>), tensor([43.3247, 44.5450, 41.7424, 34.7020, 40.5605, 35.9051, 43.5192, 46.3586,\n",
      "        38.2935, 41.4184], dtype=torch.float64, grad_fn=<AddBackward0>)]]\n"
     ]
    }
   ],
   "source": [
    "input_flattened = torch.flatten(test_image)\n",
    "bounds_affine_out, bounds_layer_out = nn.calculate_box_bounds([input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "print(\"bounds affine out \\n {}\".format(bounds_affine_out))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "dhov_model = icnn_model(icnns[layer_index][0], nn, test_image, eps, layer_index, 0, group_size, print_log=False)\n",
    "dhov_model.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "icnn_neuron_name = \"icnn_var[{}]\".format(neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "dhov_copy = dhov_model.copy()\n",
    "dhov_copy.Params.LogToConsole = 0\n",
    "add_min_constr(dhov_copy, icnn_neuron_name)\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 2.198499612885324\n"
     ]
    }
   ],
   "source": [
    "dhov_copy = dhov_model.copy()\n",
    "dhov_copy.Params.LogToConsole = 0\n",
    "add_max_constr(dhov_copy, icnn_neuron_name)\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}