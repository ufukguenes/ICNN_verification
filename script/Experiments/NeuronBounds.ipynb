{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from script.NeuralNets.Networks import SequentialNN, ICNN, ICNNApproxMax, ICNNLogical\n",
    "from script.settings import device, data_type\n",
    "import script.DHOV.MultiDHOV as multidhov\n",
    "from script.Verification.Verifier import SingleNeuronVerifier, MILPVerifier, DHOVVerifier\n",
    "import gurobipy as grp\n",
    "from torchvision.datasets import CIFAR10, MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from script.NeuralNets.ICNNFactory import ICNNFactory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def add_max_constr(model, neuron_name):\n",
    "    neuron_var = model.getVarByName(neuron_name)\n",
    "    model.setObjective(neuron_var, grp.GRB.MAXIMIZE)\n",
    "\n",
    "def add_min_constr(model, neuron):\n",
    "    neuron_var = model.getVarByName(neuron)\n",
    "    model.setObjective(neuron_var, grp.GRB.MINIMIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def optimize_model(model, neuron_name):\n",
    "    model.update()\n",
    "    model.optimize()\n",
    "    if model.Status == grp.GRB.OPTIMAL:\n",
    "        print(\"opt value: {}\".format(model.getVarByName(neuron_name).getAttr(\"x\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def icnn_model(icnn, nn, input_x, eps, layer_index, from_neuron, to_neuron, print_log=False):\n",
    "    m = grp.Model()\n",
    "    if not print_log:\n",
    "        m.Params.LogToConsole = 0\n",
    "\n",
    "    input_flattened = torch.flatten(input_x)\n",
    "    bounds_affine_out, bounds_layer_out = nn.calculate_box_bounds(\n",
    "        [input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "\n",
    "    parameter_list = list(nn.parameters())\n",
    "\n",
    "    input_size = len(parameter_list[2*(layer_index-1)])\n",
    "    lb = bounds_layer_out[layer_index-1][0].detach().cpu().numpy()\n",
    "    ub = bounds_layer_out[layer_index-1][1].detach().cpu().numpy()\n",
    "    in_var = m.addMVar(input_size, lb=-float(\"inf\"), ub=float(\"inf\"), name=\"icnn_var\")\n",
    "\n",
    "    low = bounds_layer_out[layer_index - 1][0][from_neuron: to_neuron]\n",
    "    up = bounds_layer_out[layer_index - 1][1][from_neuron: to_neuron]\n",
    "    low = torch.zeros_like(low, dtype=data_type).to(device) - 1000\n",
    "    up = torch.zeros_like(low, dtype=data_type).to(device) + 1000\n",
    "    constraint_bounds_affine_out, constraint_bounds_layer_out = icnn.calculate_box_bounds([low, up])\n",
    "    icnn.add_max_output_constraints(m, in_var[from_neuron: to_neuron], constraint_bounds_affine_out, constraint_bounds_layer_out)\n",
    "\n",
    "    return m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'nn = SequentialNN([50, 50, 50, 7])\\ntest_image = torch.zeros((1, 50), dtype=data_type).to(device)\\nparameter_list = list(nn.parameters())'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"W1 = [1. 1.; 1. -1.]\n",
    "    b1 = [0., 0.]\n",
    "    W2 = [1. 1.; 1. -1.]\n",
    "    b2 = [-0.5, 0.]\n",
    "    W3 = [-1. 1.; 1. 1.]\n",
    "    b3 = [3., 0.] \"\"\"\n",
    "\n",
    "\"\"\"nn = SequentialNN([2, 2, 2, 2])\n",
    "\n",
    "with torch.no_grad():\n",
    "    parameter_list = list(nn.parameters())\n",
    "    parameter_list[0].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[1].data = torch.tensor([0, 0], dtype=data_type).to(device)\n",
    "    parameter_list[2].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[3].data = torch.tensor([-0.5, 0], dtype=data_type).to(device)\n",
    "    parameter_list[4].data = torch.tensor([[-1, 1], [1, 1]], dtype=data_type).to(device)\n",
    "    parameter_list[5].data = torch.tensor([3, 0], dtype=data_type).to(device)\n",
    "\n",
    "test_image = torch.tensor([[0, 0]], dtype=data_type).to(device)\"\"\"\n",
    "\n",
    "\"\"\"transform = Compose([ToTensor(),\n",
    "                         Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "                        )\n",
    "\n",
    "training_data = CIFAR10(root=\"../../cifar\", train=True, download=True, transform=transform)\n",
    "images, labels = training_data.__getitem__(0)\n",
    "test_image, test_label = torch.unsqueeze(images, 0).to(dtype=data_type).to(device), torch.unsqueeze(\n",
    "    torch.tensor(labels), 0).to(dtype=data_type).to(device)\n",
    "\n",
    "nn = SequentialNN([32 * 32 * 3, 1024, 512, 10])\n",
    "nn.load_state_dict(torch.load(\"../../cifar_fc.pth\", map_location=torch.device(device)), strict=False)\n",
    "\"\"\"\n",
    "\n",
    "transform = Compose([ToTensor(),\n",
    "                         Normalize(0.5, 0.5)]\n",
    "                        )\n",
    "\n",
    "training_data = MNIST(root=\"../../mnist\",\n",
    "                      train=True,\n",
    "                      download=True,\n",
    "                      transform=transform)\n",
    "images, labels = training_data.__getitem__(0)\n",
    "test_image, test_label = torch.unsqueeze(images, 0).to(dtype=data_type).to(device), torch.unsqueeze(\n",
    "    torch.tensor(labels), 0).to(dtype=data_type).to(device)\n",
    "\n",
    "nn = SequentialNN([28*28*1, 100, 30, 10])\n",
    "nn.load_state_dict(torch.load(\"../../mnist_fc.pth\", map_location=torch.device('cpu')), strict=False)\n",
    "\n",
    "parameter_list = list(nn.parameters())\n",
    "\n",
    "\"\"\"nn = SequentialNN([50, 50, 50, 7])\n",
    "test_image = torch.zeros((1, 50), dtype=data_type).to(device)\n",
    "parameter_list = list(nn.parameters())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eps = 0.01"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for DHOV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-11-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ufuk\\Documents\\Programming\\ICNN_verification\\script\\DHOV\\MultiDHOV.py:77: UserWarning: keep_ambient_space is True and sampling method ist -per_group_sampling-. Keeping previous samples is not supported when using per group sampling\n",
      "  warnings.warn(\"keep_ambient_space is True and sampling method ist -per_group_sampling-. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "approximation of layer: 0\n",
      "    number of fixed neurons for current layer: 92\n",
      "    layer progress, group 1 of 4 \n",
      "        time for sampling for one group: 0.008049249649047852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ufuk\\Documents\\Programming\\ICNN_verification\\script\\Optimizer\\sdlbfgs.py:83: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1420.)\n",
      "  p.data.add_(step_size, update[offset:offset + numel].view_as(p.data))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time for training: 0.33118152618408203\n",
      "        actual verification time 0.022214889526367188\n",
      "        time for verification: 0.1030421257019043\n",
      "    layer progress, group 2 of 4 \n",
      "        time for sampling for one group: 0.010093450546264648\n",
      "        time for training: 0.36333727836608887\n",
      "        actual verification time 0.020172119140625\n",
      "        time for verification: 0.10095024108886719\n",
      "    layer progress, group 3 of 4 \n",
      "        time for sampling for one group: 0.010094404220581055\n",
      "        time for training: 0.4041421413421631\n",
      "        actual verification time 0.020164012908935547\n",
      "        time for verification: 0.10088872909545898\n",
      "    layer progress, group 4 of 4 \n",
      "        time for sampling for one group: 0.018135786056518555\n",
      "        time for training: 0.41382408142089844\n",
      "        actual verification time 0.03026556968688965\n",
      "        time for verification: 0.09084820747375488\n",
      "    time for regrouping method: 0.0\n",
      "\n",
      "approximation of layer: 1\n",
      "        lower: new -0.07899962427050938, old -1.0272694263485382\n",
      "        upper: new 0.6440411088627572, old 1.590265447932639\n",
      "        lower: new 5.6164708542688615, old 4.891074441089023\n",
      "        upper: new 6.187856984383464, old 6.908179377487894\n",
      "        lower: new 1.1511168722326042, old 0.4758416777957901\n",
      "        upper: new 1.7719579678222668, old 2.45705423241999\n",
      "        lower: new -3.6142057804852086, old -4.154560614460519\n",
      "        upper: new -3.1914409762517693, old -2.6379028626565093\n",
      "        lower: new 1.6298233063478973, old 0.6517725440588809\n",
      "        upper: new 2.346362313540993, old 3.3335162230102693\n",
      "        lower: new -1.3129682983744866, old -2.143489793168459\n",
      "        upper: new -0.7421786736867847, old 0.0854374951093364\n",
      "        lower: new 0.5390218647522084, old -0.409115897681394\n",
      "        upper: new 1.2524376229776453, old 2.2013279327856976\n",
      "        lower: new -0.5323833408078734, old -1.194134963667596\n",
      "        upper: new -0.08104848901917903, old 0.5879126079003312\n",
      "        lower: new 1.9818317902599214, old 1.1517885635031728\n",
      "        upper: new 2.606206198356879, old 3.4413901127827238\n",
      "        lower: new 0.741233783146717, old 0.053368456055829405\n",
      "        upper: new 1.2497587889486528, old 1.951150902106173\n",
      "        lower: new 1.2913250837989054, old 0.4474716841053148\n",
      "        upper: new 1.9282708789389242, old 2.7688675833083156\n",
      "        lower: new 3.1718762846050903, old 2.2823298654349804\n",
      "        upper: new 3.7140363774630054, old 4.599801049017392\n",
      "        lower: new 2.3159349223013974, old 1.6933718660848394\n",
      "        upper: new 2.829658259734421, old 3.471459235031665\n",
      "        lower: new -1.3153022380712533, old -1.8334256175700663\n",
      "        upper: new -1.039864261354517, old -0.5237117713086965\n",
      "        lower: new -1.0035107686383156, old -1.466869389694395\n",
      "        upper: new -0.7673023543730753, old -0.30613013523807897\n",
      "        lower: new 5.665257315989262, old 4.668204914112108\n",
      "        upper: new 6.361139602767444, old 7.361566298400341\n",
      "        lower: new 0.2642568723685221, old -0.6847946385441421\n",
      "        upper: new 1.128012934895411, old 2.0801847320655966\n",
      "        lower: new 2.9591027948502666, old 2.2004989456216055\n",
      "        upper: new 3.509924693038446, old 4.267971015539602\n",
      "        lower: new -0.9054087427456698, old -1.2830149131120172\n",
      "        upper: new -0.6788801875937468, old -0.29468515782038596\n",
      "        lower: new 5.370648665669505, old 4.670984259366115\n",
      "        upper: new 5.959922084332108, old 6.657308087984413\n",
      "        lower: new 0.07062257344304564, old -0.6091871666301043\n",
      "        upper: new 0.5178415719978685, old 1.200720888753544\n",
      "        lower: new 6.160351262020607, old 5.484337577617196\n",
      "        upper: new 6.746114779497837, old 7.413609163446834\n",
      "        lower: new 1.9918280097337822, old 1.2427032510074483\n",
      "        upper: new 2.569510088534744, old 3.320612581395128\n",
      "        lower: new 5.14056245921461, old 4.168817558547471\n",
      "        upper: new 5.807848140076078, old 6.780179104352769\n",
      "        lower: new 7.380702644964069, old 6.446242411024807\n",
      "        upper: new 8.047949328279568, old 8.971084931603443\n",
      "        lower: new -0.7407899295546988, old -1.1600468860809312\n",
      "        upper: new -0.46591126148236617, old -0.046419147582785314\n",
      "        lower: new 4.484271645273507, old 3.754943133455928\n",
      "        upper: new 4.9825345938375465, old 5.711956539875997\n",
      "        lower: new 4.4454037378142335, old 3.561375283453498\n",
      "        upper: new 5.17656397280038, old 6.063069775488341\n",
      "        lower: new 1.3276064948240212, old 0.7072285143067245\n",
      "        upper: new 1.672598518349647, old 2.2934821027747554\n",
      "        lower: new 3.7146362755716393, old 2.928185776482185\n",
      "        upper: new 4.318519267131344, old 5.094451979379954\n",
      "    time for icnn_bound calculation: 1.488236427307129\n",
      "    number of fixed neurons for current layer: 29\n",
      "    layer progress, group 1 of 1 \n",
      "        time for sampling for one group: 46.89554715156555\n",
      "        time for training: 47.207467794418335\n",
      "        actual verification time 0.03828024864196777\n",
      "        time for verification: 0.10085344314575195\n",
      "    time for regrouping method: 0.0\n",
      "        lower: new -0.00021587307227810548, old -5.222328370466463\n",
      "        upper: new 1.1198453338512055, old 6.4550215091504075\n",
      "        lower: new 0.7396900527388428, old -4.918760822623748\n",
      "        upper: new 2.0932818295190487, old 7.295738312409591\n",
      "        lower: new -0.575688208630723, old -6.658893474237098\n",
      "        upper: new 1.4065616318826728, old 7.852218028790009\n",
      "        lower: new 8.447808734848845, old 2.644916692106161\n",
      "        upper: new 10.036445091228796, old 15.606944995777688\n",
      "        lower: new -13.535788344143302, old -18.618164387099664\n",
      "        upper: new -11.849227028785576, old -5.71679109540866\n",
      "        lower: new 9.89933944516559, old 3.640542770683016\n",
      "        upper: new 11.484101522789649, old 17.27910677198991\n",
      "        lower: new -4.102469848815132, old -9.56686692623975\n",
      "        upper: new -2.824198359035516, old 2.3780248928482886\n",
      "        lower: new 1.475627688558066, old -4.352364636627183\n",
      "        upper: new 2.848899764774944, old 8.45344870964095\n",
      "        lower: new -4.456127288138068, old -10.968712675309703\n",
      "        upper: new -2.958516225048736, old 3.7082917227510546\n",
      "        lower: new -3.1324408551488645, old -9.135683286699116\n",
      "        upper: new -1.6241117375732261, old 4.336747007588861\n",
      "done...\n"
     ]
    }
   ],
   "source": [
    "group_size = 2\n",
    "icnn_factory = ICNNFactory(\"logical\", [5, 5, 1], force_positive_init=False, with_two_layers=False,\n",
    "                               init_scaling=10, init_all_with_zeros=False)\n",
    "#icnn_factory = ICNNFactory(\"standard\", [5, 5, 1])\n",
    "\n",
    "dhov_verifier = multidhov.MultiDHOV()\n",
    "dhov_verifier.start_verification(nn, test_image, icnn_factory, group_size, eps=eps, icnn_epochs=10,\n",
    "                                 icnn_batch_size=1000, sample_count=1000, sample_new=True, use_over_approximation=True, break_after=None,\n",
    "                                 sample_over_input_space=False, sample_over_output_space=True, use_icnn_bounds=True,\n",
    "                                 use_fixed_neurons=True, sampling_method=\"per_group_sampling\",\n",
    "                                 force_inclusion_steps=0, preemptive_stop=False, even_gradient_training=False,\n",
    "                                 keep_ambient_space=True, data_grad_descent_steps=0, opt_steps_gd=100,\n",
    "                                 train_outer=False, print_training_loss=False,\n",
    "                                 should_plot=\"none\", optimizer=\"SdLBFGS\", init_network=True, adapt_lambda=\"none\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "layer_index = 2\n",
    "neuron_index = 1\n",
    "# neuron_name = \"relu_var{}[{}]\".format(2*layer_index, neuron_index)\n",
    "neuron_name = \"last_affine_var[{}]\".format(neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1, 23], [25, 51], [60, 69], [86, 96]], [[0]]]\n"
     ]
    }
   ],
   "source": [
    "print(dhov_verifier.all_group_indices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.1587e-04,  7.3969e-01, -5.7569e-01,  8.4478e+00, -1.3536e+01,\n",
      "         9.8993e+00, -4.1025e+00,  1.4756e+00, -4.4561e+00, -3.1324e+00],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "print(dhov_verifier.bounds_affine_out[layer_index][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.1198,   2.0933,   1.4066,  10.0364, -11.8492,  11.4841,  -2.8242,\n",
      "          2.8489,  -2.9585,  -1.6241], dtype=torch.float64,\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "print(dhov_verifier.bounds_affine_out[layer_index][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -5.2223,  -4.9188,  -6.6589,   2.6449, -18.6182,   3.6405,  -9.5669,\n",
      "         -4.3524, -10.9687,  -9.1357], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([ 6.4550,  7.2957,  7.8522, 15.6069, -5.7168, 17.2791,  2.3780,  8.4534,\n",
      "         3.7083,  4.3367], dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_flattened = torch.flatten(test_image)\n",
    "simple_bounds_affine_out, simple_bounds_layer_out = nn.calculate_box_bounds([input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "print(simple_bounds_affine_out[layer_index][0])\n",
    "print(simple_bounds_affine_out[layer_index][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "icnn_neuron_name = \"output_layer_[{}]_[{}]\".format(layer_index, neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.7396900527388428\n"
     ]
    }
   ],
   "source": [
    "dhov_copy = dhov_verifier.nn_encoding_model.copy()\n",
    "add_min_constr(dhov_copy, icnn_neuron_name)\n",
    "dhov_copy.update()\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 2.0932818295190487\n"
     ]
    }
   ],
   "source": [
    "dhov_copy = dhov_verifier.nn_encoding_model.copy()\n",
    "dhov_copy.Params.LogToConsole = 0\n",
    "add_max_constr(dhov_copy, icnn_neuron_name)\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for SNV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "snv_verifier = SingleNeuronVerifier(nn, test_image, eps, print_log=False)\n",
    "snv_verifier.generate_constraints_for_net()\n",
    "snv_model = snv_verifier.model\n",
    "snv_model.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.5887688158971365\n"
     ]
    }
   ],
   "source": [
    "snv_copy = snv_model.copy()\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "add_min_constr(snv_copy, neuron_name)\n",
    "optimize_model(snv_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 2.0317086474039625\n"
     ]
    }
   ],
   "source": [
    "snv_copy = snv_model.copy()\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "add_max_constr(snv_copy, neuron_name)\n",
    "optimize_model(snv_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for MILP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "'all_var = milp_model.getVars()\\nfor var in all_var:\\n    print(var)'"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milp_verifier = MILPVerifier(nn, test_image, eps, print_log=False)\n",
    "milp_verifier.generate_constraints_for_net(until_layer_neuron=[layer_index, neuron_index])\n",
    "milp_model = milp_verifier.model\n",
    "milp_model.update()\n",
    "\n",
    "\"\"\"all_var = milp_model.getVars()\n",
    "for var in all_var:\n",
    "    print(var)\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.9777576260166984\n"
     ]
    }
   ],
   "source": [
    "milp_copy = milp_model.copy()\n",
    "milp_copy.Params.LogToConsole = 0\n",
    "add_min_constr(milp_copy, neuron_name)\n",
    "optimize_model(milp_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 1.8828109205406829\n"
     ]
    }
   ],
   "source": [
    "milp_copy = milp_model.copy()\n",
    "milp_copy.Params.LogToConsole = 0\n",
    "add_max_constr(milp_copy, neuron_name)\n",
    "optimize_model(milp_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}