{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from script.NeuralNets.Networks import SequentialNN, ICNN, ICNNApproxMax, ICNNLogical\n",
    "from script.settings import device, data_type\n",
    "import script.DHOV.MultiDHOV as multidhov\n",
    "from script.Verification.Verifier import SingleNeuronVerifier, MILPVerifier, DHOVVerifier\n",
    "import gurobipy as grp\n",
    "from torchvision.datasets import CIFAR10, MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from script.NeuralNets.ICNNFactory import ICNNFactory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def add_max_constr(model, neuron_name):\n",
    "    neuron_var = model.getVarByName(neuron_name)\n",
    "    model.setObjective(neuron_var, grp.GRB.MAXIMIZE)\n",
    "\n",
    "def add_min_constr(model, neuron):\n",
    "    neuron_var = model.getVarByName(neuron)\n",
    "    model.setObjective(neuron_var, grp.GRB.MINIMIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def optimize_model(model, neuron_name):\n",
    "    model.update()\n",
    "    model.optimize()\n",
    "    if model.Status == grp.GRB.OPTIMAL:\n",
    "        print(\"opt value: {}\".format(model.getVarByName(neuron_name).getAttr(\"x\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def icnn_model(icnn, nn, input_x, eps, layer_index, from_neuron, to_neuron, print_log=False):\n",
    "    m = grp.Model()\n",
    "    if not print_log:\n",
    "        m.Params.LogToConsole = 0\n",
    "\n",
    "    input_flattened = torch.flatten(input_x)\n",
    "    bounds_affine_out, bounds_layer_out = nn.calculate_box_bounds(\n",
    "        [input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "\n",
    "    parameter_list = list(nn.parameters())\n",
    "\n",
    "    input_size = len(parameter_list[2*(layer_index-1)])\n",
    "    lb = bounds_layer_out[layer_index-1][0].detach().cpu().numpy()\n",
    "    ub = bounds_layer_out[layer_index-1][1].detach().cpu().numpy()\n",
    "    in_var = m.addMVar(input_size, lb=-float(\"inf\"), ub=float(\"inf\"), name=\"icnn_var\")\n",
    "\n",
    "    low = bounds_layer_out[layer_index - 1][0][from_neuron: to_neuron]\n",
    "    up = bounds_layer_out[layer_index - 1][1][from_neuron: to_neuron]\n",
    "    low = torch.zeros_like(low, dtype=data_type).to(device) - 1000\n",
    "    up = torch.zeros_like(low, dtype=data_type).to(device) + 1000\n",
    "    constraint_bounds_affine_out, constraint_bounds_layer_out = icnn.calculate_box_bounds([low, up])\n",
    "    icnn.add_max_output_constraints(m, in_var[from_neuron: to_neuron], constraint_bounds_affine_out, constraint_bounds_layer_out)\n",
    "\n",
    "    return m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'nn = SequentialNN([50, 50, 50, 7])\\ntest_image = torch.zeros((1, 50), dtype=data_type).to(device)\\nparameter_list = list(nn.parameters())'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"W1 = [1. 1.; 1. -1.]\n",
    "    b1 = [0., 0.]\n",
    "    W2 = [1. 1.; 1. -1.]\n",
    "    b2 = [-0.5, 0.]\n",
    "    W3 = [-1. 1.; 1. 1.]\n",
    "    b3 = [3., 0.] \"\"\"\n",
    "\n",
    "\"\"\"nn = SequentialNN([2, 2, 2, 2])\n",
    "\n",
    "with torch.no_grad():\n",
    "    parameter_list = list(nn.parameters())\n",
    "    parameter_list[0].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[1].data = torch.tensor([0, 0], dtype=data_type).to(device)\n",
    "    parameter_list[2].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[3].data = torch.tensor([-0.5, 0], dtype=data_type).to(device)\n",
    "    parameter_list[4].data = torch.tensor([[-1, 1], [1, 1]], dtype=data_type).to(device)\n",
    "    parameter_list[5].data = torch.tensor([3, 0], dtype=data_type).to(device)\n",
    "\n",
    "test_image = torch.tensor([[0, 0]], dtype=data_type).to(device)\"\"\"\n",
    "\n",
    "\"\"\"transform = Compose([ToTensor(),\n",
    "                         Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "                        )\n",
    "\n",
    "training_data = CIFAR10(root=\"../../cifar\", train=True, download=True, transform=transform)\n",
    "images, labels = training_data.__getitem__(0)\n",
    "test_image, test_label = torch.unsqueeze(images, 0).to(dtype=data_type).to(device), torch.unsqueeze(\n",
    "    torch.tensor(labels), 0).to(dtype=data_type).to(device)\n",
    "\n",
    "nn = SequentialNN([32 * 32 * 3, 1024, 512, 10])\n",
    "nn.load_state_dict(torch.load(\"../../cifar_fc.pth\", map_location=torch.device(device)), strict=False)\n",
    "\"\"\"\n",
    "\n",
    "transform = Compose([ToTensor(),\n",
    "                         Normalize(0.5, 0.5)]\n",
    "                        )\n",
    "\n",
    "training_data = MNIST(root=\"../../mnist\",\n",
    "                      train=True,\n",
    "                      download=True,\n",
    "                      transform=transform)\n",
    "images, labels = training_data.__getitem__(0)\n",
    "test_image, test_label = torch.unsqueeze(images, 0).to(dtype=data_type).to(device), torch.unsqueeze(\n",
    "    torch.tensor(labels), 0).to(dtype=data_type).to(device)\n",
    "\n",
    "nn = SequentialNN([28*28*1, 100, 30, 10])\n",
    "nn.load_state_dict(torch.load(\"../../mnist_fc.pth\", map_location=torch.device('cpu')), strict=False)\n",
    "\n",
    "parameter_list = list(nn.parameters())\n",
    "\n",
    "\"\"\"nn = SequentialNN([50, 50, 50, 7])\n",
    "test_image = torch.zeros((1, 50), dtype=data_type).to(device)\n",
    "parameter_list = list(nn.parameters())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "eps = 0.01\n",
    "layer_index = 1\n",
    "neuron_index = 0\n",
    "neuron_name = \"relu_var{}[{}]\".format(2*layer_index, neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for DHOV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "approximation of layer: 0\n",
      "    number of fixed neurons for current layer: 92\n",
      "    layer progress, group 1 of 4 \n",
      "=== Epoch: 0===\n",
      "batch = 0, mean loss = 1.2816370075495223\n",
      "batch = 1, mean loss = 1.2816370075495223\n",
      "time per epoch: 0.2530515193939209\n",
      "=== Epoch: 1===\n",
      "batch = 0, mean loss = 1.3314186258637766\n",
      "batch = 1, mean loss = 1.3314186258637766\n",
      "time per epoch: 0.032999277114868164\n",
      "=== Epoch: 2===\n",
      "batch = 0, mean loss = 1.3191488859164855\n",
      "batch = 1, mean loss = 1.3191488859164855\n",
      "time per epoch: 0.031000614166259766\n",
      "=== Epoch: 3===\n",
      "batch = 0, mean loss = 1.283836804538065\n",
      "batch = 1, mean loss = 1.283836804538065\n",
      "time per epoch: 0.03100109100341797\n",
      "=== Epoch: 4===\n",
      "batch = 0, mean loss = 1.2532449631059832\n",
      "batch = 1, mean loss = 1.2532449631059832\n",
      "time per epoch: 0.03299832344055176\n",
      "=== Epoch: 5===\n",
      "batch = 0, mean loss = 1.2546358998334801\n",
      "batch = 1, mean loss = 1.2546358998334801\n",
      "time per epoch: 0.032000064849853516\n",
      "=== Epoch: 6===\n",
      "batch = 0, mean loss = 1.237018360289654\n",
      "batch = 1, mean loss = 1.237018360289654\n",
      "time per epoch: 0.03299999237060547\n",
      "=== Epoch: 7===\n",
      "batch = 0, mean loss = 1.2290338872036721\n",
      "batch = 1, mean loss = 1.2290338872036721\n",
      "time per epoch: 0.032000064849853516\n",
      "=== Epoch: 8===\n",
      "batch = 0, mean loss = 1.2119433960006245\n",
      "batch = 1, mean loss = 1.2119433960006245\n",
      "time per epoch: 0.034003496170043945\n",
      "=== Epoch: 9===\n",
      "batch = 0, mean loss = 1.2045610951444479\n",
      "batch = 1, mean loss = 1.2045610951444479\n",
      "time per epoch: 0.029996156692504883\n",
      "=== Epoch: 10===\n",
      "batch = 0, mean loss = 1.1777979176259483\n",
      "batch = 1, mean loss = 1.1777979176259483\n",
      "time per epoch: 0.03200030326843262\n",
      "=== Epoch: 11===\n",
      "batch = 0, mean loss = 1.1750657694643214\n",
      "batch = 1, mean loss = 1.1750657694643214\n",
      "time per epoch: 0.024004220962524414\n",
      "=== Epoch: 12===\n",
      "batch = 0, mean loss = 1.1700336334017276\n",
      "batch = 1, mean loss = 1.1700336334017276\n",
      "time per epoch: 0.028000593185424805\n",
      "=== Epoch: 13===\n",
      "batch = 0, mean loss = 1.1580836052642043\n",
      "batch = 1, mean loss = 1.1580836052642043\n",
      "time per epoch: 0.028995990753173828\n",
      "=== Epoch: 14===\n",
      "batch = 0, mean loss = 1.1592801868031826\n",
      "batch = 1, mean loss = 1.1592801868031826\n",
      "time per epoch: 0.02899909019470215\n",
      "=== Epoch: 15===\n",
      "batch = 0, mean loss = 1.1647921268914954\n",
      "batch = 1, mean loss = 1.1647921268914954\n",
      "time per epoch: 0.03099989891052246\n",
      "=== Epoch: 16===\n",
      "batch = 0, mean loss = 1.1615801951951\n",
      "batch = 1, mean loss = 1.1615801951951\n",
      "time per epoch: 0.03299975395202637\n",
      "=== Epoch: 17===\n",
      "batch = 0, mean loss = 1.1617666750519773\n",
      "batch = 1, mean loss = 1.1617666750519773\n",
      "time per epoch: 0.029000520706176758\n",
      "=== Epoch: 18===\n",
      "batch = 0, mean loss = 1.16114817437724\n",
      "batch = 1, mean loss = 1.16114817437724\n",
      "time per epoch: 0.03400015830993652\n",
      "=== Epoch: 19===\n",
      "batch = 0, mean loss = 1.159780924001344\n",
      "batch = 1, mean loss = 1.159780924001344\n",
      "time per epoch: 0.026005029678344727\n",
      "=== Epoch: 20===\n",
      "batch = 0, mean loss = 1.156485163370266\n",
      "batch = 1, mean loss = 1.156485163370266\n",
      "time per epoch: 0.024999618530273438\n",
      "=== Epoch: 21===\n",
      "batch = 0, mean loss = 1.153752279587596\n",
      "batch = 1, mean loss = 1.153752279587596\n",
      "time per epoch: 0.029000282287597656\n",
      "=== Epoch: 22===\n",
      "batch = 0, mean loss = 1.1532567308015562\n",
      "batch = 1, mean loss = 1.1532567308015562\n",
      "time per epoch: 0.023999452590942383\n",
      "=== Epoch: 23===\n",
      "batch = 0, mean loss = 1.152778638112672\n",
      "batch = 1, mean loss = 1.152778638112672\n",
      "time per epoch: 0.026999711990356445\n",
      "=== Epoch: 24===\n",
      "batch = 0, mean loss = 1.15246906202999\n",
      "batch = 1, mean loss = 1.15246906202999\n",
      "time per epoch: 0.03399538993835449\n",
      "=== Epoch: 25===\n",
      "batch = 0, mean loss = 1.1526654440320279\n",
      "batch = 1, mean loss = 1.1526654440320279\n",
      "time per epoch: 0.033000946044921875\n",
      "=== Epoch: 26===\n",
      "batch = 0, mean loss = 1.1526330384094912\n",
      "batch = 1, mean loss = 1.1526330384094912\n",
      "time per epoch: 0.03199934959411621\n",
      "=== Epoch: 27===\n",
      "batch = 0, mean loss = 1.1525080941436545\n",
      "batch = 1, mean loss = 1.1525080941436545\n",
      "time per epoch: 0.03200030326843262\n",
      "=== Epoch: 28===\n",
      "batch = 0, mean loss = 1.1524726464107284\n",
      "batch = 1, mean loss = 1.1524726464107284\n",
      "time per epoch: 0.032000064849853516\n",
      "=== Epoch: 29===\n",
      "batch = 0, mean loss = 1.1524322523816026\n",
      "batch = 1, mean loss = 1.1524322523816026\n",
      "time per epoch: 0.02900528907775879\n",
      "=== Epoch: 30===\n",
      "batch = 0, mean loss = 1.1524566068287159\n",
      "batch = 1, mean loss = 1.1524566068287159\n",
      "time per epoch: 0.02999424934387207\n",
      "=== Epoch: 31===\n",
      "batch = 0, mean loss = 1.1524177307879346\n",
      "batch = 1, mean loss = 1.1524177307879346\n",
      "time per epoch: 0.03399991989135742\n",
      "=== Epoch: 32===\n",
      "batch = 0, mean loss = 1.152444188958154\n",
      "batch = 1, mean loss = 1.152444188958154\n",
      "time per epoch: 0.03400135040283203\n",
      "=== Epoch: 33===\n",
      "batch = 0, mean loss = 1.152399301651486\n",
      "batch = 1, mean loss = 1.152399301651486\n",
      "time per epoch: 0.03299903869628906\n",
      "=== Epoch: 34===\n",
      "batch = 0, mean loss = 1.1524202933401457\n",
      "batch = 1, mean loss = 1.1524202933401457\n",
      "time per epoch: 0.03400015830993652\n",
      "=== Epoch: 35===\n",
      "batch = 0, mean loss = 1.1524175803919063\n",
      "batch = 1, mean loss = 1.1524175803919063\n",
      "time per epoch: 0.03600144386291504\n",
      "=== Epoch: 36===\n",
      "batch = 0, mean loss = 1.152400276282038\n",
      "batch = 1, mean loss = 1.152400276282038\n",
      "time per epoch: 0.03499865531921387\n",
      "=== Epoch: 37===\n",
      "batch = 0, mean loss = 1.152418070128336\n",
      "batch = 1, mean loss = 1.152418070128336\n",
      "time per epoch: 0.03000020980834961\n",
      "=== Epoch: 38===\n",
      "batch = 0, mean loss = 1.1523831877275648\n",
      "batch = 1, mean loss = 1.1523831877275648\n",
      "time per epoch: 0.03299975395202637\n",
      "=== Epoch: 39===\n",
      "batch = 0, mean loss = 1.1524163114345354\n",
      "batch = 1, mean loss = 1.1524163114345354\n",
      "time per epoch: 0.03600049018859863\n",
      "=== Epoch: 40===\n",
      "batch = 0, mean loss = 1.1523954971200756\n",
      "batch = 1, mean loss = 1.1523954971200756\n",
      "time per epoch: 0.03400015830993652\n",
      "=== Epoch: 41===\n",
      "batch = 0, mean loss = 1.1524036420924673\n",
      "batch = 1, mean loss = 1.1524036420924673\n",
      "time per epoch: 0.03200197219848633\n",
      "=== Epoch: 42===\n",
      "batch = 0, mean loss = 1.1524115536662012\n",
      "batch = 1, mean loss = 1.1524115536662012\n",
      "time per epoch: 0.031000137329101562\n",
      "=== Epoch: 43===\n",
      "batch = 0, mean loss = 1.15239789149141\n",
      "batch = 1, mean loss = 1.15239789149141\n",
      "time per epoch: 0.028997421264648438\n",
      "=== Epoch: 44===\n",
      "batch = 0, mean loss = 1.1523948376205626\n",
      "batch = 1, mean loss = 1.1523948376205626\n",
      "time per epoch: 0.037000179290771484\n",
      "=== Epoch: 45===\n",
      "batch = 0, mean loss = 1.152396757807348\n",
      "batch = 1, mean loss = 1.152396757807348\n",
      "time per epoch: 0.03500032424926758\n",
      "=== Epoch: 46===\n",
      "batch = 0, mean loss = 1.1523945173689414\n",
      "batch = 1, mean loss = 1.1523945173689414\n",
      "time per epoch: 0.034005165100097656\n",
      "=== Epoch: 47===\n",
      "batch = 0, mean loss = 1.1523912046346934\n",
      "batch = 1, mean loss = 1.1523912046346934\n",
      "time per epoch: 0.03199458122253418\n",
      "=== Epoch: 48===\n",
      "batch = 0, mean loss = 1.152396053803732\n",
      "batch = 1, mean loss = 1.152396053803732\n",
      "time per epoch: 0.03500032424926758\n",
      "=== Epoch: 49===\n",
      "batch = 0, mean loss = 1.152387930308708\n",
      "batch = 1, mean loss = 1.152387930308708\n",
      "time per epoch: 0.03600001335144043\n",
      "=== Epoch: 50===\n",
      "batch = 0, mean loss = 1.1523875228137765\n",
      "batch = 1, mean loss = 1.1523875228137765\n",
      "time per epoch: 0.03099989891052246\n",
      "=== Epoch: 51===\n",
      "batch = 0, mean loss = 1.1523937609926513\n",
      "batch = 1, mean loss = 1.1523937609926513\n",
      "time per epoch: 0.02800440788269043\n",
      "=== Epoch: 52===\n",
      "batch = 0, mean loss = 1.152385383229126\n",
      "batch = 1, mean loss = 1.152385383229126\n",
      "time per epoch: 0.02699446678161621\n",
      "=== Epoch: 53===\n",
      "batch = 0, mean loss = 1.1524006669311444\n",
      "batch = 1, mean loss = 1.1524006669311444\n",
      "time per epoch: 0.026999711990356445\n",
      "=== Epoch: 54===\n",
      "batch = 0, mean loss = 1.1523728032336424\n",
      "batch = 1, mean loss = 1.1523728032336424\n",
      "time per epoch: 0.03100132942199707\n",
      "=== Epoch: 55===\n",
      "batch = 0, mean loss = 1.152407172808206\n",
      "batch = 1, mean loss = 1.152407172808206\n",
      "time per epoch: 0.03600001335144043\n",
      "=== Epoch: 56===\n",
      "batch = 0, mean loss = 1.1523717460467529\n",
      "batch = 1, mean loss = 1.1523717460467529\n",
      "time per epoch: 0.03499960899353027\n",
      "=== Epoch: 57===\n",
      "batch = 0, mean loss = 1.1523889044233382\n",
      "batch = 1, mean loss = 1.1523889044233382\n",
      "time per epoch: 0.027005672454833984\n",
      "=== Epoch: 58===\n",
      "batch = 0, mean loss = 1.152390708222175\n",
      "batch = 1, mean loss = 1.152390708222175\n",
      "time per epoch: 0.027002811431884766\n",
      "=== Epoch: 59===\n",
      "batch = 0, mean loss = 1.1523719883683572\n",
      "batch = 1, mean loss = 1.1523719883683572\n",
      "time per epoch: 0.026996612548828125\n",
      "=== Epoch: 60===\n",
      "batch = 0, mean loss = 1.1524009899152816\n",
      "batch = 1, mean loss = 1.1524009899152816\n",
      "time per epoch: 0.029994964599609375\n",
      "=== Epoch: 61===\n",
      "batch = 0, mean loss = 1.1523701739041559\n",
      "batch = 1, mean loss = 1.1523701739041559\n",
      "time per epoch: 0.029999971389770508\n",
      "=== Epoch: 62===\n",
      "batch = 0, mean loss = 1.1523822446637282\n",
      "batch = 1, mean loss = 1.1523822446637282\n",
      "time per epoch: 0.03500032424926758\n",
      "=== Epoch: 63===\n",
      "batch = 0, mean loss = 1.1523904721156077\n",
      "batch = 1, mean loss = 1.1523904721156077\n",
      "time per epoch: 0.03400278091430664\n",
      "=== Epoch: 64===\n",
      "batch = 0, mean loss = 1.1523676613300988\n",
      "batch = 1, mean loss = 1.1523676613300988\n",
      "time per epoch: 0.03699827194213867\n",
      "=== Epoch: 65===\n",
      "batch = 0, mean loss = 1.152387732009856\n",
      "batch = 1, mean loss = 1.152387732009856\n",
      "time per epoch: 0.03499865531921387\n",
      "=== Epoch: 66===\n",
      "batch = 0, mean loss = 1.152384786077413\n",
      "batch = 1, mean loss = 1.152384786077413\n",
      "time per epoch: 0.03305244445800781\n",
      "=== Epoch: 67===\n",
      "batch = 0, mean loss = 1.1523815750779742\n",
      "batch = 1, mean loss = 1.1523815750779742\n",
      "time per epoch: 0.029999971389770508\n",
      "=== Epoch: 68===\n",
      "batch = 0, mean loss = 1.1523859697096768\n",
      "batch = 1, mean loss = 1.1523859697096768\n",
      "time per epoch: 0.03000020980834961\n",
      "=== Epoch: 69===\n",
      "batch = 0, mean loss = 1.1523661871248905\n",
      "batch = 1, mean loss = 1.1523661871248905\n",
      "time per epoch: 0.027007341384887695\n",
      "=== Epoch: 70===\n",
      "batch = 0, mean loss = 1.1523872651386173\n",
      "batch = 1, mean loss = 1.1523872651386173\n",
      "time per epoch: 0.02499699592590332\n",
      "=== Epoch: 71===\n",
      "batch = 0, mean loss = 1.1523782744446498\n",
      "batch = 1, mean loss = 1.1523782744446498\n",
      "time per epoch: 0.034995317459106445\n",
      "=== Epoch: 72===\n",
      "batch = 0, mean loss = 1.1523707952243671\n",
      "batch = 1, mean loss = 1.1523707952243671\n",
      "time per epoch: 0.0280001163482666\n",
      "=== Epoch: 73===\n",
      "batch = 0, mean loss = 1.1523864558004413\n",
      "batch = 1, mean loss = 1.1523864558004413\n",
      "time per epoch: 0.03200030326843262\n",
      "=== Epoch: 74===\n",
      "batch = 0, mean loss = 1.152370211579605\n",
      "batch = 1, mean loss = 1.152370211579605\n",
      "time per epoch: 0.03599953651428223\n",
      "=== Epoch: 75===\n",
      "batch = 0, mean loss = 1.1523771857029455\n",
      "batch = 1, mean loss = 1.1523771857029455\n",
      "time per epoch: 0.03500103950500488\n",
      "=== Epoch: 76===\n",
      "batch = 0, mean loss = 1.1523826834729733\n",
      "batch = 1, mean loss = 1.1523826834729733\n",
      "time per epoch: 0.03399944305419922\n",
      "=== Epoch: 77===\n",
      "batch = 0, mean loss = 1.1523661379019399\n",
      "batch = 1, mean loss = 1.1523661379019399\n",
      "time per epoch: 0.0370020866394043\n",
      "=== Epoch: 78===\n",
      "batch = 0, mean loss = 1.152382040862918\n",
      "batch = 1, mean loss = 1.152382040862918\n",
      "time per epoch: 0.03999781608581543\n",
      "=== Epoch: 79===\n",
      "batch = 0, mean loss = 1.1523778444323802\n",
      "batch = 1, mean loss = 1.1523778444323802\n",
      "time per epoch: 0.03699994087219238\n",
      "=== Epoch: 80===\n",
      "batch = 0, mean loss = 1.1523691331966457\n",
      "batch = 1, mean loss = 1.1523691331966457\n",
      "time per epoch: 0.03699994087219238\n",
      "=== Epoch: 81===\n",
      "batch = 0, mean loss = 1.1523823178472932\n",
      "batch = 1, mean loss = 1.1523823178472932\n",
      "time per epoch: 0.032837867736816406\n",
      "=== Epoch: 82===\n",
      "batch = 0, mean loss = 1.1523798194794719\n",
      "batch = 1, mean loss = 1.1523798194794719\n",
      "time per epoch: 0.03551650047302246\n",
      "=== Epoch: 83===\n",
      "batch = 0, mean loss = 1.1523734816640614\n",
      "batch = 1, mean loss = 1.1523734816640614\n",
      "time per epoch: 0.033000946044921875\n",
      "=== Epoch: 84===\n",
      "batch = 0, mean loss = 1.152377016059787\n",
      "batch = 1, mean loss = 1.152377016059787\n",
      "time per epoch: 0.028000354766845703\n",
      "=== Epoch: 85===\n",
      "batch = 0, mean loss = 1.152377727900648\n",
      "batch = 1, mean loss = 1.152377727900648\n",
      "time per epoch: 0.029999732971191406\n",
      "=== Epoch: 86===\n",
      "batch = 0, mean loss = 1.1523789842412304\n",
      "batch = 1, mean loss = 1.1523789842412304\n",
      "time per epoch: 0.03299999237060547\n",
      "=== Epoch: 87===\n",
      "batch = 0, mean loss = 1.1523701753924325\n",
      "batch = 1, mean loss = 1.1523701753924325\n",
      "time per epoch: 0.028999805450439453\n",
      "=== Epoch: 88===\n",
      "batch = 0, mean loss = 1.1523858105903892\n",
      "batch = 1, mean loss = 1.1523858105903892\n",
      "time per epoch: 0.03800034523010254\n",
      "=== Epoch: 89===\n",
      "batch = 0, mean loss = 1.1523723484359036\n",
      "batch = 1, mean loss = 1.1523723484359036\n",
      "time per epoch: 0.0370030403137207\n",
      "=== Epoch: 90===\n",
      "batch = 0, mean loss = 1.1523694874275479\n",
      "batch = 1, mean loss = 1.1523694874275479\n",
      "time per epoch: 0.03099656105041504\n",
      "=== Epoch: 91===\n",
      "batch = 0, mean loss = 1.1523787362644213\n",
      "batch = 1, mean loss = 1.1523787362644213\n",
      "time per epoch: 0.03400588035583496\n",
      "=== Epoch: 92===\n",
      "batch = 0, mean loss = 1.1523696612407832\n",
      "batch = 1, mean loss = 1.1523696612407832\n",
      "time per epoch: 0.03899574279785156\n",
      "=== Epoch: 93===\n",
      "batch = 0, mean loss = 1.1523739457389812\n",
      "batch = 1, mean loss = 1.1523739457389812\n",
      "time per epoch: 0.041999101638793945\n",
      "=== Epoch: 94===\n",
      "batch = 0, mean loss = 1.152379033314367\n",
      "batch = 1, mean loss = 1.152379033314367\n",
      "time per epoch: 0.04199934005737305\n",
      "=== Epoch: 95===\n",
      "batch = 0, mean loss = 1.1523653100831717\n",
      "batch = 1, mean loss = 1.1523653100831717\n",
      "time per epoch: 0.040000200271606445\n",
      "=== Epoch: 96===\n",
      "batch = 0, mean loss = 1.152377543749409\n",
      "batch = 1, mean loss = 1.152377543749409\n",
      "time per epoch: 0.0409998893737793\n",
      "=== Epoch: 97===\n",
      "batch = 0, mean loss = 1.152373400626018\n",
      "batch = 1, mean loss = 1.152373400626018\n",
      "time per epoch: 0.03400111198425293\n",
      "=== Epoch: 98===\n",
      "batch = 0, mean loss = 1.1523710286363544\n",
      "batch = 1, mean loss = 1.1523710286363544\n",
      "time per epoch: 0.037000179290771484\n",
      "=== Epoch: 99===\n",
      "batch = 0, mean loss = 1.152380683160646\n",
      "batch = 1, mean loss = 1.152380683160646\n",
      "time per epoch: 0.0410003662109375\n",
      "=== Epoch: 100===\n",
      "batch = 0, mean loss = 1.1523726336915572\n",
      "batch = 1, mean loss = 1.1523726336915572\n",
      "time per epoch: 0.04099869728088379\n",
      "=== Epoch: 101===\n",
      "batch = 0, mean loss = 1.1523718308077266\n",
      "batch = 1, mean loss = 1.1523718308077266\n",
      "time per epoch: 0.039999961853027344\n",
      "=== Epoch: 102===\n",
      "batch = 0, mean loss = 1.1523760209996197\n",
      "batch = 1, mean loss = 1.1523760209996197\n",
      "time per epoch: 0.0409998893737793\n",
      "=== Epoch: 103===\n",
      "batch = 0, mean loss = 1.1523704353897983\n",
      "batch = 1, mean loss = 1.1523704353897983\n",
      "time per epoch: 0.03899979591369629\n",
      "=== Epoch: 104===\n",
      "batch = 0, mean loss = 1.152375192691658\n",
      "batch = 1, mean loss = 1.152375192691658\n",
      "time per epoch: 0.029002904891967773\n",
      "=== Epoch: 105===\n",
      "batch = 0, mean loss = 1.1523689415206144\n",
      "batch = 1, mean loss = 1.1523689415206144\n",
      "time per epoch: 0.03299450874328613\n",
      "=== Epoch: 106===\n",
      "batch = 0, mean loss = 1.1523799652840547\n",
      "batch = 1, mean loss = 1.1523799652840547\n",
      "time per epoch: 0.03100132942199707\n",
      "=== Epoch: 107===\n",
      "batch = 0, mean loss = 1.1523695007435744\n",
      "batch = 1, mean loss = 1.1523695007435744\n",
      "time per epoch: 0.041002511978149414\n",
      "=== Epoch: 108===\n",
      "batch = 0, mean loss = 1.1523681201867917\n",
      "batch = 1, mean loss = 1.1523681201867917\n",
      "time per epoch: 0.0330045223236084\n",
      "=== Epoch: 109===\n",
      "batch = 0, mean loss = 1.1523761398478294\n",
      "batch = 1, mean loss = 1.1523761398478294\n",
      "time per epoch: 0.03599095344543457\n",
      "=== Epoch: 110===\n",
      "batch = 0, mean loss = 1.152372587242168\n",
      "batch = 1, mean loss = 1.152372587242168\n",
      "time per epoch: 0.040999650955200195\n",
      "=== Epoch: 111===\n",
      "batch = 0, mean loss = 1.152371055500773\n",
      "batch = 1, mean loss = 1.152371055500773\n",
      "time per epoch: 0.031000375747680664\n",
      "=== Epoch: 112===\n",
      "batch = 0, mean loss = 1.1523717313641453\n",
      "batch = 1, mean loss = 1.1523717313641453\n",
      "time per epoch: 0.031005144119262695\n",
      "=== Epoch: 113===\n",
      "batch = 0, mean loss = 1.1523714595468284\n",
      "batch = 1, mean loss = 1.1523714595468284\n",
      "time per epoch: 0.03399538993835449\n",
      "=== Epoch: 114===\n",
      "batch = 0, mean loss = 1.1523719327421227\n",
      "batch = 1, mean loss = 1.1523719327421227\n",
      "time per epoch: 0.031004905700683594\n",
      "=== Epoch: 115===\n",
      "batch = 0, mean loss = 1.1523690601577798\n",
      "batch = 1, mean loss = 1.1523690601577798\n",
      "time per epoch: 0.0379946231842041\n",
      "=== Epoch: 116===\n",
      "batch = 0, mean loss = 1.1523794893757722\n",
      "batch = 1, mean loss = 1.1523794893757722\n",
      "time per epoch: 0.03800344467163086\n",
      "=== Epoch: 117===\n",
      "batch = 0, mean loss = 1.152393573630551\n",
      "batch = 1, mean loss = 1.152393573630551\n",
      "time per epoch: 0.03399658203125\n",
      "=== Epoch: 118===\n",
      "batch = 0, mean loss = 1.152436511787788\n",
      "batch = 1, mean loss = 1.152436511787788\n",
      "time per epoch: 0.04200005531311035\n",
      "=== Epoch: 119===\n",
      "batch = 0, mean loss = 1.1524508832690863\n",
      "batch = 1, mean loss = 1.1524508832690863\n",
      "time per epoch: 0.03519606590270996\n",
      "=== Epoch: 120===\n",
      "batch = 0, mean loss = 1.152408986713274\n",
      "batch = 1, mean loss = 1.152408986713274\n",
      "time per epoch: 0.04299616813659668\n",
      "=== Epoch: 121===\n",
      "batch = 0, mean loss = 1.1523915096784092\n",
      "batch = 1, mean loss = 1.1523915096784092\n",
      "time per epoch: 0.04300093650817871\n",
      "=== Epoch: 122===\n",
      "batch = 0, mean loss = 1.1523862957064284\n",
      "batch = 1, mean loss = 1.1523862957064284\n",
      "time per epoch: 0.03599882125854492\n",
      "=== Epoch: 123===\n",
      "batch = 0, mean loss = 1.152394217574923\n",
      "batch = 1, mean loss = 1.152394217574923\n",
      "time per epoch: 0.032000064849853516\n",
      "=== Epoch: 124===\n",
      "batch = 0, mean loss = 1.1523873274232534\n",
      "batch = 1, mean loss = 1.1523873274232534\n",
      "time per epoch: 0.0310060977935791\n",
      "=== Epoch: 125===\n",
      "batch = 0, mean loss = 1.1523806364974454\n",
      "batch = 1, mean loss = 1.1523806364974454\n",
      "time per epoch: 0.03399395942687988\n",
      "=== Epoch: 126===\n",
      "batch = 0, mean loss = 1.1523796234072348\n",
      "batch = 1, mean loss = 1.1523796234072348\n",
      "time per epoch: 0.031000137329101562\n",
      "=== Epoch: 127===\n",
      "batch = 0, mean loss = 1.1523783157472174\n",
      "batch = 1, mean loss = 1.1523783157472174\n",
      "time per epoch: 0.03300023078918457\n",
      "=== Epoch: 128===\n",
      "batch = 0, mean loss = 1.1523683163232872\n",
      "batch = 1, mean loss = 1.1523683163232872\n",
      "time per epoch: 0.0429995059967041\n",
      "=== Epoch: 129===\n",
      "batch = 0, mean loss = 1.1523755235694024\n",
      "batch = 1, mean loss = 1.1523755235694024\n",
      "time per epoch: 0.03500032424926758\n",
      "=== Epoch: 130===\n",
      "batch = 0, mean loss = 1.1523743186324644\n",
      "batch = 1, mean loss = 1.1523743186324644\n",
      "time per epoch: 0.032999515533447266\n",
      "=== Epoch: 131===\n",
      "batch = 0, mean loss = 1.152371282845385\n",
      "batch = 1, mean loss = 1.152371282845385\n",
      "time per epoch: 0.02800297737121582\n",
      "=== Epoch: 132===\n",
      "batch = 0, mean loss = 1.1523728598232386\n",
      "batch = 1, mean loss = 1.1523728598232386\n",
      "time per epoch: 0.030002832412719727\n",
      "=== Epoch: 133===\n",
      "batch = 0, mean loss = 1.1523764195648272\n",
      "batch = 1, mean loss = 1.1523764195648272\n",
      "time per epoch: 0.03299450874328613\n",
      "=== Epoch: 134===\n",
      "batch = 0, mean loss = 1.152379786488598\n",
      "batch = 1, mean loss = 1.152379786488598\n",
      "time per epoch: 0.0409998893737793\n",
      "=== Epoch: 135===\n",
      "batch = 0, mean loss = 1.1523704955788263\n",
      "batch = 1, mean loss = 1.1523704955788263\n",
      "time per epoch: 0.037000179290771484\n",
      "=== Epoch: 136===\n",
      "batch = 0, mean loss = 1.1523712205008574\n",
      "batch = 1, mean loss = 1.1523712205008574\n",
      "time per epoch: 0.028000831604003906\n",
      "=== Epoch: 137===\n",
      "batch = 0, mean loss = 1.1523745169632869\n",
      "batch = 1, mean loss = 1.1523745169632869\n",
      "time per epoch: 0.03199934959411621\n",
      "=== Epoch: 138===\n",
      "batch = 0, mean loss = 1.152366858835967\n",
      "batch = 1, mean loss = 1.152366858835967\n",
      "time per epoch: 0.031005382537841797\n",
      "=== Epoch: 139===\n",
      "batch = 0, mean loss = 1.1523715656417566\n",
      "batch = 1, mean loss = 1.1523715656417566\n",
      "time per epoch: 0.03399968147277832\n",
      "=== Epoch: 140===\n",
      "batch = 0, mean loss = 1.1523746801749022\n",
      "batch = 1, mean loss = 1.1523746801749022\n",
      "time per epoch: 0.030000686645507812\n",
      "=== Epoch: 141===\n",
      "batch = 0, mean loss = 1.1523725108924412\n",
      "batch = 1, mean loss = 1.1523725108924412\n",
      "time per epoch: 0.03299522399902344\n",
      "=== Epoch: 142===\n",
      "batch = 0, mean loss = 1.1523726237039327\n",
      "batch = 1, mean loss = 1.1523726237039327\n",
      "time per epoch: 0.030999183654785156\n",
      "=== Epoch: 143===\n",
      "batch = 0, mean loss = 1.1523699623873227\n",
      "batch = 1, mean loss = 1.1523699623873227\n",
      "time per epoch: 0.029999494552612305\n",
      "=== Epoch: 144===\n",
      "batch = 0, mean loss = 1.15237159123546\n",
      "batch = 1, mean loss = 1.15237159123546\n",
      "time per epoch: 0.038001298904418945\n",
      "=== Epoch: 145===\n",
      "batch = 0, mean loss = 1.1523736727982783\n",
      "batch = 1, mean loss = 1.1523736727982783\n",
      "time per epoch: 0.04199862480163574\n",
      "=== Epoch: 146===\n",
      "batch = 0, mean loss = 1.1523789444030585\n",
      "batch = 1, mean loss = 1.1523789444030585\n",
      "time per epoch: 0.042999982833862305\n",
      "=== Epoch: 147===\n",
      "batch = 0, mean loss = 1.1523740540856102\n",
      "batch = 1, mean loss = 1.1523740540856102\n",
      "time per epoch: 0.0409998893737793\n",
      "=== Epoch: 148===\n",
      "batch = 0, mean loss = 1.152382018314335\n",
      "batch = 1, mean loss = 1.152382018314335\n",
      "time per epoch: 0.04400062561035156\n",
      "=== Epoch: 149===\n",
      "batch = 0, mean loss = 1.1523740245476397\n",
      "batch = 1, mean loss = 1.1523740245476397\n",
      "time per epoch: 0.0449984073638916\n",
      "=== Epoch: 150===\n",
      "batch = 0, mean loss = 1.1523694585720485\n",
      "batch = 1, mean loss = 1.1523694585720485\n",
      "time per epoch: 0.04100155830383301\n",
      "=== Epoch: 151===\n",
      "batch = 0, mean loss = 1.1523694826841986\n",
      "batch = 1, mean loss = 1.1523694826841986\n",
      "time per epoch: 0.042999982833862305\n",
      "=== Epoch: 152===\n",
      "batch = 0, mean loss = 1.1523761097415275\n",
      "batch = 1, mean loss = 1.1523761097415275\n",
      "time per epoch: 0.04300093650817871\n",
      "=== Epoch: 153===\n",
      "batch = 0, mean loss = 1.152369651975433\n",
      "batch = 1, mean loss = 1.152369651975433\n",
      "time per epoch: 0.04099845886230469\n",
      "=== Epoch: 154===\n",
      "batch = 0, mean loss = 1.1523721226263137\n",
      "batch = 1, mean loss = 1.1523721226263137\n",
      "time per epoch: 0.04199862480163574\n",
      "=== Epoch: 155===\n",
      "batch = 0, mean loss = 1.152369032498268\n",
      "batch = 1, mean loss = 1.152369032498268\n",
      "time per epoch: 0.039006710052490234\n",
      "=== Epoch: 156===\n",
      "batch = 0, mean loss = 1.1523724670766282\n",
      "batch = 1, mean loss = 1.1523724670766282\n",
      "time per epoch: 0.04306340217590332\n",
      "=== Epoch: 157===\n",
      "batch = 0, mean loss = 1.1523868710813345\n",
      "batch = 1, mean loss = 1.1523868710813345\n",
      "time per epoch: 0.04300069808959961\n",
      "=== Epoch: 158===\n",
      "batch = 0, mean loss = 1.1523693274717481\n",
      "batch = 1, mean loss = 1.1523693274717481\n",
      "time per epoch: 0.03399968147277832\n",
      "=== Epoch: 159===\n",
      "batch = 0, mean loss = 1.152368118485919\n",
      "batch = 1, mean loss = 1.152368118485919\n",
      "time per epoch: 0.031999826431274414\n",
      "=== Epoch: 160===\n",
      "batch = 0, mean loss = 1.1523731945077382\n",
      "batch = 1, mean loss = 1.1523731945077382\n",
      "time per epoch: 0.03599977493286133\n",
      "=== Epoch: 161===\n",
      "batch = 0, mean loss = 1.1523738294849866\n",
      "batch = 1, mean loss = 1.1523738294849866\n",
      "time per epoch: 0.037000417709350586\n",
      "=== Epoch: 162===\n",
      "batch = 0, mean loss = 1.1523694152313353\n",
      "batch = 1, mean loss = 1.1523694152313353\n",
      "time per epoch: 0.037000179290771484\n",
      "=== Epoch: 163===\n",
      "batch = 0, mean loss = 1.1523705406275515\n",
      "batch = 1, mean loss = 1.1523705406275515\n",
      "time per epoch: 0.03199958801269531\n",
      "=== Epoch: 164===\n",
      "batch = 0, mean loss = 1.1523765167253939\n",
      "batch = 1, mean loss = 1.1523765167253939\n",
      "time per epoch: 0.03600001335144043\n",
      "=== Epoch: 165===\n",
      "batch = 0, mean loss = 1.1523742063379088\n",
      "batch = 1, mean loss = 1.1523742063379088\n",
      "time per epoch: 0.03299975395202637\n",
      "=== Epoch: 166===\n",
      "batch = 0, mean loss = 1.1523655600221336\n",
      "batch = 1, mean loss = 1.1523655600221336\n",
      "time per epoch: 0.029000043869018555\n",
      "=== Epoch: 167===\n",
      "batch = 0, mean loss = 1.1523776549780866\n",
      "batch = 1, mean loss = 1.1523776549780866\n",
      "time per epoch: 0.032001495361328125\n",
      "=== Epoch: 168===\n",
      "batch = 0, mean loss = 1.1523788942401136\n",
      "batch = 1, mean loss = 1.1523788942401136\n",
      "time per epoch: 0.03600430488586426\n",
      "=== Epoch: 169===\n",
      "batch = 0, mean loss = 1.152368625389533\n",
      "batch = 1, mean loss = 1.152368625389533\n",
      "time per epoch: 0.03999447822570801\n",
      "=== Epoch: 170===\n",
      "batch = 0, mean loss = 1.1523721007422318\n",
      "batch = 1, mean loss = 1.1523721007422318\n",
      "time per epoch: 0.031999826431274414\n",
      "=== Epoch: 171===\n",
      "batch = 0, mean loss = 1.1523685049979098\n",
      "batch = 1, mean loss = 1.1523685049979098\n",
      "time per epoch: 0.039999961853027344\n",
      "=== Epoch: 172===\n",
      "batch = 0, mean loss = 1.1523677106790233\n",
      "batch = 1, mean loss = 1.1523677106790233\n",
      "time per epoch: 0.029000043869018555\n",
      "=== Epoch: 173===\n",
      "batch = 0, mean loss = 1.1523728074156412\n",
      "batch = 1, mean loss = 1.1523728074156412\n",
      "time per epoch: 0.03299999237060547\n",
      "=== Epoch: 174===\n",
      "batch = 0, mean loss = 1.152371965106851\n",
      "batch = 1, mean loss = 1.152371965106851\n",
      "time per epoch: 0.040000200271606445\n",
      "=== Epoch: 175===\n",
      "batch = 0, mean loss = 1.152373950557646\n",
      "batch = 1, mean loss = 1.152373950557646\n",
      "time per epoch: 0.03300166130065918\n",
      "=== Epoch: 176===\n",
      "batch = 0, mean loss = 1.15237618967552\n",
      "batch = 1, mean loss = 1.15237618967552\n",
      "time per epoch: 0.03599834442138672\n",
      "=== Epoch: 177===\n",
      "batch = 0, mean loss = 1.152368019976973\n",
      "batch = 1, mean loss = 1.152368019976973\n",
      "time per epoch: 0.03899979591369629\n",
      "=== Epoch: 178===\n",
      "batch = 0, mean loss = 1.1523713640401843\n",
      "batch = 1, mean loss = 1.1523713640401843\n",
      "time per epoch: 0.040000200271606445\n",
      "=== Epoch: 179===\n",
      "batch = 0, mean loss = 1.1523674542290963\n",
      "batch = 1, mean loss = 1.1523674542290963\n",
      "time per epoch: 0.03900027275085449\n",
      "=== Epoch: 180===\n",
      "batch = 0, mean loss = 1.1523730251097914\n",
      "batch = 1, mean loss = 1.1523730251097914\n",
      "time per epoch: 0.0390012264251709\n",
      "=== Epoch: 181===\n",
      "batch = 0, mean loss = 1.1523675615159152\n",
      "batch = 1, mean loss = 1.1523675615159152\n",
      "time per epoch: 0.034998178482055664\n",
      "=== Epoch: 182===\n",
      "batch = 0, mean loss = 1.1523658282687301\n",
      "batch = 1, mean loss = 1.1523658282687301\n",
      "time per epoch: 0.03300023078918457\n",
      "=== Epoch: 183===\n",
      "batch = 0, mean loss = 1.1523776960187786\n",
      "batch = 1, mean loss = 1.1523776960187786\n",
      "time per epoch: 0.029000282287597656\n",
      "=== Epoch: 184===\n",
      "batch = 0, mean loss = 1.1523670058313984\n",
      "batch = 1, mean loss = 1.1523670058313984\n",
      "time per epoch: 0.02899956703186035\n",
      "=== Epoch: 185===\n",
      "batch = 0, mean loss = 1.1523665605562836\n",
      "batch = 1, mean loss = 1.1523665605562836\n",
      "time per epoch: 0.029000282287597656\n",
      "=== Epoch: 186===\n",
      "batch = 0, mean loss = 1.1523692575334334\n",
      "batch = 1, mean loss = 1.1523692575334334\n",
      "time per epoch: 0.028000831604003906\n",
      "=== Epoch: 187===\n",
      "batch = 0, mean loss = 1.152372009083861\n",
      "batch = 1, mean loss = 1.152372009083861\n",
      "time per epoch: 0.02900385856628418\n",
      "=== Epoch: 188===\n",
      "batch = 0, mean loss = 1.152370915460843\n",
      "batch = 1, mean loss = 1.152370915460843\n",
      "time per epoch: 0.029995203018188477\n",
      "=== Epoch: 189===\n",
      "batch = 0, mean loss = 1.1523656361183183\n",
      "batch = 1, mean loss = 1.1523656361183183\n",
      "time per epoch: 0.037999868392944336\n",
      "=== Epoch: 190===\n",
      "batch = 0, mean loss = 1.1523704340904513\n",
      "batch = 1, mean loss = 1.1523704340904513\n",
      "time per epoch: 0.027000904083251953\n",
      "=== Epoch: 191===\n",
      "batch = 0, mean loss = 1.15237319808775\n",
      "batch = 1, mean loss = 1.15237319808775\n",
      "time per epoch: 0.03299903869628906\n",
      "=== Epoch: 192===\n",
      "batch = 0, mean loss = 1.1523681076912538\n",
      "batch = 1, mean loss = 1.1523681076912538\n",
      "time per epoch: 0.034999847412109375\n",
      "=== Epoch: 193===\n",
      "batch = 0, mean loss = 1.1523693257282583\n",
      "batch = 1, mean loss = 1.1523693257282583\n",
      "time per epoch: 0.02700495719909668\n",
      "=== Epoch: 194===\n",
      "batch = 0, mean loss = 1.1523692831395262\n",
      "batch = 1, mean loss = 1.1523692831395262\n",
      "time per epoch: 0.03899526596069336\n",
      "=== Epoch: 195===\n",
      "batch = 0, mean loss = 1.1523658097068468\n",
      "batch = 1, mean loss = 1.1523658097068468\n",
      "time per epoch: 0.03599905967712402\n",
      "=== Epoch: 196===\n",
      "batch = 0, mean loss = 1.1523762672319562\n",
      "batch = 1, mean loss = 1.1523762672319562\n",
      "time per epoch: 0.03607058525085449\n",
      "=== Epoch: 197===\n",
      "batch = 0, mean loss = 1.152367542312257\n",
      "batch = 1, mean loss = 1.152367542312257\n",
      "time per epoch: 0.029000043869018555\n",
      "=== Epoch: 198===\n",
      "batch = 0, mean loss = 1.1523669687755596\n",
      "batch = 1, mean loss = 1.1523669687755596\n",
      "time per epoch: 0.030003070831298828\n",
      "=== Epoch: 199===\n",
      "batch = 0, mean loss = 1.1523755080489209\n",
      "batch = 1, mean loss = 1.1523755080489209\n",
      "time per epoch: 0.029999732971191406\n",
      "=== Epoch: 200===\n",
      "batch = 0, mean loss = 1.1523671953144288\n",
      "batch = 1, mean loss = 1.1523671953144288\n",
      "time per epoch: 0.031999826431274414\n",
      "=== Epoch: 201===\n",
      "batch = 0, mean loss = 1.152366344442832\n",
      "batch = 1, mean loss = 1.152366344442832\n",
      "time per epoch: 0.03199434280395508\n",
      "=== Epoch: 202===\n",
      "batch = 0, mean loss = 1.1523698846671746\n",
      "batch = 1, mean loss = 1.1523698846671746\n",
      "time per epoch: 0.03700590133666992\n",
      "=== Epoch: 203===\n",
      "batch = 0, mean loss = 1.1523724137694282\n",
      "batch = 1, mean loss = 1.1523724137694282\n",
      "time per epoch: 0.04199481010437012\n",
      "=== Epoch: 204===\n",
      "batch = 0, mean loss = 1.1523694508226545\n",
      "batch = 1, mean loss = 1.1523694508226545\n",
      "time per epoch: 0.035999298095703125\n",
      "=== Epoch: 205===\n",
      "batch = 0, mean loss = 1.1523674846813448\n",
      "batch = 1, mean loss = 1.1523674846813448\n",
      "time per epoch: 0.04200005531311035\n",
      "=== Epoch: 206===\n",
      "batch = 0, mean loss = 1.1523694838860834\n",
      "batch = 1, mean loss = 1.1523694838860834\n",
      "time per epoch: 0.030005693435668945\n",
      "=== Epoch: 207===\n",
      "batch = 0, mean loss = 1.1523719288960528\n",
      "batch = 1, mean loss = 1.1523719288960528\n",
      "time per epoch: 0.0379941463470459\n",
      "=== Epoch: 208===\n",
      "batch = 0, mean loss = 1.152368535290357\n",
      "batch = 1, mean loss = 1.152368535290357\n",
      "time per epoch: 0.04200029373168945\n",
      "=== Epoch: 209===\n",
      "batch = 0, mean loss = 1.1523686857417799\n",
      "batch = 1, mean loss = 1.1523686857417799\n",
      "time per epoch: 0.03000020980834961\n",
      "=== Epoch: 210===\n",
      "batch = 0, mean loss = 1.152368168983362\n",
      "batch = 1, mean loss = 1.152368168983362\n",
      "time per epoch: 0.029999494552612305\n",
      "=== Epoch: 211===\n",
      "batch = 0, mean loss = 1.1523692742665776\n",
      "batch = 1, mean loss = 1.1523692742665776\n",
      "time per epoch: 0.029000043869018555\n",
      "=== Epoch: 212===\n",
      "batch = 0, mean loss = 1.152374162641193\n",
      "batch = 1, mean loss = 1.152374162641193\n",
      "time per epoch: 0.029000043869018555\n",
      "=== Epoch: 213===\n",
      "batch = 0, mean loss = 1.152369173140751\n",
      "batch = 1, mean loss = 1.152369173140751\n",
      "time per epoch: 0.03099989891052246\n",
      "=== Epoch: 214===\n",
      "batch = 0, mean loss = 1.1523685706228435\n",
      "batch = 1, mean loss = 1.1523685706228435\n",
      "time per epoch: 0.029000043869018555\n",
      "=== Epoch: 215===\n",
      "batch = 0, mean loss = 1.1523709326975782\n",
      "batch = 1, mean loss = 1.1523709326975782\n",
      "time per epoch: 0.02700018882751465\n",
      "=== Epoch: 216===\n",
      "batch = 0, mean loss = 1.1523665802952698\n",
      "batch = 1, mean loss = 1.1523665802952698\n",
      "time per epoch: 0.03399991989135742\n",
      "=== Epoch: 217===\n",
      "batch = 0, mean loss = 1.1523713951421395\n",
      "batch = 1, mean loss = 1.1523713951421395\n",
      "time per epoch: 0.03400230407714844\n",
      "=== Epoch: 218===\n",
      "batch = 0, mean loss = 1.1523700408312072\n",
      "batch = 1, mean loss = 1.1523700408312072\n",
      "time per epoch: 0.02699732780456543\n",
      "=== Epoch: 219===\n",
      "batch = 0, mean loss = 1.1523688495688282\n",
      "batch = 1, mean loss = 1.1523688495688282\n",
      "time per epoch: 0.02599930763244629\n",
      "=== Epoch: 220===\n",
      "batch = 0, mean loss = 1.1523750937681725\n",
      "batch = 1, mean loss = 1.1523750937681725\n",
      "time per epoch: 0.029001235961914062\n",
      "=== Epoch: 221===\n",
      "batch = 0, mean loss = 1.1523781164690035\n",
      "batch = 1, mean loss = 1.1523781164690035\n",
      "time per epoch: 0.02600240707397461\n",
      "=== Epoch: 222===\n",
      "batch = 0, mean loss = 1.152390698049964\n",
      "batch = 1, mean loss = 1.152390698049964\n",
      "time per epoch: 0.03200101852416992\n",
      "=== Epoch: 223===\n",
      "batch = 0, mean loss = 1.1523731321013608\n",
      "batch = 1, mean loss = 1.1523731321013608\n",
      "time per epoch: 0.027998924255371094\n",
      "=== Epoch: 224===\n",
      "batch = 0, mean loss = 1.152372616838547\n",
      "batch = 1, mean loss = 1.152372616838547\n",
      "time per epoch: 0.028002500534057617\n",
      "=== Epoch: 225===\n",
      "batch = 0, mean loss = 1.1523810103582302\n",
      "batch = 1, mean loss = 1.1523810103582302\n",
      "time per epoch: 0.0279996395111084\n",
      "=== Epoch: 226===\n",
      "batch = 0, mean loss = 1.1523754078739084\n",
      "batch = 1, mean loss = 1.1523754078739084\n",
      "time per epoch: 0.027068138122558594\n",
      "=== Epoch: 227===\n",
      "batch = 0, mean loss = 1.152369240383178\n",
      "batch = 1, mean loss = 1.152369240383178\n",
      "time per epoch: 0.026998519897460938\n",
      "=== Epoch: 228===\n",
      "batch = 0, mean loss = 1.1523731381863191\n",
      "batch = 1, mean loss = 1.1523731381863191\n",
      "time per epoch: 0.02700185775756836\n",
      "=== Epoch: 229===\n",
      "batch = 0, mean loss = 1.1523684057568668\n",
      "batch = 1, mean loss = 1.1523684057568668\n",
      "time per epoch: 0.026999950408935547\n",
      "=== Epoch: 230===\n",
      "batch = 0, mean loss = 1.152370117022074\n",
      "batch = 1, mean loss = 1.152370117022074\n",
      "time per epoch: 0.02599930763244629\n",
      "=== Epoch: 231===\n",
      "batch = 0, mean loss = 1.1523724183526212\n",
      "batch = 1, mean loss = 1.1523724183526212\n",
      "time per epoch: 0.02700018882751465\n",
      "=== Epoch: 232===\n",
      "batch = 0, mean loss = 1.1523696714041638\n",
      "batch = 1, mean loss = 1.1523696714041638\n",
      "time per epoch: 0.027000904083251953\n",
      "=== Epoch: 233===\n",
      "batch = 0, mean loss = 1.1523679566231102\n",
      "batch = 1, mean loss = 1.1523679566231102\n",
      "time per epoch: 0.02800130844116211\n",
      "=== Epoch: 234===\n",
      "batch = 0, mean loss = 1.1523708061202091\n",
      "batch = 1, mean loss = 1.1523708061202091\n",
      "time per epoch: 0.02799820899963379\n",
      "=== Epoch: 235===\n",
      "batch = 0, mean loss = 1.152369434965218\n",
      "batch = 1, mean loss = 1.152369434965218\n",
      "time per epoch: 0.030994653701782227\n",
      "=== Epoch: 236===\n",
      "batch = 0, mean loss = 1.152369902377858\n",
      "batch = 1, mean loss = 1.152369902377858\n",
      "time per epoch: 0.02700042724609375\n",
      "=== Epoch: 237===\n",
      "batch = 0, mean loss = 1.1523728211662343\n",
      "batch = 1, mean loss = 1.1523728211662343\n",
      "time per epoch: 0.03500032424926758\n",
      "=== Epoch: 238===\n",
      "batch = 0, mean loss = 1.1523699807862513\n",
      "batch = 1, mean loss = 1.1523699807862513\n",
      "time per epoch: 0.028998613357543945\n",
      "=== Epoch: 239===\n",
      "batch = 0, mean loss = 1.1523728611938755\n",
      "batch = 1, mean loss = 1.1523728611938755\n",
      "time per epoch: 0.03500223159790039\n",
      "=== Epoch: 240===\n",
      "batch = 0, mean loss = 1.1523677456369097\n",
      "batch = 1, mean loss = 1.1523677456369097\n",
      "time per epoch: 0.038607120513916016\n",
      "=== Epoch: 241===\n",
      "batch = 0, mean loss = 1.1523702878887583\n",
      "batch = 1, mean loss = 1.1523702878887583\n",
      "time per epoch: 0.040999412536621094\n",
      "=== Epoch: 242===\n",
      "batch = 0, mean loss = 1.1523764904894542\n",
      "batch = 1, mean loss = 1.1523764904894542\n",
      "time per epoch: 0.039999961853027344\n",
      "=== Epoch: 243===\n",
      "batch = 0, mean loss = 1.1523710454634557\n",
      "batch = 1, mean loss = 1.1523710454634557\n",
      "time per epoch: 0.037000417709350586\n",
      "=== Epoch: 244===\n",
      "batch = 0, mean loss = 1.152368849259547\n",
      "batch = 1, mean loss = 1.152368849259547\n",
      "time per epoch: 0.03399968147277832\n",
      "=== Epoch: 245===\n",
      "batch = 0, mean loss = 1.1523700775558565\n",
      "batch = 1, mean loss = 1.1523700775558565\n",
      "time per epoch: 0.03699994087219238\n",
      "=== Epoch: 246===\n",
      "batch = 0, mean loss = 1.1523660161260811\n",
      "batch = 1, mean loss = 1.1523660161260811\n",
      "time per epoch: 0.031006574630737305\n",
      "=== Epoch: 247===\n",
      "batch = 0, mean loss = 1.152370057897246\n",
      "batch = 1, mean loss = 1.152370057897246\n",
      "time per epoch: 0.029993772506713867\n",
      "=== Epoch: 248===\n",
      "batch = 0, mean loss = 1.1523721016881603\n",
      "batch = 1, mean loss = 1.1523721016881603\n",
      "time per epoch: 0.031999826431274414\n",
      "=== Epoch: 249===\n",
      "batch = 0, mean loss = 1.1523720481550814\n",
      "batch = 1, mean loss = 1.1523720481550814\n",
      "time per epoch: 0.03599977493286133\n",
      "=== Epoch: 250===\n",
      "batch = 0, mean loss = 1.1523710500532873\n",
      "batch = 1, mean loss = 1.1523710500532873\n",
      "time per epoch: 0.037999868392944336\n",
      "=== Epoch: 251===\n",
      "batch = 0, mean loss = 1.15236877723769\n",
      "batch = 1, mean loss = 1.15236877723769\n",
      "time per epoch: 0.03451108932495117\n",
      "=== Epoch: 252===\n",
      "batch = 0, mean loss = 1.1523678955193613\n",
      "batch = 1, mean loss = 1.1523678955193613\n",
      "time per epoch: 0.03851485252380371\n",
      "=== Epoch: 253===\n",
      "batch = 0, mean loss = 1.1523683685689903\n",
      "batch = 1, mean loss = 1.1523683685689903\n",
      "time per epoch: 0.030000686645507812\n",
      "=== Epoch: 254===\n",
      "batch = 0, mean loss = 1.1523749287914296\n",
      "batch = 1, mean loss = 1.1523749287914296\n",
      "time per epoch: 0.030002355575561523\n",
      "=== Epoch: 255===\n",
      "batch = 0, mean loss = 1.152370238812538\n",
      "batch = 1, mean loss = 1.152370238812538\n",
      "time per epoch: 0.030995607376098633\n",
      "=== Epoch: 256===\n",
      "batch = 0, mean loss = 1.1523675272709126\n",
      "batch = 1, mean loss = 1.1523675272709126\n",
      "time per epoch: 0.03400397300720215\n",
      "=== Epoch: 257===\n",
      "batch = 0, mean loss = 1.1523742895641877\n",
      "batch = 1, mean loss = 1.1523742895641877\n",
      "time per epoch: 0.025998353958129883\n",
      "=== Epoch: 258===\n",
      "batch = 0, mean loss = 1.1523723313359473\n",
      "batch = 1, mean loss = 1.1523723313359473\n",
      "time per epoch: 0.02599930763244629\n",
      "=== Epoch: 259===\n",
      "batch = 0, mean loss = 1.152369537980771\n",
      "batch = 1, mean loss = 1.152369537980771\n",
      "time per epoch: 0.02700018882751465\n",
      "=== Epoch: 260===\n",
      "batch = 0, mean loss = 1.1523738897986493\n",
      "batch = 1, mean loss = 1.1523738897986493\n",
      "time per epoch: 0.028001070022583008\n",
      "=== Epoch: 261===\n",
      "batch = 0, mean loss = 1.1523712974396447\n",
      "batch = 1, mean loss = 1.1523712974396447\n",
      "time per epoch: 0.027994394302368164\n",
      "=== Epoch: 262===\n",
      "batch = 0, mean loss = 1.1523649800369067\n",
      "batch = 1, mean loss = 1.1523649800369067\n",
      "time per epoch: 0.02599954605102539\n",
      "=== Epoch: 263===\n",
      "batch = 0, mean loss = 1.1523697366729613\n",
      "batch = 1, mean loss = 1.1523697366729613\n",
      "time per epoch: 0.03000044822692871\n",
      "=== Epoch: 264===\n",
      "batch = 0, mean loss = 1.152371708923878\n",
      "batch = 1, mean loss = 1.152371708923878\n",
      "time per epoch: 0.03500008583068848\n",
      "=== Epoch: 265===\n",
      "batch = 0, mean loss = 1.1523677919041697\n",
      "batch = 1, mean loss = 1.1523677919041697\n",
      "time per epoch: 0.03899979591369629\n",
      "=== Epoch: 266===\n",
      "batch = 0, mean loss = 1.15237372836281\n",
      "batch = 1, mean loss = 1.15237372836281\n",
      "time per epoch: 0.03899979591369629\n",
      "=== Epoch: 267===\n",
      "batch = 0, mean loss = 1.1523695034486106\n",
      "batch = 1, mean loss = 1.1523695034486106\n",
      "time per epoch: 0.031000614166259766\n",
      "=== Epoch: 268===\n",
      "batch = 0, mean loss = 1.1523653750130796\n",
      "batch = 1, mean loss = 1.1523653750130796\n",
      "time per epoch: 0.0409998893737793\n",
      "=== Epoch: 269===\n",
      "batch = 0, mean loss = 1.1523725840769339\n",
      "batch = 1, mean loss = 1.1523725840769339\n",
      "time per epoch: 0.03699994087219238\n",
      "=== Epoch: 270===\n",
      "batch = 0, mean loss = 1.1523729158300684\n",
      "batch = 1, mean loss = 1.1523729158300684\n",
      "time per epoch: 0.03200030326843262\n",
      "=== Epoch: 271===\n",
      "batch = 0, mean loss = 1.1523689885423753\n",
      "batch = 1, mean loss = 1.1523689885423753\n",
      "time per epoch: 0.03999972343444824\n",
      "=== Epoch: 272===\n",
      "batch = 0, mean loss = 1.152371231199956\n",
      "batch = 1, mean loss = 1.152371231199956\n",
      "time per epoch: 0.02900552749633789\n",
      "=== Epoch: 273===\n",
      "batch = 0, mean loss = 1.1523671065282595\n",
      "batch = 1, mean loss = 1.1523671065282595\n",
      "time per epoch: 0.02899789810180664\n",
      "=== Epoch: 274===\n",
      "batch = 0, mean loss = 1.152369084691955\n",
      "batch = 1, mean loss = 1.152369084691955\n",
      "time per epoch: 0.034995079040527344\n",
      "=== Epoch: 275===\n",
      "batch = 0, mean loss = 1.1523727800965\n",
      "batch = 1, mean loss = 1.1523727800965\n",
      "time per epoch: 0.03700137138366699\n",
      "=== Epoch: 276===\n",
      "batch = 0, mean loss = 1.1523662439054176\n",
      "batch = 1, mean loss = 1.1523662439054176\n",
      "time per epoch: 0.03699970245361328\n",
      "=== Epoch: 277===\n",
      "batch = 0, mean loss = 1.1523693057573046\n",
      "batch = 1, mean loss = 1.1523693057573046\n",
      "time per epoch: 0.026000261306762695\n",
      "=== Epoch: 278===\n",
      "batch = 0, mean loss = 1.152369083127049\n",
      "batch = 1, mean loss = 1.152369083127049\n",
      "time per epoch: 0.027998685836791992\n",
      "=== Epoch: 279===\n",
      "batch = 0, mean loss = 1.1523757600231272\n",
      "batch = 1, mean loss = 1.1523757600231272\n",
      "time per epoch: 0.03100109100341797\n",
      "=== Epoch: 280===\n",
      "batch = 0, mean loss = 1.1523702662304731\n",
      "batch = 1, mean loss = 1.1523702662304731\n",
      "time per epoch: 0.03500008583068848\n",
      "=== Epoch: 281===\n",
      "batch = 0, mean loss = 1.1523668437775871\n",
      "batch = 1, mean loss = 1.1523668437775871\n",
      "time per epoch: 0.03505682945251465\n",
      "=== Epoch: 282===\n",
      "batch = 0, mean loss = 1.1523695281070307\n",
      "batch = 1, mean loss = 1.1523695281070307\n",
      "time per epoch: 0.029005050659179688\n",
      "=== Epoch: 283===\n",
      "batch = 0, mean loss = 1.1523667844242849\n",
      "batch = 1, mean loss = 1.1523667844242849\n",
      "time per epoch: 0.02899479866027832\n",
      "=== Epoch: 284===\n",
      "batch = 0, mean loss = 1.1523678820822334\n",
      "batch = 1, mean loss = 1.1523678820822334\n",
      "time per epoch: 0.03300023078918457\n",
      "=== Epoch: 285===\n",
      "batch = 0, mean loss = 1.1523717431878995\n",
      "batch = 1, mean loss = 1.1523717431878995\n",
      "time per epoch: 0.026999711990356445\n",
      "=== Epoch: 286===\n",
      "batch = 0, mean loss = 1.1523659589265474\n",
      "batch = 1, mean loss = 1.1523659589265474\n",
      "time per epoch: 0.027006149291992188\n",
      "=== Epoch: 287===\n",
      "batch = 0, mean loss = 1.1523698085632614\n",
      "batch = 1, mean loss = 1.1523698085632614\n",
      "time per epoch: 0.028994083404541016\n",
      "=== Epoch: 288===\n",
      "batch = 0, mean loss = 1.152368214869916\n",
      "batch = 1, mean loss = 1.152368214869916\n",
      "time per epoch: 0.03800010681152344\n",
      "=== Epoch: 289===\n",
      "batch = 0, mean loss = 1.1523722033431918\n",
      "batch = 1, mean loss = 1.1523722033431918\n",
      "time per epoch: 0.032004356384277344\n",
      "=== Epoch: 290===\n",
      "batch = 0, mean loss = 1.1523690425688247\n",
      "batch = 1, mean loss = 1.1523690425688247\n",
      "time per epoch: 0.03699541091918945\n",
      "=== Epoch: 291===\n",
      "batch = 0, mean loss = 1.1523675348366615\n",
      "batch = 1, mean loss = 1.1523675348366615\n",
      "time per epoch: 0.031000137329101562\n",
      "=== Epoch: 292===\n",
      "batch = 0, mean loss = 1.1523684027344887\n",
      "batch = 1, mean loss = 1.1523684027344887\n",
      "time per epoch: 0.03000044822692871\n",
      "=== Epoch: 293===\n",
      "batch = 0, mean loss = 1.152366992285009\n",
      "batch = 1, mean loss = 1.152366992285009\n",
      "time per epoch: 0.029000282287597656\n",
      "=== Epoch: 294===\n",
      "batch = 0, mean loss = 1.1523677701154003\n",
      "batch = 1, mean loss = 1.1523677701154003\n",
      "time per epoch: 0.0330047607421875\n",
      "=== Epoch: 295===\n",
      "batch = 0, mean loss = 1.1523740176647341\n",
      "batch = 1, mean loss = 1.1523740176647341\n",
      "time per epoch: 0.030999183654785156\n",
      "=== Epoch: 296===\n",
      "batch = 0, mean loss = 1.1523685030019544\n",
      "batch = 1, mean loss = 1.1523685030019544\n",
      "time per epoch: 0.03299546241760254\n",
      "=== Epoch: 297===\n",
      "batch = 0, mean loss = 1.152367182908398\n",
      "batch = 1, mean loss = 1.152367182908398\n",
      "time per epoch: 0.031999826431274414\n",
      "=== Epoch: 298===\n",
      "batch = 0, mean loss = 1.1523686227400323\n",
      "batch = 1, mean loss = 1.1523686227400323\n",
      "time per epoch: 0.030009031295776367\n",
      "=== Epoch: 299===\n",
      "batch = 0, mean loss = 1.1523679175702077\n",
      "batch = 1, mean loss = 1.1523679175702077\n",
      "time per epoch: 0.02999734878540039\n",
      "=== Epoch: 300===\n",
      "batch = 0, mean loss = 1.1523766468142007\n",
      "batch = 1, mean loss = 1.1523766468142007\n",
      "time per epoch: 0.03499245643615723\n",
      "=== Epoch: 301===\n",
      "batch = 0, mean loss = 1.1523691679899166\n",
      "batch = 1, mean loss = 1.1523691679899166\n",
      "time per epoch: 0.033000946044921875\n",
      "=== Epoch: 302===\n",
      "batch = 0, mean loss = 1.1523660694767142\n",
      "batch = 1, mean loss = 1.1523660694767142\n",
      "time per epoch: 0.03800010681152344\n",
      "=== Epoch: 303===\n",
      "batch = 0, mean loss = 1.1523693419180663\n",
      "batch = 1, mean loss = 1.1523693419180663\n",
      "time per epoch: 0.03800177574157715\n",
      "=== Epoch: 304===\n",
      "batch = 0, mean loss = 1.1523678677637847\n",
      "batch = 1, mean loss = 1.1523678677637847\n",
      "time per epoch: 0.0319972038269043\n",
      "=== Epoch: 305===\n",
      "batch = 0, mean loss = 1.1523715388097646\n",
      "batch = 1, mean loss = 1.1523715388097646\n",
      "time per epoch: 0.03800177574157715\n",
      "=== Epoch: 306===\n",
      "batch = 0, mean loss = 1.152368827312137\n",
      "batch = 1, mean loss = 1.152368827312137\n",
      "time per epoch: 0.03699970245361328\n",
      "=== Epoch: 307===\n",
      "batch = 0, mean loss = 1.1523670207360606\n",
      "batch = 1, mean loss = 1.1523670207360606\n",
      "time per epoch: 0.03199958801269531\n",
      "=== Epoch: 308===\n",
      "batch = 0, mean loss = 1.1523685629964437\n",
      "batch = 1, mean loss = 1.1523685629964437\n",
      "time per epoch: 0.02700018882751465\n",
      "=== Epoch: 309===\n",
      "batch = 0, mean loss = 1.1523656551837094\n",
      "batch = 1, mean loss = 1.1523656551837094\n",
      "time per epoch: 0.029999732971191406\n",
      "=== Epoch: 310===\n",
      "batch = 0, mean loss = 1.1523730170528996\n",
      "batch = 1, mean loss = 1.1523730170528996\n",
      "time per epoch: 0.030005931854248047\n",
      "=== Epoch: 311===\n",
      "batch = 0, mean loss = 1.1523694993329099\n",
      "batch = 1, mean loss = 1.1523694993329099\n",
      "time per epoch: 0.027998924255371094\n",
      "=== Epoch: 312===\n",
      "batch = 0, mean loss = 1.1523654200201432\n",
      "batch = 1, mean loss = 1.1523654200201432\n",
      "time per epoch: 0.029001951217651367\n",
      "=== Epoch: 313===\n",
      "batch = 0, mean loss = 1.1523696533326966\n",
      "batch = 1, mean loss = 1.1523696533326966\n",
      "time per epoch: 0.034993886947631836\n",
      "=== Epoch: 314===\n",
      "batch = 0, mean loss = 1.1523687847801254\n",
      "batch = 1, mean loss = 1.1523687847801254\n",
      "time per epoch: 0.03300023078918457\n",
      "=== Epoch: 315===\n",
      "batch = 0, mean loss = 1.152368154101673\n",
      "batch = 1, mean loss = 1.152368154101673\n",
      "time per epoch: 0.035999298095703125\n",
      "=== Epoch: 316===\n",
      "batch = 0, mean loss = 1.1523699582127833\n",
      "batch = 1, mean loss = 1.1523699582127833\n",
      "time per epoch: 0.037000179290771484\n",
      "=== Epoch: 317===\n",
      "batch = 0, mean loss = 1.152368112168825\n",
      "batch = 1, mean loss = 1.152368112168825\n",
      "time per epoch: 0.03500008583068848\n",
      "=== Epoch: 318===\n",
      "batch = 0, mean loss = 1.152366987369907\n",
      "batch = 1, mean loss = 1.152366987369907\n",
      "time per epoch: 0.03400015830993652\n",
      "=== Epoch: 319===\n",
      "batch = 0, mean loss = 1.1523672305477746\n",
      "batch = 1, mean loss = 1.1523672305477746\n",
      "time per epoch: 0.0319981575012207\n",
      "=== Epoch: 320===\n",
      "batch = 0, mean loss = 1.1523673257123197\n",
      "batch = 1, mean loss = 1.1523673257123197\n",
      "time per epoch: 0.03400158882141113\n",
      "=== Epoch: 321===\n",
      "batch = 0, mean loss = 1.1523715376612356\n",
      "batch = 1, mean loss = 1.1523715376612356\n",
      "time per epoch: 0.03399991989135742\n",
      "=== Epoch: 322===\n",
      "batch = 0, mean loss = 1.1523692232640517\n",
      "batch = 1, mean loss = 1.1523692232640517\n",
      "time per epoch: 0.031999826431274414\n",
      "=== Epoch: 323===\n",
      "batch = 0, mean loss = 1.1523661119786026\n",
      "batch = 1, mean loss = 1.1523661119786026\n",
      "time per epoch: 0.02907252311706543\n",
      "=== Epoch: 324===\n",
      "batch = 0, mean loss = 1.1523693904268617\n",
      "batch = 1, mean loss = 1.1523693904268617\n",
      "time per epoch: 0.03500032424926758\n",
      "=== Epoch: 325===\n",
      "batch = 0, mean loss = 1.152368991583158\n",
      "batch = 1, mean loss = 1.152368991583158\n",
      "time per epoch: 0.03899955749511719\n",
      "=== Epoch: 326===\n",
      "batch = 0, mean loss = 1.152376270028022\n",
      "batch = 1, mean loss = 1.152376270028022\n",
      "time per epoch: 0.029000520706176758\n",
      "=== Epoch: 327===\n",
      "batch = 0, mean loss = 1.152380065711506\n",
      "batch = 1, mean loss = 1.152380065711506\n",
      "time per epoch: 0.03400015830993652\n",
      "=== Epoch: 328===\n",
      "batch = 0, mean loss = 1.1523748559537872\n",
      "batch = 1, mean loss = 1.1523748559537872\n",
      "time per epoch: 0.03399944305419922\n",
      "=== Epoch: 329===\n",
      "batch = 0, mean loss = 1.1523720747390185\n",
      "batch = 1, mean loss = 1.1523720747390185\n",
      "time per epoch: 0.03899979591369629\n",
      "=== Epoch: 330===\n",
      "batch = 0, mean loss = 1.152370434142734\n",
      "batch = 1, mean loss = 1.152370434142734\n",
      "time per epoch: 0.03600168228149414\n",
      "=== Epoch: 331===\n",
      "batch = 0, mean loss = 1.1523714952394384\n",
      "batch = 1, mean loss = 1.1523714952394384\n",
      "time per epoch: 0.04099893569946289\n",
      "=== Epoch: 332===\n",
      "batch = 0, mean loss = 1.1523667536825042\n",
      "batch = 1, mean loss = 1.1523667536825042\n",
      "time per epoch: 0.039999961853027344\n",
      "=== Epoch: 333===\n",
      "batch = 0, mean loss = 1.1523675219108138\n",
      "batch = 1, mean loss = 1.1523675219108138\n",
      "time per epoch: 0.029000043869018555\n",
      "=== Epoch: 334===\n",
      "batch = 0, mean loss = 1.1523703746657443\n",
      "batch = 1, mean loss = 1.1523703746657443\n",
      "time per epoch: 0.03599953651428223\n",
      "=== Epoch: 335===\n",
      "batch = 0, mean loss = 1.1523682207814165\n",
      "batch = 1, mean loss = 1.1523682207814165\n",
      "time per epoch: 0.03600001335144043\n",
      "=== Epoch: 336===\n",
      "batch = 0, mean loss = 1.1523711098027212\n",
      "batch = 1, mean loss = 1.1523711098027212\n",
      "time per epoch: 0.03699946403503418\n",
      "=== Epoch: 337===\n",
      "batch = 0, mean loss = 1.1523661941237158\n",
      "batch = 1, mean loss = 1.1523661941237158\n",
      "time per epoch: 0.028001070022583008\n",
      "=== Epoch: 338===\n",
      "batch = 0, mean loss = 1.152368542428098\n",
      "batch = 1, mean loss = 1.152368542428098\n",
      "time per epoch: 0.030004024505615234\n",
      "=== Epoch: 339===\n",
      "batch = 0, mean loss = 1.1523679240552036\n",
      "batch = 1, mean loss = 1.1523679240552036\n",
      "time per epoch: 0.02999424934387207\n",
      "=== Epoch: 340===\n",
      "batch = 0, mean loss = 1.1523713925352754\n",
      "batch = 1, mean loss = 1.1523713925352754\n",
      "time per epoch: 0.028000593185424805\n",
      "=== Epoch: 341===\n",
      "batch = 0, mean loss = 1.152368536775564\n",
      "batch = 1, mean loss = 1.152368536775564\n",
      "time per epoch: 0.028002500534057617\n",
      "=== Epoch: 342===\n",
      "batch = 0, mean loss = 1.1523656294680598\n",
      "batch = 1, mean loss = 1.1523656294680598\n",
      "time per epoch: 0.027002573013305664\n",
      "=== Epoch: 343===\n",
      "batch = 0, mean loss = 1.152367918790094\n",
      "batch = 1, mean loss = 1.152367918790094\n",
      "time per epoch: 0.029995203018188477\n",
      "=== Epoch: 344===\n",
      "batch = 0, mean loss = 1.1523660249832797\n",
      "batch = 1, mean loss = 1.1523660249832797\n",
      "time per epoch: 0.030000925064086914\n",
      "=== Epoch: 345===\n",
      "batch = 0, mean loss = 1.152369468119815\n",
      "batch = 1, mean loss = 1.152369468119815\n",
      "time per epoch: 0.029004812240600586\n",
      "=== Epoch: 346===\n",
      "batch = 0, mean loss = 1.1523718325000083\n",
      "batch = 1, mean loss = 1.1523718325000083\n",
      "time per epoch: 0.029000520706176758\n",
      "=== Epoch: 347===\n",
      "batch = 0, mean loss = 1.1523688156666392\n",
      "batch = 1, mean loss = 1.1523688156666392\n",
      "time per epoch: 0.03399395942687988\n",
      "=== Epoch: 348===\n",
      "batch = 0, mean loss = 1.1523686087652583\n",
      "batch = 1, mean loss = 1.1523686087652583\n",
      "time per epoch: 0.03399968147277832\n",
      "=== Epoch: 349===\n",
      "batch = 0, mean loss = 1.1523670244214432\n",
      "batch = 1, mean loss = 1.1523670244214432\n",
      "time per epoch: 0.034999847412109375\n",
      "=== Epoch: 350===\n",
      "batch = 0, mean loss = 1.1523675550648214\n",
      "batch = 1, mean loss = 1.1523675550648214\n",
      "time per epoch: 0.037003517150878906\n",
      "=== Epoch: 351===\n",
      "batch = 0, mean loss = 1.1523692133047656\n",
      "batch = 1, mean loss = 1.1523692133047656\n",
      "time per epoch: 0.035996437072753906\n",
      "=== Epoch: 352===\n",
      "batch = 0, mean loss = 1.1523726775355219\n",
      "batch = 1, mean loss = 1.1523726775355219\n",
      "time per epoch: 0.037000417709350586\n",
      "=== Epoch: 353===\n",
      "batch = 0, mean loss = 1.152368053816122\n",
      "batch = 1, mean loss = 1.152368053816122\n",
      "time per epoch: 0.02900385856628418\n",
      "=== Epoch: 354===\n",
      "batch = 0, mean loss = 1.1523675284402632\n",
      "batch = 1, mean loss = 1.1523675284402632\n",
      "time per epoch: 0.032996177673339844\n",
      "=== Epoch: 355===\n",
      "batch = 0, mean loss = 1.1523650682680642\n",
      "batch = 1, mean loss = 1.1523650682680642\n",
      "time per epoch: 0.03599977493286133\n",
      "=== Epoch: 356===\n",
      "batch = 0, mean loss = 1.152368430892379\n",
      "batch = 1, mean loss = 1.152368430892379\n",
      "time per epoch: 0.03900003433227539\n",
      "=== Epoch: 357===\n",
      "batch = 0, mean loss = 1.152367312222291\n",
      "batch = 1, mean loss = 1.152367312222291\n",
      "time per epoch: 0.034000396728515625\n",
      "=== Epoch: 358===\n",
      "batch = 0, mean loss = 1.1523705404238644\n",
      "batch = 1, mean loss = 1.1523705404238644\n",
      "time per epoch: 0.028005361557006836\n",
      "=== Epoch: 359===\n",
      "batch = 0, mean loss = 1.152369834308659\n",
      "batch = 1, mean loss = 1.152369834308659\n",
      "time per epoch: 0.027999401092529297\n",
      "=== Epoch: 360===\n",
      "batch = 0, mean loss = 1.1523687893284216\n",
      "batch = 1, mean loss = 1.1523687893284216\n",
      "time per epoch: 0.026994943618774414\n",
      "=== Epoch: 361===\n",
      "batch = 0, mean loss = 1.1523664573166787\n",
      "batch = 1, mean loss = 1.1523664573166787\n",
      "time per epoch: 0.026000261306762695\n",
      "=== Epoch: 362===\n",
      "batch = 0, mean loss = 1.152367223758265\n",
      "batch = 1, mean loss = 1.152367223758265\n",
      "time per epoch: 0.026999473571777344\n",
      "=== Epoch: 363===\n",
      "batch = 0, mean loss = 1.152369819080997\n",
      "batch = 1, mean loss = 1.152369819080997\n",
      "time per epoch: 0.031000375747680664\n",
      "=== Epoch: 364===\n",
      "batch = 0, mean loss = 1.1523681144239277\n",
      "batch = 1, mean loss = 1.1523681144239277\n",
      "time per epoch: 0.038526058197021484\n",
      "=== Epoch: 365===\n",
      "batch = 0, mean loss = 1.152366813554546\n",
      "batch = 1, mean loss = 1.152366813554546\n",
      "time per epoch: 0.03256535530090332\n",
      "=== Epoch: 366===\n",
      "batch = 0, mean loss = 1.1523658642598575\n",
      "batch = 1, mean loss = 1.1523658642598575\n",
      "time per epoch: 0.032002925872802734\n",
      "=== Epoch: 367===\n",
      "batch = 0, mean loss = 1.1523680452208325\n",
      "batch = 1, mean loss = 1.1523680452208325\n",
      "time per epoch: 0.032000064849853516\n",
      "=== Epoch: 368===\n",
      "batch = 0, mean loss = 1.1523666936359394\n",
      "batch = 1, mean loss = 1.1523666936359394\n",
      "time per epoch: 0.029993772506713867\n",
      "=== Epoch: 369===\n",
      "batch = 0, mean loss = 1.1523682184847335\n",
      "batch = 1, mean loss = 1.1523682184847335\n",
      "time per epoch: 0.031000137329101562\n",
      "=== Epoch: 370===\n",
      "batch = 0, mean loss = 1.1523700137254038\n",
      "batch = 1, mean loss = 1.1523700137254038\n",
      "time per epoch: 0.029000520706176758\n",
      "=== Epoch: 371===\n",
      "batch = 0, mean loss = 1.1523686677681988\n",
      "batch = 1, mean loss = 1.1523686677681988\n",
      "time per epoch: 0.03399944305419922\n",
      "=== Epoch: 372===\n",
      "batch = 0, mean loss = 1.152366071045399\n",
      "batch = 1, mean loss = 1.152366071045399\n",
      "time per epoch: 0.029999971389770508\n",
      "=== Epoch: 373===\n",
      "batch = 0, mean loss = 1.152366161136416\n",
      "batch = 1, mean loss = 1.152366161136416\n",
      "time per epoch: 0.04199957847595215\n",
      "=== Epoch: 374===\n",
      "batch = 0, mean loss = 1.152368546100718\n",
      "batch = 1, mean loss = 1.152368546100718\n",
      "time per epoch: 0.03800034523010254\n",
      "=== Epoch: 375===\n",
      "batch = 0, mean loss = 1.1523731284675671\n",
      "batch = 1, mean loss = 1.1523731284675671\n",
      "time per epoch: 0.03600001335144043\n",
      "=== Epoch: 376===\n",
      "batch = 0, mean loss = 1.1523681558402112\n",
      "batch = 1, mean loss = 1.1523681558402112\n",
      "time per epoch: 0.03399991989135742\n",
      "=== Epoch: 377===\n",
      "batch = 0, mean loss = 1.1523658864046098\n",
      "batch = 1, mean loss = 1.1523658864046098\n",
      "time per epoch: 0.029999971389770508\n",
      "=== Epoch: 378===\n",
      "batch = 0, mean loss = 1.1523681796968077\n",
      "batch = 1, mean loss = 1.1523681796968077\n",
      "time per epoch: 0.029999971389770508\n",
      "=== Epoch: 379===\n",
      "batch = 0, mean loss = 1.1523665167879296\n",
      "batch = 1, mean loss = 1.1523665167879296\n",
      "time per epoch: 0.04200029373168945\n",
      "=== Epoch: 380===\n",
      "batch = 0, mean loss = 1.1523720527148007\n",
      "batch = 1, mean loss = 1.1523720527148007\n",
      "time per epoch: 0.04007720947265625\n",
      "=== Epoch: 381===\n",
      "batch = 0, mean loss = 1.1523727497710725\n",
      "batch = 1, mean loss = 1.1523727497710725\n",
      "time per epoch: 0.030005216598510742\n",
      "=== Epoch: 382===\n",
      "batch = 0, mean loss = 1.1523682478275155\n",
      "batch = 1, mean loss = 1.1523682478275155\n",
      "time per epoch: 0.029994726181030273\n",
      "=== Epoch: 383===\n",
      "batch = 0, mean loss = 1.152367445852728\n",
      "batch = 1, mean loss = 1.152367445852728\n",
      "time per epoch: 0.03299999237060547\n",
      "=== Epoch: 384===\n",
      "batch = 0, mean loss = 1.1523664945620244\n",
      "batch = 1, mean loss = 1.1523664945620244\n",
      "time per epoch: 0.03600001335144043\n",
      "=== Epoch: 385===\n",
      "batch = 0, mean loss = 1.1523660523272197\n",
      "batch = 1, mean loss = 1.1523660523272197\n",
      "time per epoch: 0.029999732971191406\n",
      "=== Epoch: 386===\n",
      "batch = 0, mean loss = 1.152370131890778\n",
      "batch = 1, mean loss = 1.152370131890778\n",
      "time per epoch: 0.0280001163482666\n",
      "=== Epoch: 387===\n",
      "batch = 0, mean loss = 1.1523718030434549\n",
      "batch = 1, mean loss = 1.1523718030434549\n",
      "time per epoch: 0.029000043869018555\n",
      "=== Epoch: 388===\n",
      "batch = 0, mean loss = 1.1523676064936348\n",
      "batch = 1, mean loss = 1.1523676064936348\n",
      "time per epoch: 0.03099989891052246\n",
      "=== Epoch: 389===\n",
      "batch = 0, mean loss = 1.1523683084528276\n",
      "batch = 1, mean loss = 1.1523683084528276\n",
      "time per epoch: 0.026999950408935547\n",
      "=== Epoch: 390===\n",
      "batch = 0, mean loss = 1.1523657005101178\n",
      "batch = 1, mean loss = 1.1523657005101178\n",
      "time per epoch: 0.034999847412109375\n",
      "=== Epoch: 391===\n",
      "batch = 0, mean loss = 1.1523663487879077\n",
      "batch = 1, mean loss = 1.1523663487879077\n",
      "time per epoch: 0.02600240707397461\n",
      "=== Epoch: 392===\n",
      "batch = 0, mean loss = 1.1523682791687828\n",
      "batch = 1, mean loss = 1.1523682791687828\n",
      "time per epoch: 0.028998136520385742\n",
      "=== Epoch: 393===\n",
      "batch = 0, mean loss = 1.1523702600218293\n",
      "batch = 1, mean loss = 1.1523702600218293\n",
      "time per epoch: 0.03199958801269531\n",
      "=== Epoch: 394===\n",
      "batch = 0, mean loss = 1.1523673587223873\n",
      "batch = 1, mean loss = 1.1523673587223873\n",
      "time per epoch: 0.028000354766845703\n",
      "=== Epoch: 395===\n",
      "batch = 0, mean loss = 1.152367819134638\n",
      "batch = 1, mean loss = 1.152367819134638\n",
      "time per epoch: 0.03399968147277832\n",
      "=== Epoch: 396===\n",
      "batch = 0, mean loss = 1.152365658555135\n",
      "batch = 1, mean loss = 1.152365658555135\n",
      "time per epoch: 0.029000043869018555\n",
      "=== Epoch: 397===\n",
      "batch = 0, mean loss = 1.1523707193864414\n",
      "batch = 1, mean loss = 1.1523707193864414\n",
      "time per epoch: 0.0279998779296875\n",
      "=== Epoch: 398===\n",
      "batch = 0, mean loss = 1.1523711296469112\n",
      "batch = 1, mean loss = 1.1523711296469112\n",
      "time per epoch: 0.03399944305419922\n",
      "=== Epoch: 399===\n",
      "batch = 0, mean loss = 1.152367893559364\n",
      "batch = 1, mean loss = 1.152367893559364\n",
      "time per epoch: 0.03599953651428223\n",
      "=== Epoch: 400===\n",
      "batch = 0, mean loss = 1.152369299387138\n",
      "batch = 1, mean loss = 1.152369299387138\n",
      "time per epoch: 0.03000020980834961\n",
      "=== Epoch: 401===\n",
      "batch = 0, mean loss = 1.1523688528457907\n",
      "batch = 1, mean loss = 1.1523688528457907\n",
      "time per epoch: 0.03399968147277832\n",
      "=== Epoch: 402===\n",
      "batch = 0, mean loss = 1.1523647430602568\n",
      "batch = 1, mean loss = 1.1523647430602568\n",
      "time per epoch: 0.03000020980834961\n",
      "=== Epoch: 403===\n",
      "batch = 0, mean loss = 1.1523675496650019\n",
      "batch = 1, mean loss = 1.1523675496650019\n",
      "time per epoch: 0.029999971389770508\n",
      "=== Epoch: 404===\n",
      "batch = 0, mean loss = 1.1523684595510084\n",
      "batch = 1, mean loss = 1.1523684595510084\n",
      "time per epoch: 0.03600502014160156\n",
      "=== Epoch: 405===\n",
      "batch = 0, mean loss = 1.1523740482738782\n",
      "batch = 1, mean loss = 1.1523740482738782\n",
      "time per epoch: 0.029000043869018555\n",
      "=== Epoch: 406===\n",
      "batch = 0, mean loss = 1.152370113047629\n",
      "batch = 1, mean loss = 1.152370113047629\n",
      "time per epoch: 0.030997276306152344\n",
      "=== Epoch: 407===\n",
      "batch = 0, mean loss = 1.1523665881445477\n",
      "batch = 1, mean loss = 1.1523665881445477\n",
      "time per epoch: 0.029047250747680664\n",
      "=== Epoch: 408===\n",
      "batch = 0, mean loss = 1.1523684414317883\n",
      "batch = 1, mean loss = 1.1523684414317883\n",
      "time per epoch: 0.03099989891052246\n",
      "=== Epoch: 409===\n",
      "batch = 0, mean loss = 1.1523671431909601\n",
      "batch = 1, mean loss = 1.1523671431909601\n",
      "time per epoch: 0.029999732971191406\n",
      "=== Epoch: 410===\n",
      "batch = 0, mean loss = 1.152373980459118\n",
      "batch = 1, mean loss = 1.152373980459118\n",
      "time per epoch: 0.03699946403503418\n",
      "=== Epoch: 411===\n",
      "batch = 0, mean loss = 1.1523674933555945\n",
      "batch = 1, mean loss = 1.1523674933555945\n",
      "time per epoch: 0.03799939155578613\n",
      "=== Epoch: 412===\n",
      "batch = 0, mean loss = 1.1523648728806664\n",
      "batch = 1, mean loss = 1.1523648728806664\n",
      "time per epoch: 0.041001081466674805\n",
      "=== Epoch: 413===\n",
      "batch = 0, mean loss = 1.1523674504767565\n",
      "batch = 1, mean loss = 1.1523674504767565\n",
      "time per epoch: 0.034999847412109375\n",
      "=== Epoch: 414===\n",
      "batch = 0, mean loss = 1.1523698206437423\n",
      "batch = 1, mean loss = 1.1523698206437423\n",
      "time per epoch: 0.035999298095703125\n",
      "=== Epoch: 415===\n",
      "batch = 0, mean loss = 1.1523674773768102\n",
      "batch = 1, mean loss = 1.1523674773768102\n",
      "time per epoch: 0.030005931854248047\n",
      "=== Epoch: 416===\n",
      "batch = 0, mean loss = 1.152368344627579\n",
      "batch = 1, mean loss = 1.152368344627579\n",
      "time per epoch: 0.03000020980834961\n",
      "=== Epoch: 417===\n",
      "batch = 0, mean loss = 1.1523689446184668\n",
      "batch = 1, mean loss = 1.1523689446184668\n",
      "time per epoch: 0.02899956703186035\n",
      "=== Epoch: 418===\n",
      "batch = 0, mean loss = 1.1523648370613948\n",
      "batch = 1, mean loss = 1.1523648370613948\n",
      "time per epoch: 0.03000020980834961\n",
      "=== Epoch: 419===\n",
      "batch = 0, mean loss = 1.1523693387617473\n",
      "batch = 1, mean loss = 1.1523693387617473\n",
      "time per epoch: 0.030995845794677734\n",
      "=== Epoch: 420===\n",
      "batch = 0, mean loss = 1.1523687374297316\n",
      "batch = 1, mean loss = 1.1523687374297316\n",
      "time per epoch: 0.029998779296875\n",
      "=== Epoch: 421===\n",
      "batch = 0, mean loss = 1.1523678134232562\n",
      "batch = 1, mean loss = 1.1523678134232562\n",
      "time per epoch: 0.03500556945800781\n",
      "=== Epoch: 422===\n",
      "batch = 0, mean loss = 1.1523695626558428\n",
      "batch = 1, mean loss = 1.1523695626558428\n",
      "time per epoch: 0.03000020980834961\n",
      "=== Epoch: 423===\n",
      "batch = 0, mean loss = 1.1523654024291865\n",
      "batch = 1, mean loss = 1.1523654024291865\n",
      "time per epoch: 0.028998851776123047\n",
      "=== Epoch: 424===\n",
      "batch = 0, mean loss = 1.152366231067885\n",
      "batch = 1, mean loss = 1.152366231067885\n",
      "time per epoch: 0.029994964599609375\n",
      "=== Epoch: 425===\n",
      "batch = 0, mean loss = 1.1523708749414852\n",
      "batch = 1, mean loss = 1.1523708749414852\n",
      "time per epoch: 0.029999732971191406\n",
      "=== Epoch: 426===\n",
      "batch = 0, mean loss = 1.1523697365246024\n",
      "batch = 1, mean loss = 1.1523697365246024\n",
      "time per epoch: 0.030004501342773438\n",
      "=== Epoch: 427===\n",
      "batch = 0, mean loss = 1.152368922887995\n",
      "batch = 1, mean loss = 1.152368922887995\n",
      "time per epoch: 0.031002283096313477\n",
      "=== Epoch: 428===\n",
      "batch = 0, mean loss = 1.152367088324771\n",
      "batch = 1, mean loss = 1.152367088324771\n",
      "time per epoch: 0.029999256134033203\n",
      "=== Epoch: 429===\n",
      "batch = 0, mean loss = 1.1523671675780893\n",
      "batch = 1, mean loss = 1.1523671675780893\n",
      "time per epoch: 0.028998851776123047\n",
      "=== Epoch: 430===\n",
      "batch = 0, mean loss = 1.1523681725023613\n",
      "batch = 1, mean loss = 1.1523681725023613\n",
      "time per epoch: 0.02700042724609375\n",
      "=== Epoch: 431===\n",
      "batch = 0, mean loss = 1.1523726543016877\n",
      "batch = 1, mean loss = 1.1523726543016877\n",
      "time per epoch: 0.02700042724609375\n",
      "=== Epoch: 432===\n",
      "batch = 0, mean loss = 1.152372007551753\n",
      "batch = 1, mean loss = 1.152372007551753\n",
      "time per epoch: 0.025996923446655273\n",
      "=== Epoch: 433===\n",
      "batch = 0, mean loss = 1.1523689023767352\n",
      "batch = 1, mean loss = 1.1523689023767352\n",
      "time per epoch: 0.0319972038269043\n",
      "=== Epoch: 434===\n",
      "batch = 0, mean loss = 1.1523657654178936\n",
      "batch = 1, mean loss = 1.1523657654178936\n",
      "time per epoch: 0.02700018882751465\n",
      "=== Epoch: 435===\n",
      "batch = 0, mean loss = 1.1523683514586662\n",
      "batch = 1, mean loss = 1.1523683514586662\n",
      "time per epoch: 0.027999162673950195\n",
      "=== Epoch: 436===\n",
      "batch = 0, mean loss = 1.1523677239465049\n",
      "batch = 1, mean loss = 1.1523677239465049\n",
      "time per epoch: 0.031000137329101562\n",
      "=== Epoch: 437===\n",
      "batch = 0, mean loss = 1.1523680106062122\n",
      "batch = 1, mean loss = 1.1523680106062122\n",
      "time per epoch: 0.03199958801269531\n",
      "=== Epoch: 438===\n",
      "batch = 0, mean loss = 1.1523699530719658\n",
      "batch = 1, mean loss = 1.1523699530719658\n",
      "time per epoch: 0.030000925064086914\n",
      "=== Epoch: 439===\n",
      "batch = 0, mean loss = 1.1523679713932957\n",
      "batch = 1, mean loss = 1.1523679713932957\n",
      "time per epoch: 0.03099966049194336\n",
      "=== Epoch: 440===\n",
      "batch = 0, mean loss = 1.1523702870029853\n",
      "batch = 1, mean loss = 1.1523702870029853\n",
      "time per epoch: 0.028003454208374023\n",
      "=== Epoch: 441===\n",
      "batch = 0, mean loss = 1.1523674815684162\n",
      "batch = 1, mean loss = 1.1523674815684162\n",
      "time per epoch: 0.028997182846069336\n",
      "=== Epoch: 442===\n",
      "batch = 0, mean loss = 1.1523680618831895\n",
      "batch = 1, mean loss = 1.1523680618831895\n",
      "time per epoch: 0.02700042724609375\n",
      "=== Epoch: 443===\n",
      "batch = 0, mean loss = 1.1523692851960043\n",
      "batch = 1, mean loss = 1.1523692851960043\n",
      "time per epoch: 0.02900528907775879\n",
      "=== Epoch: 444===\n",
      "batch = 0, mean loss = 1.1523692424924428\n",
      "batch = 1, mean loss = 1.1523692424924428\n",
      "time per epoch: 0.033995628356933594\n",
      "=== Epoch: 445===\n",
      "batch = 0, mean loss = 1.152366232229677\n",
      "batch = 1, mean loss = 1.152366232229677\n",
      "time per epoch: 0.03699922561645508\n",
      "=== Epoch: 446===\n",
      "batch = 0, mean loss = 1.1523687558098914\n",
      "batch = 1, mean loss = 1.1523687558098914\n",
      "time per epoch: 0.03999924659729004\n",
      "=== Epoch: 447===\n",
      "batch = 0, mean loss = 1.152366376706659\n",
      "batch = 1, mean loss = 1.152366376706659\n",
      "time per epoch: 0.03399991989135742\n",
      "=== Epoch: 448===\n",
      "batch = 0, mean loss = 1.152366042774682\n",
      "batch = 1, mean loss = 1.152366042774682\n",
      "time per epoch: 0.031003475189208984\n",
      "=== Epoch: 449===\n",
      "batch = 0, mean loss = 1.1523695894723631\n",
      "batch = 1, mean loss = 1.1523695894723631\n",
      "time per epoch: 0.029001951217651367\n",
      "=== Epoch: 450===\n",
      "batch = 0, mean loss = 1.1523682710658045\n",
      "batch = 1, mean loss = 1.1523682710658045\n",
      "time per epoch: 0.02999734878540039\n",
      "=== Epoch: 451===\n",
      "batch = 0, mean loss = 1.1523662049981787\n",
      "batch = 1, mean loss = 1.1523662049981787\n",
      "time per epoch: 0.0360713005065918\n",
      "=== Epoch: 452===\n",
      "batch = 0, mean loss = 1.1523667923789271\n",
      "batch = 1, mean loss = 1.1523667923789271\n",
      "time per epoch: 0.03799772262573242\n",
      "=== Epoch: 453===\n",
      "batch = 0, mean loss = 1.1523648405741054\n",
      "batch = 1, mean loss = 1.1523648405741054\n",
      "time per epoch: 0.03599977493286133\n",
      "=== Epoch: 454===\n",
      "batch = 0, mean loss = 1.1523679028652385\n",
      "batch = 1, mean loss = 1.1523679028652385\n",
      "time per epoch: 0.03900027275085449\n",
      "=== Epoch: 455===\n",
      "batch = 0, mean loss = 1.152370373960466\n",
      "batch = 1, mean loss = 1.152370373960466\n",
      "time per epoch: 0.031005144119262695\n",
      "=== Epoch: 456===\n",
      "batch = 0, mean loss = 1.1523665197929276\n",
      "batch = 1, mean loss = 1.1523665197929276\n",
      "time per epoch: 0.030993938446044922\n",
      "=== Epoch: 457===\n",
      "batch = 0, mean loss = 1.1523690263156183\n",
      "batch = 1, mean loss = 1.1523690263156183\n",
      "time per epoch: 0.029003381729125977\n",
      "=== Epoch: 458===\n",
      "batch = 0, mean loss = 1.1523667374063442\n",
      "batch = 1, mean loss = 1.1523667374063442\n",
      "time per epoch: 0.03899741172790527\n",
      "=== Epoch: 459===\n",
      "batch = 0, mean loss = 1.1523643695662853\n",
      "batch = 1, mean loss = 1.1523643695662853\n",
      "time per epoch: 0.041002511978149414\n",
      "=== Epoch: 460===\n",
      "batch = 0, mean loss = 1.152367578497169\n",
      "batch = 1, mean loss = 1.152367578497169\n",
      "time per epoch: 0.03999757766723633\n",
      "=== Epoch: 461===\n",
      "batch = 0, mean loss = 1.1523699680686539\n",
      "batch = 1, mean loss = 1.1523699680686539\n",
      "time per epoch: 0.03300023078918457\n",
      "=== Epoch: 462===\n",
      "batch = 0, mean loss = 1.1523674499488537\n",
      "batch = 1, mean loss = 1.1523674499488537\n",
      "time per epoch: 0.03999972343444824\n",
      "=== Epoch: 463===\n",
      "batch = 0, mean loss = 1.1523679162364355\n",
      "batch = 1, mean loss = 1.1523679162364355\n",
      "time per epoch: 0.03699970245361328\n",
      "=== Epoch: 464===\n",
      "batch = 0, mean loss = 1.1523663433752973\n",
      "batch = 1, mean loss = 1.1523663433752973\n",
      "time per epoch: 0.037000179290771484\n",
      "=== Epoch: 465===\n",
      "batch = 0, mean loss = 1.1523663102424937\n",
      "batch = 1, mean loss = 1.1523663102424937\n",
      "time per epoch: 0.03300213813781738\n",
      "=== Epoch: 466===\n",
      "batch = 0, mean loss = 1.152366740865606\n",
      "batch = 1, mean loss = 1.152366740865606\n",
      "time per epoch: 0.03400087356567383\n",
      "=== Epoch: 467===\n",
      "batch = 0, mean loss = 1.1523683533181595\n",
      "batch = 1, mean loss = 1.1523683533181595\n",
      "time per epoch: 0.02700209617614746\n",
      "=== Epoch: 468===\n",
      "batch = 0, mean loss = 1.1523706777662177\n",
      "batch = 1, mean loss = 1.1523706777662177\n",
      "time per epoch: 0.02799510955810547\n",
      "=== Epoch: 469===\n",
      "batch = 0, mean loss = 1.1523664934475755\n",
      "batch = 1, mean loss = 1.1523664934475755\n",
      "time per epoch: 0.02800297737121582\n",
      "=== Epoch: 470===\n",
      "batch = 0, mean loss = 1.1523656023603697\n",
      "batch = 1, mean loss = 1.1523656023603697\n",
      "time per epoch: 0.028001785278320312\n",
      "=== Epoch: 471===\n",
      "batch = 0, mean loss = 1.1523672020185025\n",
      "batch = 1, mean loss = 1.1523672020185025\n",
      "time per epoch: 0.02599501609802246\n",
      "=== Epoch: 472===\n",
      "batch = 0, mean loss = 1.1523677505280774\n",
      "batch = 1, mean loss = 1.1523677505280774\n",
      "time per epoch: 0.029005050659179688\n",
      "=== Epoch: 473===\n",
      "batch = 0, mean loss = 1.1523709591679148\n",
      "batch = 1, mean loss = 1.1523709591679148\n",
      "time per epoch: 0.025998353958129883\n",
      "=== Epoch: 474===\n",
      "batch = 0, mean loss = 1.152368086865928\n",
      "batch = 1, mean loss = 1.152368086865928\n",
      "time per epoch: 0.027001619338989258\n",
      "=== Epoch: 475===\n",
      "batch = 0, mean loss = 1.1523665951425948\n",
      "batch = 1, mean loss = 1.1523665951425948\n",
      "time per epoch: 0.028995037078857422\n",
      "=== Epoch: 476===\n",
      "batch = 0, mean loss = 1.1523686021245156\n",
      "batch = 1, mean loss = 1.1523686021245156\n",
      "time per epoch: 0.02700018882751465\n",
      "=== Epoch: 477===\n",
      "batch = 0, mean loss = 1.1523656942076557\n",
      "batch = 1, mean loss = 1.1523656942076557\n",
      "time per epoch: 0.027004480361938477\n",
      "=== Epoch: 478===\n",
      "batch = 0, mean loss = 1.1523666898285905\n",
      "batch = 1, mean loss = 1.1523666898285905\n",
      "time per epoch: 0.029003381729125977\n",
      "=== Epoch: 479===\n",
      "batch = 0, mean loss = 1.1523730557930507\n",
      "batch = 1, mean loss = 1.1523730557930507\n",
      "time per epoch: 0.03399252891540527\n",
      "=== Epoch: 480===\n",
      "batch = 0, mean loss = 1.1523686918198113\n",
      "batch = 1, mean loss = 1.1523686918198113\n",
      "time per epoch: 0.03899979591369629\n",
      "=== Epoch: 481===\n",
      "batch = 0, mean loss = 1.1523660478436806\n",
      "batch = 1, mean loss = 1.1523660478436806\n",
      "time per epoch: 0.029002904891967773\n",
      "=== Epoch: 482===\n",
      "batch = 0, mean loss = 1.152368925892577\n",
      "batch = 1, mean loss = 1.152368925892577\n",
      "time per epoch: 0.029996871948242188\n",
      "=== Epoch: 483===\n",
      "batch = 0, mean loss = 1.152367112245945\n",
      "batch = 1, mean loss = 1.152367112245945\n",
      "time per epoch: 0.039999961853027344\n",
      "=== Epoch: 484===\n",
      "batch = 0, mean loss = 1.1523665902040825\n",
      "batch = 1, mean loss = 1.1523665902040825\n",
      "time per epoch: 0.040000200271606445\n",
      "=== Epoch: 485===\n",
      "batch = 0, mean loss = 1.1523675227900343\n",
      "batch = 1, mean loss = 1.1523675227900343\n",
      "time per epoch: 0.03600573539733887\n",
      "=== Epoch: 486===\n",
      "batch = 0, mean loss = 1.152369980057183\n",
      "batch = 1, mean loss = 1.152369980057183\n",
      "time per epoch: 0.02899909019470215\n",
      "=== Epoch: 487===\n",
      "batch = 0, mean loss = 1.1523721874242097\n",
      "batch = 1, mean loss = 1.1523721874242097\n",
      "time per epoch: 0.03699493408203125\n",
      "=== Epoch: 488===\n",
      "batch = 0, mean loss = 1.1523689001857902\n",
      "batch = 1, mean loss = 1.1523689001857902\n",
      "time per epoch: 0.029999971389770508\n",
      "=== Epoch: 489===\n",
      "batch = 0, mean loss = 1.1523661074355425\n",
      "batch = 1, mean loss = 1.1523661074355425\n",
      "time per epoch: 0.032004594802856445\n",
      "=== Epoch: 490===\n",
      "batch = 0, mean loss = 1.1523667026355262\n",
      "batch = 1, mean loss = 1.1523667026355262\n",
      "time per epoch: 0.04199552536010742\n",
      "=== Epoch: 491===\n",
      "batch = 0, mean loss = 1.1523659767986292\n",
      "batch = 1, mean loss = 1.1523659767986292\n",
      "time per epoch: 0.032000064849853516\n",
      "=== Epoch: 492===\n",
      "batch = 0, mean loss = 1.1523639370129162\n",
      "batch = 1, mean loss = 1.1523639370129162\n",
      "time per epoch: 0.030075788497924805\n",
      "=== Epoch: 493===\n",
      "batch = 0, mean loss = 1.1523707878649563\n",
      "batch = 1, mean loss = 1.1523707878649563\n",
      "time per epoch: 0.029999494552612305\n",
      "=== Epoch: 494===\n",
      "batch = 0, mean loss = 1.152366933197411\n",
      "batch = 1, mean loss = 1.152366933197411\n",
      "time per epoch: 0.032001495361328125\n",
      "=== Epoch: 495===\n",
      "batch = 0, mean loss = 1.1523667110687035\n",
      "batch = 1, mean loss = 1.1523667110687035\n",
      "time per epoch: 0.03299283981323242\n",
      "=== Epoch: 496===\n",
      "batch = 0, mean loss = 1.1523689305675973\n",
      "batch = 1, mean loss = 1.1523689305675973\n",
      "time per epoch: 0.0280001163482666\n",
      "=== Epoch: 497===\n",
      "batch = 0, mean loss = 1.152364331575959\n",
      "batch = 1, mean loss = 1.152364331575959\n",
      "time per epoch: 0.02900528907775879\n",
      "=== Epoch: 498===\n",
      "batch = 0, mean loss = 1.152367416890935\n",
      "batch = 1, mean loss = 1.152367416890935\n",
      "time per epoch: 0.030000925064086914\n",
      "=== Epoch: 499===\n",
      "batch = 0, mean loss = 1.1523694068989454\n",
      "batch = 1, mean loss = 1.1523694068989454\n",
      "time per epoch: 0.026996374130249023\n",
      "        time for training: 16.705981492996216\n",
      "        actual verification time 0.01499485969543457\n",
      "    layer progress, group 2 of 4 \n",
      "=== Epoch: 0===\n",
      "batch = 0, mean loss = 1.4531389623775657\n",
      "batch = 1, mean loss = 1.4531389623775657\n",
      "time per epoch: 0.023999691009521484\n",
      "=== Epoch: 1===\n",
      "batch = 0, mean loss = 1.3916253415516704\n",
      "batch = 1, mean loss = 1.3916253415516704\n",
      "time per epoch: 0.023999929428100586\n",
      "=== Epoch: 2===\n",
      "batch = 0, mean loss = 1.4049278503643272\n",
      "batch = 1, mean loss = 1.4049278503643272\n",
      "time per epoch: 0.025000333786010742\n",
      "=== Epoch: 3===\n",
      "batch = 0, mean loss = 1.3652530275678803\n",
      "batch = 1, mean loss = 1.3652530275678803\n",
      "time per epoch: 0.02899956703186035\n",
      "=== Epoch: 4===\n",
      "batch = 0, mean loss = 1.3548482853471178\n",
      "batch = 1, mean loss = 1.3548482853471178\n",
      "time per epoch: 0.03000020980834961\n",
      "=== Epoch: 5===\n",
      "batch = 0, mean loss = 1.3430832046583001\n",
      "batch = 1, mean loss = 1.3430832046583001\n",
      "time per epoch: 0.0280001163482666\n",
      "=== Epoch: 6===\n",
      "batch = 0, mean loss = 1.3318262054521477\n",
      "batch = 1, mean loss = 1.3318262054521477\n",
      "time per epoch: 0.023999929428100586\n",
      "=== Epoch: 7===\n",
      "batch = 0, mean loss = 1.316724081653614\n",
      "batch = 1, mean loss = 1.316724081653614\n",
      "time per epoch: 0.023000001907348633\n",
      "=== Epoch: 8===\n",
      "batch = 0, mean loss = 1.3235507406289577\n",
      "batch = 1, mean loss = 1.3235507406289577\n",
      "time per epoch: 0.023000001907348633\n",
      "=== Epoch: 9===\n",
      "batch = 0, mean loss = 1.2952375893125914\n",
      "batch = 1, mean loss = 1.2952375893125914\n",
      "time per epoch: 0.023000240325927734\n",
      "=== Epoch: 10===\n",
      "batch = 0, mean loss = 1.3110123859689766\n",
      "batch = 1, mean loss = 1.3110123859689766\n",
      "time per epoch: 0.023000240325927734\n",
      "=== Epoch: 11===\n",
      "batch = 0, mean loss = 1.2790100938265403\n",
      "batch = 1, mean loss = 1.2790100938265403\n",
      "time per epoch: 0.03099989891052246\n",
      "=== Epoch: 12===\n",
      "batch = 0, mean loss = 1.2921436276845206\n",
      "batch = 1, mean loss = 1.2921436276845206\n",
      "time per epoch: 0.0279998779296875\n",
      "=== Epoch: 13===\n",
      "batch = 0, mean loss = 1.2703986716939382\n",
      "batch = 1, mean loss = 1.2703986716939382\n",
      "time per epoch: 0.03399991989135742\n",
      "=== Epoch: 14===\n",
      "batch = 0, mean loss = 1.2874768830326269\n",
      "batch = 1, mean loss = 1.2874768830326269\n",
      "time per epoch: 0.035001277923583984\n",
      "=== Epoch: 15===\n",
      "batch = 0, mean loss = 1.262249228290205\n",
      "batch = 1, mean loss = 1.262249228290205\n",
      "time per epoch: 0.026004314422607422\n",
      "=== Epoch: 16===\n",
      "batch = 0, mean loss = 1.2628612618560768\n",
      "batch = 1, mean loss = 1.2628612618560768\n",
      "time per epoch: 0.027996540069580078\n",
      "=== Epoch: 17===\n",
      "batch = 0, mean loss = 1.2525316830545348\n",
      "batch = 1, mean loss = 1.2525316830545348\n",
      "time per epoch: 0.02699756622314453\n",
      "=== Epoch: 18===\n",
      "batch = 0, mean loss = 1.2623064560906272\n",
      "batch = 1, mean loss = 1.2623064560906272\n",
      "time per epoch: 0.029000282287597656\n",
      "=== Epoch: 19===\n",
      "batch = 0, mean loss = 1.2483856048296973\n",
      "batch = 1, mean loss = 1.2483856048296973\n",
      "time per epoch: 0.029003381729125977\n",
      "=== Epoch: 20===\n",
      "batch = 0, mean loss = 1.2541326252688187\n",
      "batch = 1, mean loss = 1.2541326252688187\n",
      "time per epoch: 0.027001619338989258\n",
      "=== Epoch: 21===\n",
      "batch = 0, mean loss = 1.2495183550811502\n",
      "batch = 1, mean loss = 1.2495183550811502\n",
      "time per epoch: 0.02700018882751465\n",
      "=== Epoch: 22===\n",
      "batch = 0, mean loss = 1.2439199857149803\n",
      "batch = 1, mean loss = 1.2439199857149803\n",
      "time per epoch: 0.026000499725341797\n",
      "=== Epoch: 23===\n",
      "batch = 0, mean loss = 1.2439889995231828\n",
      "batch = 1, mean loss = 1.2439889995231828\n",
      "time per epoch: 0.029000043869018555\n",
      "=== Epoch: 24===\n",
      "batch = 0, mean loss = 1.2438194565527165\n",
      "batch = 1, mean loss = 1.2438194565527165\n",
      "time per epoch: 0.03699469566345215\n",
      "=== Epoch: 25===\n",
      "batch = 0, mean loss = 1.2457579154835061\n",
      "batch = 1, mean loss = 1.2457579154835061\n",
      "time per epoch: 0.03700065612792969\n",
      "=== Epoch: 26===\n",
      "batch = 0, mean loss = 1.244039995891117\n",
      "batch = 1, mean loss = 1.244039995891117\n",
      "time per epoch: 0.02700519561767578\n",
      "=== Epoch: 27===\n",
      "batch = 0, mean loss = 1.245059004978443\n",
      "batch = 1, mean loss = 1.245059004978443\n",
      "time per epoch: 0.03000020980834961\n",
      "=== Epoch: 28===\n",
      "batch = 0, mean loss = 1.2421205860949578\n",
      "batch = 1, mean loss = 1.2421205860949578\n",
      "time per epoch: 0.029993295669555664\n",
      "=== Epoch: 29===\n",
      "batch = 0, mean loss = 1.2428612420124097\n",
      "batch = 1, mean loss = 1.2428612420124097\n",
      "time per epoch: 0.037000179290771484\n",
      "=== Epoch: 30===\n",
      "batch = 0, mean loss = 1.2408830852315704\n",
      "batch = 1, mean loss = 1.2408830852315704\n",
      "time per epoch: 0.03400015830993652\n",
      "=== Epoch: 31===\n",
      "batch = 0, mean loss = 1.2426053426754184\n",
      "batch = 1, mean loss = 1.2426053426754184\n",
      "time per epoch: 0.03599977493286133\n",
      "=== Epoch: 32===\n",
      "batch = 0, mean loss = 1.2381273191289242\n",
      "batch = 1, mean loss = 1.2381273191289242\n",
      "time per epoch: 0.03099989891052246\n",
      "=== Epoch: 33===\n",
      "batch = 0, mean loss = 1.2442976399732841\n",
      "batch = 1, mean loss = 1.2442976399732841\n",
      "time per epoch: 0.028000354766845703\n",
      "=== Epoch: 34===\n",
      "batch = 0, mean loss = 1.2366977559904395\n",
      "batch = 1, mean loss = 1.2366977559904395\n",
      "time per epoch: 0.029999494552612305\n",
      "=== Epoch: 35===\n",
      "batch = 0, mean loss = 1.2455122267982488\n",
      "batch = 1, mean loss = 1.2455122267982488\n",
      "time per epoch: 0.028000354766845703\n",
      "=== Epoch: 36===\n",
      "batch = 0, mean loss = 1.2352346213548941\n",
      "batch = 1, mean loss = 1.2352346213548941\n",
      "time per epoch: 0.03305673599243164\n",
      "=== Epoch: 37===\n",
      "batch = 0, mean loss = 1.2425373004068603\n",
      "batch = 1, mean loss = 1.2425373004068603\n",
      "time per epoch: 0.026999711990356445\n",
      "=== Epoch: 38===\n",
      "batch = 0, mean loss = 1.2356148252749333\n",
      "batch = 1, mean loss = 1.2356148252749333\n",
      "time per epoch: 0.03399991989135742\n",
      "=== Epoch: 39===\n",
      "batch = 0, mean loss = 1.2391632916207127\n",
      "batch = 1, mean loss = 1.2391632916207127\n",
      "time per epoch: 0.037999868392944336\n",
      "=== Epoch: 40===\n",
      "batch = 0, mean loss = 1.235567481261915\n",
      "batch = 1, mean loss = 1.235567481261915\n",
      "time per epoch: 0.02700042724609375\n",
      "=== Epoch: 41===\n",
      "batch = 0, mean loss = 1.2372470114628829\n",
      "batch = 1, mean loss = 1.2372470114628829\n",
      "time per epoch: 0.0279996395111084\n",
      "=== Epoch: 42===\n",
      "batch = 0, mean loss = 1.2352063660452046\n",
      "batch = 1, mean loss = 1.2352063660452046\n",
      "time per epoch: 0.02700018882751465\n",
      "=== Epoch: 43===\n",
      "batch = 0, mean loss = 1.2362510265661706\n",
      "batch = 1, mean loss = 1.2362510265661706\n",
      "time per epoch: 0.029999971389770508\n",
      "=== Epoch: 44===\n",
      "batch = 0, mean loss = 1.233719763414195\n",
      "batch = 1, mean loss = 1.233719763414195\n",
      "time per epoch: 0.030002117156982422\n",
      "=== Epoch: 45===\n",
      "batch = 0, mean loss = 1.2360317139531616\n",
      "batch = 1, mean loss = 1.2360317139531616\n",
      "time per epoch: 0.033004045486450195\n",
      "=== Epoch: 46===\n",
      "batch = 0, mean loss = 1.231553549725338\n",
      "batch = 1, mean loss = 1.231553549725338\n",
      "time per epoch: 0.025993824005126953\n",
      "=== Epoch: 47===\n",
      "batch = 0, mean loss = 1.2342534284400808\n",
      "batch = 1, mean loss = 1.2342534284400808\n",
      "time per epoch: 0.037000179290771484\n",
      "=== Epoch: 48===\n",
      "batch = 0, mean loss = 1.2313899122608136\n",
      "batch = 1, mean loss = 1.2313899122608136\n",
      "time per epoch: 0.026000499725341797\n",
      "=== Epoch: 49===\n",
      "batch = 0, mean loss = 1.22900410661232\n",
      "batch = 1, mean loss = 1.22900410661232\n",
      "time per epoch: 0.030999183654785156\n",
      "=== Epoch: 50===\n",
      "batch = 0, mean loss = 1.2266475566516806\n",
      "batch = 1, mean loss = 1.2266475566516806\n",
      "time per epoch: 0.029999971389770508\n",
      "=== Epoch: 51===\n",
      "batch = 0, mean loss = 1.2259693648605732\n",
      "batch = 1, mean loss = 1.2259693648605732\n",
      "time per epoch: 0.029999971389770508\n",
      "=== Epoch: 52===\n",
      "batch = 0, mean loss = 1.2253552371898213\n",
      "batch = 1, mean loss = 1.2253552371898213\n",
      "time per epoch: 0.031000375747680664\n",
      "=== Epoch: 53===\n",
      "batch = 0, mean loss = 1.2260139627237367\n",
      "batch = 1, mean loss = 1.2260139627237367\n",
      "time per epoch: 0.02600550651550293\n",
      "=== Epoch: 54===\n",
      "batch = 0, mean loss = 1.2254793445718142\n",
      "batch = 1, mean loss = 1.2254793445718142\n",
      "time per epoch: 0.026996135711669922\n",
      "=== Epoch: 55===\n",
      "batch = 0, mean loss = 1.2233190485132628\n",
      "batch = 1, mean loss = 1.2233190485132628\n",
      "time per epoch: 0.03299832344055176\n",
      "=== Epoch: 56===\n",
      "batch = 0, mean loss = 1.2218581303012217\n",
      "batch = 1, mean loss = 1.2218581303012217\n",
      "time per epoch: 0.03800010681152344\n",
      "=== Epoch: 57===\n",
      "batch = 0, mean loss = 1.2204654005402658\n",
      "batch = 1, mean loss = 1.2204654005402658\n",
      "time per epoch: 0.03600049018859863\n",
      "=== Epoch: 58===\n",
      "batch = 0, mean loss = 1.2194884382343325\n",
      "batch = 1, mean loss = 1.2194884382343325\n",
      "time per epoch: 0.035999298095703125\n",
      "=== Epoch: 59===\n",
      "batch = 0, mean loss = 1.2184100154463615\n",
      "batch = 1, mean loss = 1.2184100154463615\n",
      "time per epoch: 0.0279998779296875\n",
      "=== Epoch: 60===\n",
      "batch = 0, mean loss = 1.216926301643971\n",
      "batch = 1, mean loss = 1.216926301643971\n",
      "time per epoch: 0.026005029678344727\n",
      "=== Epoch: 61===\n",
      "batch = 0, mean loss = 1.216600472726214\n",
      "batch = 1, mean loss = 1.216600472726214\n",
      "time per epoch: 0.02699732780456543\n",
      "=== Epoch: 62===\n",
      "batch = 0, mean loss = 1.2169645424529238\n",
      "batch = 1, mean loss = 1.2169645424529238\n",
      "time per epoch: 0.02599811553955078\n",
      "=== Epoch: 63===\n",
      "batch = 0, mean loss = 1.2167164562824344\n",
      "batch = 1, mean loss = 1.2167164562824344\n",
      "time per epoch: 0.02599954605102539\n",
      "=== Epoch: 64===\n",
      "batch = 0, mean loss = 1.2155090992906639\n",
      "batch = 1, mean loss = 1.2155090992906639\n",
      "time per epoch: 0.026000022888183594\n",
      "=== Epoch: 65===\n",
      "batch = 0, mean loss = 1.21490426376841\n",
      "batch = 1, mean loss = 1.21490426376841\n",
      "time per epoch: 0.031000137329101562\n",
      "=== Epoch: 66===\n",
      "batch = 0, mean loss = 1.214859360793657\n",
      "batch = 1, mean loss = 1.214859360793657\n",
      "time per epoch: 0.03600001335144043\n",
      "=== Epoch: 67===\n",
      "batch = 0, mean loss = 1.2137569164785929\n",
      "batch = 1, mean loss = 1.2137569164785929\n",
      "time per epoch: 0.03699994087219238\n",
      "=== Epoch: 68===\n",
      "batch = 0, mean loss = 1.2129871127631149\n",
      "batch = 1, mean loss = 1.2129871127631149\n",
      "time per epoch: 0.02899909019470215\n",
      "=== Epoch: 69===\n",
      "batch = 0, mean loss = 1.2122972121382993\n",
      "batch = 1, mean loss = 1.2122972121382993\n",
      "time per epoch: 0.028001070022583008\n",
      "=== Epoch: 70===\n",
      "batch = 0, mean loss = 1.211626465522728\n",
      "batch = 1, mean loss = 1.211626465522728\n",
      "time per epoch: 0.03599977493286133\n",
      "=== Epoch: 71===\n",
      "batch = 0, mean loss = 1.2110071023968896\n",
      "batch = 1, mean loss = 1.2110071023968896\n",
      "time per epoch: 0.034999847412109375\n",
      "=== Epoch: 72===\n",
      "batch = 0, mean loss = 1.2100808991288197\n",
      "batch = 1, mean loss = 1.2100808991288197\n",
      "time per epoch: 0.03300046920776367\n",
      "=== Epoch: 73===\n",
      "batch = 0, mean loss = 1.2095000400520122\n",
      "batch = 1, mean loss = 1.2095000400520122\n",
      "time per epoch: 0.03199958801269531\n",
      "=== Epoch: 74===\n",
      "batch = 0, mean loss = 1.2084071839608903\n",
      "batch = 1, mean loss = 1.2084071839608903\n",
      "time per epoch: 0.03500032424926758\n",
      "=== Epoch: 75===\n",
      "batch = 0, mean loss = 1.2078739796374178\n",
      "batch = 1, mean loss = 1.2078739796374178\n",
      "time per epoch: 0.0299990177154541\n",
      "=== Epoch: 76===\n",
      "batch = 0, mean loss = 1.2076502840430616\n",
      "batch = 1, mean loss = 1.2076502840430616\n",
      "time per epoch: 0.03100109100341797\n",
      "=== Epoch: 77===\n",
      "batch = 0, mean loss = 1.2069386076863513\n",
      "batch = 1, mean loss = 1.2069386076863513\n",
      "time per epoch: 0.03599953651428223\n",
      "=== Epoch: 78===\n",
      "batch = 0, mean loss = 1.206564765609528\n",
      "batch = 1, mean loss = 1.206564765609528\n",
      "time per epoch: 0.03400135040283203\n",
      "=== Epoch: 79===\n",
      "batch = 0, mean loss = 1.2057794217439604\n",
      "batch = 1, mean loss = 1.2057794217439604\n",
      "time per epoch: 0.025998830795288086\n",
      "=== Epoch: 80===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[67], line 7\u001B[0m\n\u001B[0;32m      2\u001B[0m icnn_factory \u001B[38;5;241m=\u001B[39m ICNNFactory(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogical\u001B[39m\u001B[38;5;124m\"\u001B[39m, [\u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m1\u001B[39m], force_positive_init\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, with_two_layers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m      3\u001B[0m                                init_scaling\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, init_all_with_zeros\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m#icnn_factory = ICNNFactory(\"standard\", [5, 5, 1])\u001B[39;00m\n\u001B[0;32m      6\u001B[0m icnns, last_group_indices, fixed_neuron_per_layer_lower, fixed_neuron_per_layer_upper, bounds_affine_out, bounds_layer_out \u001B[38;5;241m=\u001B[39m \\\n\u001B[1;32m----> 7\u001B[0m     \u001B[43mmultidhov\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_verification\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_image\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43micnn_factory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43micnn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m500\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43micnn_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_count\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_new\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_over_approximation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbreak_after\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m51\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43msample_over_input_space\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_over_output_space\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_icnn_bounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43muse_fixed_neurons\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampling_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mper_group_sampling\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mforce_inclusion_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreemptive_stop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meven_gradient_training\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mkeep_ambient_space\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_grad_descent_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt_steps_gd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mtrain_outer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_training_loss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mshould_plot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnone\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSdLBFGS\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_network\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madapt_lambda\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnone\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Programming\\ICNN_verification\\script\\DHOV\\MultiDHOV.py:379\u001B[0m, in \u001B[0;36mstart_verification\u001B[1;34m(nn, input, icnn_factory, group_size, eps, icnn_batch_size, icnn_epochs, sample_count, sampling_method, break_after, use_icnn_bounds, use_fixed_neurons, keep_ambient_space, sample_new, use_over_approximation, opt_steps_gd, sample_over_input_space, sample_over_output_space, data_grad_descent_steps, train_outer, preemptive_stop, even_gradient_training, force_inclusion_steps, init_network, adapt_lambda, should_plot, optimizer, print_training_loss)\u001B[0m\n\u001B[0;32m    376\u001B[0m                 plots\u001B[38;5;241m.\u001B[39mplt_mesh()\n\u001B[0;32m    378\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 379\u001B[0m         \u001B[43mtrain_icnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcurrent_icnn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mambient_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs_per_inclusion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhyper_lambda\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    380\u001B[0m \u001B[43m                   \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madapt_lambda\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madapt_lambda\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreemptive_stop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreemptive_stop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    381\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprint_training_loss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m train_outer:  \u001B[38;5;66;03m# todo will ich train outer behalten oder einfach verwerfen?\u001B[39;00m\n\u001B[0;32m    384\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(icnn_epochs):\n",
      "File \u001B[1;32m~\\Documents\\Programming\\ICNN_verification\\script\\NeuralNets\\trainFunction.py:48\u001B[0m, in \u001B[0;36mtrain_icnn\u001B[1;34m(model, train_loader, ambient_loader, epochs, optimizer, return_history, sequential, adapt_lambda, hyper_lambda, preemptive_stop, min_loss_change, verbose)\u001B[0m\n\u001B[0;32m     46\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m loss\n\u001B[0;32m     47\u001B[0m     loss \u001B[38;5;241m=\u001B[39m closure()\n\u001B[1;32m---> 48\u001B[0m     \u001B[43mopt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m     prediction_ambient \u001B[38;5;241m=\u001B[39m model(X_ambient)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\torchCPU\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001B[0m, in \u001B[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    138\u001B[0m profile_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimizer.step#\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.step\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(obj\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(profile_name):\n\u001B[1;32m--> 140\u001B[0m     out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    141\u001B[0m     obj\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\Documents\\Programming\\ICNN_verification\\script\\Optimizer\\sdlbfgs.py:193\u001B[0m, in \u001B[0;36mSdLBFGS.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    190\u001B[0m al \u001B[38;5;241m=\u001B[39m state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mal\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m    192\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_old):\n\u001B[1;32m--> 193\u001B[0m     ro[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.\u001B[39m \u001B[38;5;241m/\u001B[39m \u001B[43mold_stps\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mold_dirs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;66;03m# iteration in SdL-BFGS loop collapsed to use just one buffer\u001B[39;00m\n\u001B[0;32m    196\u001B[0m q \u001B[38;5;241m=\u001B[39m flat_grad\u001B[38;5;241m.\u001B[39mneg()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "group_size = 2\n",
    "icnn_factory = ICNNFactory(\"logical\", [5, 5, 1], force_positive_init=False, with_two_layers=False,\n",
    "                               init_scaling=10, init_all_with_zeros=False)\n",
    "#icnn_factory = ICNNFactory(\"standard\", [5, 5, 1])\n",
    "\n",
    "icnns, last_group_indices, fixed_neuron_per_layer_lower, fixed_neuron_per_layer_upper, bounds_affine_out, bounds_layer_out = \\\n",
    "    multidhov.start_verification(nn, test_image, icnn_factory, group_size, eps=eps, icnn_epochs=500,\n",
    "                                     icnn_batch_size=3, sample_count=1000, sample_new=True, use_over_approximation=True, break_after=51,\n",
    "                                     sample_over_input_space=False, sample_over_output_space=True, use_icnn_bounds=True,\n",
    "                                     use_fixed_neurons=True, sampling_method=\"per_group_sampling\",\n",
    "                                     force_inclusion_steps=0, preemptive_stop=False, even_gradient_training=False,\n",
    "                                     keep_ambient_space=True, data_grad_descent_steps=0, opt_steps_gd=100,\n",
    "                                     train_outer=False, print_training_loss=True,\n",
    "                                     should_plot=\"none\", optimizer=\"adam\", init_network=True, adapt_lambda=\"none\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "print(last_group_indices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0757,  5.6189,  1.1482, -3.6142,  1.6317, -1.2987,  0.5409, -0.5313,\n",
      "         1.9913,  0.7412,  1.2950,  3.1743,  2.3159, -1.3097, -0.9965,  5.6670,\n",
      "         0.2652,  2.9580, -0.9048,  5.3704,  0.0706,  6.1707,  1.9918,  5.1470,\n",
      "         7.3835, -0.7402,  4.4840,  4.4441,  1.3274,  3.7316],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "print(bounds_affine_out[1][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6429,  6.1889,  1.7723, -3.1887,  2.3423, -0.7422,  1.2457, -0.0882,\n",
      "         2.6099,  1.2459,  1.9281,  3.7094,  2.8397, -1.0436, -0.7669,  6.3403,\n",
      "         1.1305,  3.5073, -0.6783,  5.9606,  0.5130,  6.7461,  2.5670,  5.8033,\n",
      "         8.0480, -0.4741,  4.9826,  5.1774,  1.6728,  4.3185],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "print(bounds_affine_out[1][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0273,  4.8911,  0.4758, -4.1546,  0.6518, -2.1435, -0.4091, -1.1941,\n",
      "         1.1518,  0.0534,  0.4475,  2.2823,  1.6934, -1.8334, -1.4669,  4.6682,\n",
      "        -0.6848,  2.2005, -1.2830,  4.6710, -0.6092,  5.4843,  1.2427,  4.1688,\n",
      "         6.4462, -1.1600,  3.7549,  3.5614,  0.7072,  2.9282],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "tensor([ 1.5903,  6.9082,  2.4571, -2.6379,  3.3335,  0.0854,  2.2013,  0.5879,\n",
      "         3.4414,  1.9512,  2.7689,  4.5998,  3.4715, -0.5237, -0.3061,  7.3616,\n",
      "         2.0802,  4.2680, -0.2947,  6.6573,  1.2007,  7.4136,  3.3206,  6.7802,\n",
      "         8.9711, -0.0464,  5.7120,  6.0631,  2.2935,  5.0945],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_flattened = torch.flatten(test_image)\n",
    "simple_bounds_affine_out, simple_bounds_layer_out = nn.calculate_box_bounds([input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "print(simple_bounds_affine_out[1][0])\n",
    "print(simple_bounds_affine_out[1][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "dhov_model = icnn_model(icnns[layer_index][0], nn, test_image, eps, layer_index, 0, 1, print_log=True)\n",
    "dhov_model.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "icnn_neuron_name = \"icnn_var[{}]\".format(neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 10.0.0 build v10.0.0rc2 (win64)\n",
      "\n",
      "CPU model: AMD Ryzen 7 5800H with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Optimize a model with 39 rows, 131 columns and 86 nonzeros\n",
      "Model fingerprint: 0x73f1282a\n",
      "Model has 3 general constraints\n",
      "Variable types: 131 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-04, 4e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [7e-01, 3e+03]\n",
      "  RHS range        [1e-02, 3e+00]\n",
      "Presolve removed 32 rows and 126 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 7 rows, 5 columns, 16 nonzeros\n",
      "Variable types: 4 continuous, 1 integer (1 binary)\n",
      "Found heuristic solution: objective -0.0078686\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 1: -0.00786857 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective -7.868574787573e-03, best bound -7.868574787573e-03, gap 0.0000%\n",
      "opt value: -0.007868574787572746\n"
     ]
    }
   ],
   "source": [
    "dhov_copy = dhov_model.copy()\n",
    "dhov_copy.Params.LogToConsole = 1\n",
    "add_min_constr(dhov_copy, icnn_neuron_name)\n",
    "dhov_copy.update()\n",
    "all_var = dhov_copy.getVars()\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.6428877384264218\n"
     ]
    }
   ],
   "source": [
    "dhov_copy = dhov_model.copy()\n",
    "dhov_copy.Params.LogToConsole = 0\n",
    "add_max_constr(dhov_copy, icnn_neuron_name)\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for SNV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "snv_verifier = SingleNeuronVerifier(nn, test_image, eps, print_log=False)\n",
    "snv_verifier.generate_constraints_for_net()\n",
    "snv_model = snv_verifier.model\n",
    "snv_model.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "snv_copy = snv_model.copy()\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "add_min_constr(snv_copy, neuron_name)\n",
    "optimize_model(snv_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.9722473212684741\n"
     ]
    }
   ],
   "source": [
    "snv_copy = snv_model.copy()\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "add_max_constr(snv_copy, neuron_name)\n",
    "optimize_model(snv_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for MILP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "'all_var = milp_model.getVars()\\nfor var in all_var:\\n    print(var)'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_name = \"relu_var{}[{}]\".format(2*layer_index, 0)\n",
    "milp_verifier = MILPVerifier(nn, test_image, eps, print_log=False)\n",
    "milp_verifier.generate_constraints_for_net(until_layer_neuron=[layer_index, neuron_index])\n",
    "milp_model = milp_verifier.model\n",
    "milp_model.update()\n",
    "\n",
    "\"\"\"all_var = milp_model.getVars()\n",
    "for var in all_var:\n",
    "    print(var)\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "milp_copy = milp_model.copy()\n",
    "milp_copy.Params.LogToConsole = 0\n",
    "add_min_constr(milp_copy, neuron_name)\n",
    "optimize_model(milp_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.5622137652362753\n"
     ]
    }
   ],
   "source": [
    "milp_copy = milp_model.copy()\n",
    "milp_copy.Params.LogToConsole = 0\n",
    "add_max_constr(milp_copy, neuron_name)\n",
    "optimize_model(milp_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}