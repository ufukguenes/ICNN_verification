{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from script.NeuralNets.Networks import SequentialNN, ICNN, ICNNApproxMax, ICNNLogical\n",
    "from script.settings import device, data_type\n",
    "import script.DHOV.MultiDHOV as multidhov\n",
    "from script.Verification.Verifier import SingleNeuronVerifier, MILPVerifier, DHOVVerifier\n",
    "import gurobipy as grp\n",
    "from torchvision.datasets import CIFAR10, MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from script.NeuralNets.ICNNFactory import ICNNFactory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def add_max_constr(model, neuron_name):\n",
    "    neuron_var = model.getVarByName(neuron_name)\n",
    "    model.setObjective(neuron_var, grp.GRB.MAXIMIZE)\n",
    "\n",
    "def add_min_constr(model, neuron):\n",
    "    neuron_var = model.getVarByName(neuron)\n",
    "    model.setObjective(neuron_var, grp.GRB.MINIMIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def optimize_model(model, neuron_name):\n",
    "    model.update()\n",
    "    model.optimize()\n",
    "    if model.Status == grp.GRB.OPTIMAL:\n",
    "        print(\"opt value: {}\".format(model.getVarByName(neuron_name).getAttr(\"x\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def icnn_model(icnn, nn, input_x, eps, layer_index, from_neuron, to_neuron, print_log=False):\n",
    "    m = grp.Model()\n",
    "    if not print_log:\n",
    "        m.Params.LogToConsole = 0\n",
    "\n",
    "    input_flattened = torch.flatten(input_x)\n",
    "    bounds_affine_out, bounds_layer_out = nn.calculate_box_bounds(\n",
    "        [input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "\n",
    "    parameter_list = list(nn.parameters())\n",
    "\n",
    "    input_size = len(parameter_list[2*(layer_index-1)])\n",
    "    lb = bounds_layer_out[layer_index-1][0].detach().cpu().numpy()\n",
    "    ub = bounds_layer_out[layer_index-1][1].detach().cpu().numpy()\n",
    "    in_var = m.addMVar(input_size, lb=-float(\"inf\"), ub=float(\"inf\"), name=\"icnn_var\")\n",
    "\n",
    "    low = bounds_layer_out[layer_index - 1][0][from_neuron: to_neuron]\n",
    "    up = bounds_layer_out[layer_index - 1][1][from_neuron: to_neuron]\n",
    "    low = torch.zeros_like(low, dtype=data_type).to(device) - 1000\n",
    "    up = torch.zeros_like(low, dtype=data_type).to(device) + 1000\n",
    "    constraint_bounds_affine_out, constraint_bounds_layer_out = icnn.calculate_box_bounds([low, up])\n",
    "    icnn.add_max_output_constraints(m, in_var[from_neuron: to_neuron], constraint_bounds_affine_out, constraint_bounds_layer_out)\n",
    "\n",
    "    return m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'nn = SequentialNN([50, 50, 50, 7])\\ntest_image = torch.zeros((1, 50), dtype=data_type).to(device)\\nparameter_list = list(nn.parameters())'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"W1 = [1. 1.; 1. -1.]\n",
    "    b1 = [0., 0.]\n",
    "    W2 = [1. 1.; 1. -1.]\n",
    "    b2 = [-0.5, 0.]\n",
    "    W3 = [-1. 1.; 1. 1.]\n",
    "    b3 = [3., 0.] \"\"\"\n",
    "\n",
    "\"\"\"nn = SequentialNN([2, 2, 2, 2])\n",
    "\n",
    "with torch.no_grad():\n",
    "    parameter_list = list(nn.parameters())\n",
    "    parameter_list[0].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[1].data = torch.tensor([0, 0], dtype=data_type).to(device)\n",
    "    parameter_list[2].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[3].data = torch.tensor([-0.5, 0], dtype=data_type).to(device)\n",
    "    parameter_list[4].data = torch.tensor([[-1, 1], [1, 1]], dtype=data_type).to(device)\n",
    "    parameter_list[5].data = torch.tensor([3, 0], dtype=data_type).to(device)\n",
    "\n",
    "test_image = torch.tensor([[0, 0]], dtype=data_type).to(device)\"\"\"\n",
    "\n",
    "\"\"\"transform = Compose([ToTensor(),\n",
    "                         Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "                        )\n",
    "\n",
    "training_data = CIFAR10(root=\"../../cifar\", train=True, download=True, transform=transform)\n",
    "images, labels = training_data.__getitem__(0)\n",
    "test_image, test_label = torch.unsqueeze(images, 0).to(dtype=data_type).to(device), torch.unsqueeze(\n",
    "    torch.tensor(labels), 0).to(dtype=data_type).to(device)\n",
    "\n",
    "nn = SequentialNN([32 * 32 * 3, 1024, 512, 10])\n",
    "nn.load_state_dict(torch.load(\"../../cifar_fc.pth\", map_location=torch.device(device)), strict=False)\n",
    "\"\"\"\n",
    "\n",
    "transform = Compose([ToTensor(),\n",
    "                         Normalize(0.5, 0.5)]\n",
    "                        )\n",
    "\n",
    "training_data = MNIST(root=\"../../mnist\",\n",
    "                      train=True,\n",
    "                      download=True,\n",
    "                      transform=transform)\n",
    "images, labels = training_data.__getitem__(0)\n",
    "test_image, test_label = torch.unsqueeze(images, 0).to(dtype=data_type).to(device), torch.unsqueeze(\n",
    "    torch.tensor(labels), 0).to(dtype=data_type).to(device)\n",
    "\n",
    "nn = SequentialNN([28*28*1, 100, 30, 10])\n",
    "nn.load_state_dict(torch.load(\"../../mnist_fc.pth\", map_location=torch.device('cpu')), strict=False)\n",
    "\n",
    "parameter_list = list(nn.parameters())\n",
    "\n",
    "\"\"\"nn = SequentialNN([50, 50, 50, 7])\n",
    "test_image = torch.zeros((1, 50), dtype=data_type).to(device)\n",
    "parameter_list = list(nn.parameters())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "eps = 0.01"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for DHOV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "approximation of layer: 0\n",
      "    number of fixed neurons for current layer: 92\n",
      "    layer progress, group 1 of 2 \n",
      "        time for sampling for one group: 0.06086850166320801\n",
      "=== Epoch: 0===\n",
      "batch = 0, mean loss = 0.7263070978174967\n",
      "batch = 100, mean loss = 1.9905629510436618\n",
      "batch = 200, mean loss = 1.8171514702333729\n",
      "batch = 300, mean loss = 1.7218204980435954\n",
      "batch = 400, mean loss = 1.6370271435773995\n",
      "batch = 500, mean loss = 1.57796231284555\n",
      "batch = 600, mean loss = 1.5259610216791701\n",
      "batch = 700, mean loss = 1.4782660188467887\n",
      "batch = 800, mean loss = 1.4428924182503038\n",
      "batch = 900, mean loss = 1.4243796172653989\n",
      "batch = 1000, mean loss = 1.4035185718003798\n",
      "batch = 1100, mean loss = 1.3568291557494803\n",
      "batch = 1200, mean loss = 1.3036788407743665\n",
      "batch = 1300, mean loss = 1.2519749133852072\n",
      "batch = 1400, mean loss = 1.2000370766622788\n",
      "batch = 1500, mean loss = 1.1503557920637604\n",
      "batch = 1600, mean loss = 1.1075891055727287\n",
      "batch = 1700, mean loss = 1.066838338227432\n",
      "batch = 1800, mean loss = 1.0291048856345937\n",
      "batch = 1900, mean loss = 0.9952502197255312\n",
      "=== Epoch: 1===\n",
      "batch = 0, mean loss = 12.829195123872081\n",
      "batch = 100, mean loss = 1.7144772763063374\n",
      "batch = 200, mean loss = 1.38176361637801\n",
      "batch = 300, mean loss = 1.3510455185845416\n",
      "batch = 400, mean loss = 1.3070639410837601\n",
      "batch = 500, mean loss = 1.2965508816092741\n",
      "batch = 600, mean loss = 1.2731388886716666\n",
      "batch = 700, mean loss = 1.2468999637628524\n",
      "batch = 800, mean loss = 1.2357563717651117\n",
      "batch = 900, mean loss = 1.2383328774207134\n",
      "batch = 1000, mean loss = 1.231399097610964\n",
      "batch = 1100, mean loss = 1.1724377459491677\n",
      "batch = 1200, mean loss = 1.1142405219504594\n",
      "batch = 1300, mean loss = 1.0629017296558259\n",
      "batch = 1400, mean loss = 1.0142431518584707\n",
      "batch = 1500, mean loss = 0.9712610949793052\n",
      "batch = 1600, mean loss = 0.934884212022819\n",
      "batch = 1700, mean loss = 0.900301385799793\n",
      "batch = 1800, mean loss = 0.8681430629834337\n",
      "batch = 1900, mean loss = 0.8405850565424133\n",
      "=== Epoch: 2===\n",
      "batch = 0, mean loss = 8.4364755053412\n",
      "batch = 100, mean loss = 1.5138580261837244\n",
      "batch = 200, mean loss = 1.267129410805637\n",
      "batch = 300, mean loss = 1.2693444254635986\n",
      "batch = 400, mean loss = 1.2429196719882085\n",
      "batch = 500, mean loss = 1.243064417223442\n",
      "batch = 600, mean loss = 1.224310299479762\n",
      "batch = 700, mean loss = 1.202415656712713\n",
      "batch = 800, mean loss = 1.197855576974861\n",
      "batch = 900, mean loss = 1.2039899989166012\n",
      "batch = 1000, mean loss = 1.1991873666430393\n",
      "batch = 1100, mean loss = 1.142584512390634\n",
      "batch = 1200, mean loss = 1.0862036672211395\n",
      "batch = 1300, mean loss = 1.0359691621481404\n",
      "batch = 1400, mean loss = 0.9878391204040582\n",
      "batch = 1500, mean loss = 0.9454139603358935\n",
      "batch = 1600, mean loss = 0.9094431122378581\n",
      "batch = 1700, mean loss = 0.8751774102605795\n",
      "batch = 1800, mean loss = 0.8436737049783652\n",
      "batch = 1900, mean loss = 0.8167262646982383\n",
      "=== Epoch: 3===\n",
      "batch = 0, mean loss = 7.842433707540184\n",
      "batch = 100, mean loss = 1.530466968414043\n",
      "batch = 200, mean loss = 1.274950538951139\n",
      "batch = 300, mean loss = 1.2732324243115443\n",
      "batch = 400, mean loss = 1.2460017523369553\n",
      "batch = 500, mean loss = 1.2447911425627398\n",
      "batch = 600, mean loss = 1.2242911465120083\n",
      "batch = 700, mean loss = 1.201405180004387\n",
      "batch = 800, mean loss = 1.1974417591705342\n",
      "batch = 900, mean loss = 1.2030161924495395\n",
      "batch = 1000, mean loss = 1.1979728503998286\n",
      "batch = 1100, mean loss = 1.141572512507754\n",
      "batch = 1200, mean loss = 1.085304440274903\n",
      "batch = 1300, mean loss = 1.0354375888177656\n",
      "batch = 1400, mean loss = 0.9874760255254639\n",
      "batch = 1500, mean loss = 0.9450076626197893\n",
      "batch = 1600, mean loss = 0.9089903720221296\n",
      "batch = 1700, mean loss = 0.8742139269119253\n",
      "batch = 1800, mean loss = 0.8424487805054994\n",
      "batch = 1900, mean loss = 0.8153108349628135\n",
      "=== Epoch: 4===\n",
      "batch = 0, mean loss = 7.453885651755472\n",
      "batch = 100, mean loss = 1.5451354203614822\n",
      "batch = 200, mean loss = 1.2798558707620278\n",
      "batch = 300, mean loss = 1.2752763955809872\n",
      "batch = 400, mean loss = 1.2475268990540647\n",
      "batch = 500, mean loss = 1.2454069220997621\n",
      "batch = 600, mean loss = 1.2235268068697474\n",
      "batch = 700, mean loss = 1.1997774816001316\n",
      "batch = 800, mean loss = 1.1955550278778728\n",
      "batch = 900, mean loss = 1.2006288876134672\n",
      "batch = 1000, mean loss = 1.1954229378909396\n",
      "batch = 1100, mean loss = 1.1386176889148723\n",
      "batch = 1200, mean loss = 1.082009792022452\n",
      "batch = 1300, mean loss = 1.032188768932873\n",
      "batch = 1400, mean loss = 0.9843470683018335\n",
      "batch = 1500, mean loss = 0.9419032836492965\n",
      "batch = 1600, mean loss = 0.905916663926033\n",
      "batch = 1700, mean loss = 0.8710937139347429\n",
      "batch = 1800, mean loss = 0.8393654760856384\n",
      "batch = 1900, mean loss = 0.8123090768152179\n",
      "=== Epoch: 5===\n",
      "batch = 0, mean loss = 7.25425543239739\n",
      "batch = 100, mean loss = 1.5395462786166243\n",
      "batch = 200, mean loss = 1.2749698730803398\n",
      "batch = 300, mean loss = 1.2714912189594094\n",
      "batch = 400, mean loss = 1.2440171448078623\n",
      "batch = 500, mean loss = 1.2425265323121122\n",
      "batch = 600, mean loss = 1.2201188573463573\n",
      "batch = 700, mean loss = 1.1965910605435415\n",
      "batch = 800, mean loss = 1.1923860991410422\n",
      "batch = 900, mean loss = 1.1973999111124503\n",
      "batch = 1000, mean loss = 1.192221490097769\n",
      "batch = 1100, mean loss = 1.1356268865411407\n",
      "batch = 1200, mean loss = 1.0790828373236951\n",
      "batch = 1300, mean loss = 1.0295418486742642\n",
      "batch = 1400, mean loss = 0.9818541608186764\n",
      "batch = 1500, mean loss = 0.9395273124253493\n",
      "batch = 1600, mean loss = 0.9037019957704355\n",
      "batch = 1700, mean loss = 0.8688840265069372\n",
      "batch = 1800, mean loss = 0.8371937507643629\n",
      "batch = 1900, mean loss = 0.810190725932594\n",
      "        time for training: 28.169752597808838\n",
      "        actual verification time 0.18029189109802246\n",
      "        time for verification: 0.31508302688598633\n",
      "    layer progress, group 2 of 2 \n",
      "        time for sampling for one group: 0.040635108947753906\n",
      "=== Epoch: 0===\n",
      "batch = 0, mean loss = 0.6958827588418423\n",
      "batch = 100, mean loss = 1.4475551722249411\n",
      "batch = 200, mean loss = 1.3298763553034458\n",
      "batch = 300, mean loss = 1.2709519857005116\n",
      "batch = 400, mean loss = 1.2313198829197542\n",
      "batch = 500, mean loss = 1.2054431990084917\n",
      "batch = 600, mean loss = 1.1911850037073752\n",
      "batch = 700, mean loss = 1.1653652777845027\n",
      "batch = 800, mean loss = 1.156859169272935\n",
      "batch = 900, mean loss = 1.1461553071849047\n",
      "batch = 1000, mean loss = 1.1328100793396156\n",
      "batch = 1100, mean loss = 1.1140718745661644\n",
      "batch = 1200, mean loss = 1.0938674416025502\n",
      "batch = 1300, mean loss = 1.0697196142721086\n",
      "batch = 1400, mean loss = 1.0487378204847604\n",
      "batch = 1500, mean loss = 1.0283631230534738\n",
      "batch = 1600, mean loss = 1.0099629598691076\n",
      "batch = 1700, mean loss = 0.9932408845257368\n",
      "batch = 1800, mean loss = 0.9790223935033804\n",
      "batch = 1900, mean loss = 0.9655152078773308\n",
      "=== Epoch: 1===\n",
      "batch = 0, mean loss = 2.362412197037364\n",
      "batch = 100, mean loss = 1.4688802577694051\n",
      "batch = 200, mean loss = 1.217198230430166\n",
      "batch = 300, mean loss = 1.1637764184843182\n",
      "batch = 400, mean loss = 1.1285821915768504\n",
      "batch = 500, mean loss = 1.1121517055434984\n",
      "batch = 600, mean loss = 1.1109155273118716\n",
      "batch = 700, mean loss = 1.0917158509341787\n",
      "batch = 800, mean loss = 1.0884281469227504\n",
      "batch = 900, mean loss = 1.082392592755279\n",
      "batch = 1000, mean loss = 1.0755333698129794\n",
      "batch = 1100, mean loss = 1.0607717886528807\n",
      "batch = 1200, mean loss = 1.0435921774528232\n",
      "batch = 1300, mean loss = 1.0233834617161541\n",
      "batch = 1400, mean loss = 1.006716925455336\n",
      "batch = 1500, mean loss = 0.9899152995313276\n",
      "batch = 1600, mean loss = 0.9736773694789516\n",
      "batch = 1700, mean loss = 0.9588165139898017\n",
      "batch = 1800, mean loss = 0.9461940242273711\n",
      "batch = 1900, mean loss = 0.9343151680619382\n",
      "=== Epoch: 2===\n",
      "batch = 0, mean loss = 2.464127885914124\n",
      "batch = 100, mean loss = 1.3972335361481687\n",
      "batch = 200, mean loss = 1.1784528291624259\n",
      "batch = 300, mean loss = 1.1342124196972436\n",
      "batch = 400, mean loss = 1.102893208024595\n",
      "batch = 500, mean loss = 1.0897935577768398\n",
      "batch = 600, mean loss = 1.0902387695242342\n",
      "batch = 700, mean loss = 1.0731248640088322\n",
      "batch = 800, mean loss = 1.0703164779983942\n",
      "batch = 900, mean loss = 1.0660316649595643\n",
      "batch = 1000, mean loss = 1.0606818547802055\n",
      "batch = 1100, mean loss = 1.046648837500157\n",
      "batch = 1200, mean loss = 1.0297720091528344\n",
      "batch = 1300, mean loss = 1.0100683667155117\n",
      "batch = 1400, mean loss = 0.9937582680105423\n",
      "batch = 1500, mean loss = 0.9776307798644962\n",
      "batch = 1600, mean loss = 0.9622488345034623\n",
      "batch = 1700, mean loss = 0.9479658279445127\n",
      "batch = 1800, mean loss = 0.9355678710152177\n",
      "batch = 1900, mean loss = 0.924006774674733\n",
      "=== Epoch: 3===\n",
      "batch = 0, mean loss = 2.5588994730156487\n",
      "batch = 100, mean loss = 1.4002035995680118\n",
      "batch = 200, mean loss = 1.1808372703133823\n",
      "batch = 300, mean loss = 1.1349645062295088\n",
      "batch = 400, mean loss = 1.1025202173828295\n",
      "batch = 500, mean loss = 1.0893408424835294\n",
      "batch = 600, mean loss = 1.0887940385240549\n",
      "batch = 700, mean loss = 1.0715078109334735\n",
      "batch = 800, mean loss = 1.0681730523123252\n",
      "batch = 900, mean loss = 1.0640478443506685\n",
      "batch = 1000, mean loss = 1.0585640922400414\n",
      "batch = 1100, mean loss = 1.0445063887796675\n",
      "batch = 1200, mean loss = 1.0277921990054197\n",
      "batch = 1300, mean loss = 1.0080086750362902\n",
      "batch = 1400, mean loss = 0.9916761851482918\n",
      "batch = 1500, mean loss = 0.9756272784297888\n",
      "batch = 1600, mean loss = 0.9603861236879804\n",
      "batch = 1700, mean loss = 0.9461963046717863\n",
      "batch = 1800, mean loss = 0.9336969227188545\n",
      "batch = 1900, mean loss = 0.9220878033079684\n",
      "=== Epoch: 4===\n",
      "batch = 0, mean loss = 2.504057097380365\n",
      "batch = 100, mean loss = 1.3978054014562875\n",
      "batch = 200, mean loss = 1.1789505037541217\n",
      "batch = 300, mean loss = 1.1330362308171398\n",
      "batch = 400, mean loss = 1.100376470268403\n",
      "batch = 500, mean loss = 1.0873396759397087\n",
      "batch = 600, mean loss = 1.0866892389590497\n",
      "batch = 700, mean loss = 1.0695212417260445\n",
      "batch = 800, mean loss = 1.0656834437215914\n",
      "batch = 900, mean loss = 1.0616822567447683\n",
      "batch = 1000, mean loss = 1.0561926897488234\n",
      "batch = 1100, mean loss = 1.0421630196497533\n",
      "batch = 1200, mean loss = 1.0253303061715404\n",
      "batch = 1300, mean loss = 1.0053818010637339\n",
      "batch = 1400, mean loss = 0.9887495250669678\n",
      "batch = 1500, mean loss = 0.9726302220915939\n",
      "batch = 1600, mean loss = 0.9574529372057637\n",
      "batch = 1700, mean loss = 0.9433662066067341\n",
      "batch = 1800, mean loss = 0.9309207383863439\n",
      "batch = 1900, mean loss = 0.9194287422463558\n",
      "=== Epoch: 5===\n",
      "batch = 0, mean loss = 2.458002359493209\n",
      "batch = 100, mean loss = 1.395538961347119\n",
      "batch = 200, mean loss = 1.1751456519909562\n",
      "batch = 300, mean loss = 1.1295139803145995\n",
      "batch = 400, mean loss = 1.0966173977887792\n",
      "batch = 500, mean loss = 1.0839498114329118\n",
      "batch = 600, mean loss = 1.083018313769229\n",
      "batch = 700, mean loss = 1.065713913900152\n",
      "batch = 800, mean loss = 1.061486051439672\n",
      "batch = 900, mean loss = 1.05774452137025\n",
      "batch = 1000, mean loss = 1.052314174136951\n",
      "batch = 1100, mean loss = 1.0385887355217056\n",
      "batch = 1200, mean loss = 1.0216878275884524\n",
      "batch = 1300, mean loss = 1.0015624075068772\n",
      "batch = 1400, mean loss = 0.9849708081758453\n",
      "batch = 1500, mean loss = 0.9688987609343118\n",
      "batch = 1600, mean loss = 0.9538017154222276\n",
      "batch = 1700, mean loss = 0.9398136496310536\n",
      "batch = 1800, mean loss = 0.927541728766049\n",
      "batch = 1900, mean loss = 0.916199126687605\n",
      "        time for training: 28.173767566680908\n",
      "        actual verification time 0.06150960922241211\n",
      "        time for verification: 0.18559932708740234\n",
      "    time for regrouping method: 0.0\n",
      "\n",
      "approximation of layer: 1\n",
      "        lower: new -0.07765699722062919, old -1.0272694263485382\n",
      "        upper: new 0.6439635464237189, old 1.590265447932639\n",
      "        lower: new 5.619377058057212, old 4.891074441089023\n",
      "        upper: new 6.188892350651961, old 6.908179377487894\n",
      "        lower: new 1.1482282982544463, old 0.4758416777957901\n",
      "        upper: new 1.767785826567232, old 2.45705423241999\n",
      "        lower: new -3.6142057804852086, old -4.154560614460519\n",
      "        upper: new -3.1945842676787577, old -2.6379028626565093\n",
      "        lower: new 1.6298233063478973, old 0.6517725440588809\n",
      "        upper: new 2.3468338589264435, old 3.3335162230102693\n",
      "        lower: new -1.30430821683908, old -2.143489793168459\n",
      "        upper: new -0.7425728364032159, old 0.0854374951093364\n",
      "        lower: new 0.5384099657439204, old -0.409115897681394\n",
      "        upper: new 1.2505398182792666, old 2.2013279327856976\n",
      "        lower: new -0.5323833408078734, old -1.194134963667596\n",
      "        upper: new -0.08472938888522706, old 0.5879126079003312\n",
      "        lower: new 1.9801316663658506, old 1.1517885635031728\n",
      "        upper: new 2.6093188584143614, old 3.4413901127827238\n",
      "        lower: new 0.741233783146717, old 0.053368456055829405\n",
      "        upper: new 1.254305223750692, old 1.951150902106173\n",
      "        lower: new 1.289103021948643, old 0.4474716841053148\n",
      "        upper: new 1.9283165274112721, old 2.7688675833083156\n",
      "        lower: new 3.1767307325756904, old 2.2823298654349804\n",
      "        upper: new 3.710161021610619, old 4.599801049017392\n",
      "        lower: new 2.3159349223013974, old 1.6933718660848394\n",
      "        upper: new 2.8246526007577146, old 3.471459235031665\n",
      "        lower: new -1.3125666887307998, old -1.8334256175700663\n",
      "        upper: new -1.0399690818883638, old -0.5237117713086965\n",
      "        lower: new -1.002861747650774, old -1.466869389694395\n",
      "        upper: new -0.7687161871343708, old -0.30613013523807897\n",
      "        lower: new 5.665520629344293, old 4.668204914112108\n",
      "        upper: new 6.348171729626524, old 7.361566298400341\n",
      "        lower: new 0.26497666416904647, old -0.6847946385441421\n",
      "        upper: new 1.1255486299371742, old 2.0801847320655966\n",
      "        lower: new 2.9613812691756767, old 2.2004989456216055\n",
      "        upper: new 3.5078274044360835, old 4.267971015539602\n",
      "        lower: new -0.9054087427456698, old -1.2830149131120172\n",
      "        upper: new -0.678498098696377, old -0.29468515782038596\n",
      "        lower: new 5.374366947472981, old 4.670984259366115\n",
      "        upper: new 5.957689274527782, old 6.657308087984413\n",
      "        lower: new 0.07062257344304564, old -0.6091871666301043\n",
      "        upper: new 0.51803356630341, old 1.200720888753544\n",
      "        lower: new 6.174147693362204, old 5.484337577617196\n",
      "        upper: new 6.746114779497837, old 7.413609163446834\n",
      "        lower: new 1.9918280097337822, old 1.2427032510074483\n",
      "        upper: new 2.567724231174834, old 3.320612581395128\n",
      "        lower: new 5.142264511704205, old 4.168817558547471\n",
      "        upper: new 5.805290457023303, old 6.780179104352769\n",
      "        lower: new 7.389885174361593, old 6.446242411024807\n",
      "        upper: new 8.04732016031602, old 8.971084931603443\n",
      "        lower: new -0.7408716516122217, old -1.1600468860809312\n",
      "        upper: new -0.4653931069959214, old -0.046419147582785314\n",
      "        lower: new 4.483645861555731, old 3.754943133455928\n",
      "        upper: new 4.982977875648116, old 5.711956539875997\n",
      "        lower: new 4.442982119987138, old 3.561375283453498\n",
      "        upper: new 5.179967403844819, old 6.063069775488341\n",
      "        lower: new 1.328374781694314, old 0.7072285143067245\n",
      "        upper: new 1.6727917939393173, old 2.2934821027747554\n",
      "        lower: new 3.728750364263268, old 2.928185776482185\n",
      "        upper: new 4.318519267131344, old 5.094451979379954\n",
      "    time for icnn_bound calculation: 1.589829683303833\n",
      "    number of fixed neurons for current layer: 29\n",
      "    layer progress, group 1 of 1 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m#icnn_factory = ICNNFactory(\"standard\", [5, 5, 1])\u001B[39;00m\n\u001B[0;32m      6\u001B[0m dhov_verifier \u001B[38;5;241m=\u001B[39m multidhov\u001B[38;5;241m.\u001B[39mMultiDHOV()\n\u001B[1;32m----> 7\u001B[0m \u001B[43mdhov_verifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_verification\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_image\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43micnn_factory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43micnn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43micnn_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_count\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_new\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_over_approximation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbreak_after\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43msample_over_input_space\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_over_output_space\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_icnn_bounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43muse_fixed_neurons\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampling_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mper_group_sampling\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mforce_inclusion_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreemptive_stop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meven_gradient_training\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mkeep_ambient_space\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_grad_descent_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt_steps_gd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mtrain_outer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_training_loss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_new_bounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mshould_plot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnone\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43madam\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_network\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madapt_lambda\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnone\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Programming\\ICNN_verification\\script\\DHOV\\MultiDHOV.py:300\u001B[0m, in \u001B[0;36mMultiDHOV.start_verification\u001B[1;34m(self, nn, input, icnn_factory, group_size, eps, icnn_batch_size, icnn_epochs, sample_count, sampling_method, break_after, use_icnn_bounds, use_fixed_neurons, keep_ambient_space, sample_new, use_over_approximation, opt_steps_gd, sample_over_input_space, sample_over_output_space, data_grad_descent_steps, train_outer, preemptive_stop, even_gradient_training, force_inclusion_steps, init_network, adapt_lambda, should_plot, optimizer, print_training_loss, print_new_bounds)\u001B[0m\n\u001B[0;32m    298\u001B[0m copy_model \u001B[38;5;241m=\u001B[39m nn_encoding_model\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m    299\u001B[0m t_group \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 300\u001B[0m included_space \u001B[38;5;241m=\u001B[39m \u001B[43mds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample_per_group_as_lp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mincluded_space\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minc_space_sample_count\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    301\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43maffine_w\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maffine_b\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    302\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mindex_to_select\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    303\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mbounds_affine_out\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcurrent_layer_index\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    304\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mprev_layer_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    305\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mrand_samples_percent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    306\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mrand_sample_alternation_percent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    307\u001B[0m included_space \u001B[38;5;241m=\u001B[39m ds\u001B[38;5;241m.\u001B[39msample_uniform_over_icnn(included_space, inc_space_sample_count \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m    308\u001B[0m                                              list_of_icnns[current_layer_index \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m],\n\u001B[0;32m    309\u001B[0m                                              all_group_indices[current_layer_index \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m],\n\u001B[0;32m    310\u001B[0m                                              bounds_layer_out[current_layer_index \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m],\n\u001B[0;32m    311\u001B[0m                                              keep_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    312\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        time for sampling for one group: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m t_group))\n",
      "File \u001B[1;32m~\\Documents\\Programming\\ICNN_verification\\script\\DHOV\\DataSampling.py:293\u001B[0m, in \u001B[0;36msample_per_group_as_lp\u001B[1;34m(data_samples, amount, affine_w, affine_b, index_to_select, model, curr_bounds_affine_out, prev_layer_index, rand_samples_percent, rand_sample_alternation_percent, keep_samples)\u001B[0m\n\u001B[0;32m    290\u001B[0m c \u001B[38;5;241m=\u001B[39m c\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m    291\u001B[0m model\u001B[38;5;241m.\u001B[39msetObjective(c \u001B[38;5;241m@\u001B[39m output_var, grp\u001B[38;5;241m.\u001B[39mGRB\u001B[38;5;241m.\u001B[39mMAXIMIZE)\n\u001B[1;32m--> 293\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model\u001B[38;5;241m.\u001B[39mStatus \u001B[38;5;241m==\u001B[39m grp\u001B[38;5;241m.\u001B[39mGRB\u001B[38;5;241m.\u001B[39mOPTIMAL:\n\u001B[0;32m    295\u001B[0m     samples[index] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(output_prev_layer\u001B[38;5;241m.\u001B[39mgetAttr(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m), dtype\u001B[38;5;241m=\u001B[39mdata_type)\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "group_size = 4\n",
    "icnn_factory = ICNNFactory(\"logical\", [10, 10, 1], force_positive_init=False, with_two_layers=False,\n",
    "                               init_scaling=10, init_all_with_zeros=False)\n",
    "#icnn_factory = ICNNFactory(\"standard\", [5, 5, 1])\n",
    "\n",
    "dhov_verifier = multidhov.MultiDHOV()\n",
    "dhov_verifier.start_verification(nn, test_image, icnn_factory, group_size, eps=eps, icnn_epochs=6,\n",
    "                                 icnn_batch_size=1, sample_count=4000, sample_new=True, use_over_approximation=True, break_after=None,\n",
    "                                 sample_over_input_space=False, sample_over_output_space=True, use_icnn_bounds=True,\n",
    "                                 use_fixed_neurons=True, sampling_method=\"per_group_sampling\",\n",
    "                                 force_inclusion_steps=0, preemptive_stop=False, even_gradient_training=False,\n",
    "                                 keep_ambient_space=True, data_grad_descent_steps=0, opt_steps_gd=100,\n",
    "                                 train_outer=False, print_training_loss=True, print_new_bounds=True,\n",
    "                                 should_plot=\"none\", optimizer=\"adam\", init_network=True, adapt_lambda=\"none\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "layer_index = 1\n",
    "neuron_index = 0\n",
    "neuron_name = \"relu_var{}[{}]\".format(2*layer_index, neuron_index)\n",
    "# neuron_name = \"last_affine_var[{}]\".format(neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1, 23, 25, 51, 60, 69], [86, 96]], [[0]]]\n"
     ]
    }
   ],
   "source": [
    "print(dhov_verifier.all_group_indices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.4146e-03,  7.4557e-01, -5.6243e-01,  8.4533e+00, -1.3533e+01,\n",
      "         9.8790e+00, -4.1001e+00,  1.4761e+00, -4.4413e+00, -3.1309e+00],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "print(dhov_verifier.bounds_affine_out[layer_index][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.1148,   2.0757,   1.4071,  10.0276, -11.8640,  11.4802,  -2.8277,\n",
      "          2.8650,  -2.9554,  -1.6298], dtype=torch.float64,\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "print(dhov_verifier.bounds_affine_out[layer_index][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -5.2223,  -4.9188,  -6.6589,   2.6449, -18.6182,   3.6405,  -9.5669,\n",
      "         -4.3524, -10.9687,  -9.1357], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([ 6.4550,  7.2957,  7.8522, 15.6069, -5.7168, 17.2791,  2.3780,  8.4534,\n",
      "         3.7083,  4.3367], dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_flattened = torch.flatten(test_image)\n",
    "simple_bounds_affine_out, simple_bounds_layer_out = nn.calculate_box_bounds([input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "print(simple_bounds_affine_out[layer_index][0])\n",
    "print(simple_bounds_affine_out[layer_index][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "icnn_neuron_name = \"output_layer_[{}]_[{}]\".format(layer_index, neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.01661858322323939\n"
     ]
    }
   ],
   "source": [
    "dhov_copy = dhov_verifier.nn_encoding_model.copy()\n",
    "add_min_constr(dhov_copy, icnn_neuron_name)\n",
    "dhov_copy.update()\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 1.1121084806256867\n"
     ]
    }
   ],
   "source": [
    "dhov_copy = dhov_verifier.nn_encoding_model.copy()\n",
    "dhov_copy.Params.LogToConsole = 0\n",
    "add_max_constr(dhov_copy, icnn_neuron_name)\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for SNV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "snv_verifier = SingleNeuronVerifier(nn, test_image, eps, print_log=False)\n",
    "snv_verifier.generate_constraints_for_net()\n",
    "snv_model = snv_verifier.model\n",
    "snv_model.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "snv_copy = snv_model.copy()\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "add_min_constr(snv_copy, neuron_name)\n",
    "optimize_model(snv_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.9722473212684741\n"
     ]
    }
   ],
   "source": [
    "snv_copy = snv_model.copy()\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "add_max_constr(snv_copy, neuron_name)\n",
    "optimize_model(snv_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for MILP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "'all_var = milp_model.getVars()\\nfor var in all_var:\\n    print(var)'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milp_verifier = MILPVerifier(nn, test_image, eps, print_log=False)\n",
    "milp_verifier.generate_constraints_for_net(until_layer_neuron=[layer_index, neuron_index])\n",
    "milp_model = milp_verifier.model\n",
    "milp_model.update()\n",
    "\n",
    "\"\"\"all_var = milp_model.getVars()\n",
    "for var in all_var:\n",
    "    print(var)\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "milp_copy = milp_model.copy()\n",
    "milp_copy.Params.LogToConsole = 0\n",
    "add_min_constr(milp_copy, neuron_name)\n",
    "optimize_model(milp_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.5622137652362753\n"
     ]
    }
   ],
   "source": [
    "milp_copy = milp_model.copy()\n",
    "milp_copy.Params.LogToConsole = 0\n",
    "add_max_constr(milp_copy, neuron_name)\n",
    "optimize_model(milp_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}