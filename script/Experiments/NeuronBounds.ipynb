{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from script.NeuralNets.Networks import SequentialNN, ICNN, ICNNApproxMax, ICNNLogical\n",
    "from script.settings import device, data_type\n",
    "import script.DHOV.MultiDHOV as multidhov\n",
    "from script.Verification.Verifier import SingleNeuronVerifier, MILPVerifier, DHOVVerifier\n",
    "import gurobipy as grp\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from script.NeuralNets.ICNNFactory import ICNNFactory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def add_max_constr(model, neuron_name):\n",
    "    neuron_var = model.getVarByName(neuron_name)\n",
    "    model.setObjective(neuron_var, grp.GRB.MAXIMIZE)\n",
    "\n",
    "def add_min_constr(model, neuron):\n",
    "    neuron_var = model.getVarByName(neuron)\n",
    "    model.setObjective(neuron_var, grp.GRB.MINIMIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def optimize_model(model, neuron_name):\n",
    "    model.update()\n",
    "    model.optimize()\n",
    "    if model.Status == grp.GRB.OPTIMAL:\n",
    "        print(\"opt value: {}\".format(model.getVarByName(neuron_name).getAttr(\"x\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def icnn_model(icnn, nn, input_x, eps, layer_index, from_neuron, to_neuron, print_log=False):\n",
    "    m = grp.Model()\n",
    "    if not print_log:\n",
    "        m.Params.LogToConsole = 0\n",
    "\n",
    "    input_flattened = torch.flatten(input_x)\n",
    "    bounds_affine_out, bounds_layer_out = nn.calculate_box_bounds(\n",
    "        [input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "\n",
    "    parameter_list = list(nn.parameters())\n",
    "\n",
    "    input_size = len(parameter_list[2*layer_index])\n",
    "    lb = bounds_layer_out[layer_index][0].detach().cpu().numpy()\n",
    "    ub = bounds_layer_out[layer_index][1].detach().cpu().numpy()\n",
    "    in_var = m.addMVar(input_size, lb=lb, ub=ub, name=\"icnn_var\")\n",
    "\n",
    "    low = bounds_layer_out[layer_index][0][from_neuron: to_neuron]\n",
    "    up = bounds_layer_out[layer_index][1][from_neuron: to_neuron]\n",
    "    constraint_bounds_affine_out, constraint_bounds_layer_out = icnn.calculate_box_bounds([low, up])\n",
    "    icnn.add_max_output_constraints(m, in_var[from_neuron: to_neuron], constraint_bounds_affine_out, constraint_bounds_layer_out)\n",
    "\n",
    "    return m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": "'nn = SequentialNN([50, 50, 50, 7])\\ntest_image = torch.zeros((1, 50), dtype=data_type).to(device)\\nparameter_list = list(nn.parameters())'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"W1 = [1. 1.; 1. -1.]\n",
    "    b1 = [0., 0.]\n",
    "    W2 = [1. 1.; 1. -1.]\n",
    "    b2 = [-0.5, 0.]\n",
    "    W3 = [-1. 1.; 1. 1.]\n",
    "    b3 = [3., 0.] \"\"\"\n",
    "\n",
    "\"\"\"nn = SequentialNN([2, 2, 2, 2])\n",
    "\n",
    "with torch.no_grad():\n",
    "    parameter_list = list(nn.parameters())\n",
    "    parameter_list[0].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[1].data = torch.tensor([0, 0], dtype=data_type).to(device)\n",
    "    parameter_list[2].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[3].data = torch.tensor([-0.5, 0], dtype=data_type).to(device)\n",
    "    parameter_list[4].data = torch.tensor([[-1, 1], [1, 1]], dtype=data_type).to(device)\n",
    "    parameter_list[5].data = torch.tensor([3, 0], dtype=data_type).to(device)\n",
    "\n",
    "test_image = torch.tensor([[0, 0]], dtype=data_type).to(device)\"\"\"\n",
    "\n",
    "transform = Compose([ToTensor(),\n",
    "                         Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "                        )\n",
    "\n",
    "training_data = CIFAR10(root=\"../../cifar\", train=True, download=True, transform=transform)\n",
    "images, labels = training_data.__getitem__(0)\n",
    "test_image, test_label = torch.unsqueeze(images, 0).to(dtype=data_type).to(device), torch.unsqueeze(\n",
    "    torch.tensor(labels), 0).to(dtype=data_type).to(device)\n",
    "\n",
    "nn = SequentialNN([32 * 32 * 3, 1024, 512, 10])\n",
    "nn.load_state_dict(torch.load(\"../../cifar_fc.pth\", map_location=torch.device(device)), strict=False)\n",
    "parameter_list = list(nn.parameters())\n",
    "\n",
    "\"\"\"nn = SequentialNN([50, 50, 50, 7])\n",
    "test_image = torch.zeros((1, 50), dtype=data_type).to(device)\n",
    "parameter_list = list(nn.parameters())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "eps = 0.01\n",
    "layer_index = 1\n",
    "neuron_index = 0\n",
    "neuron_name = \"relu_var{}[{}]\".format(2*layer_index, neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for DHOV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "approximation of layer: 0\n",
      "    number of fixed neurons for current layer: 571\n",
      "    layer progress, group 1 of 151 \n",
      "=== Epoch: 0===\n",
      "batch = 0, mean loss = 1.238969326019287\n",
      "batch = 1, mean loss = 1.238969326019287\n",
      "time per epoch: 0.037999629974365234\n",
      "=== Epoch: 1===\n",
      "batch = 0, mean loss = 1.081930160522461\n",
      "batch = 1, mean loss = 1.081930160522461\n",
      "time per epoch: 0.05453157424926758\n",
      "=== Epoch: 2===\n",
      "batch = 0, mean loss = 1.019504427909851\n",
      "batch = 1, mean loss = 1.019504427909851\n",
      "time per epoch: 0.05722618103027344\n",
      "=== Epoch: 3===\n",
      "batch = 0, mean loss = 1.0235786437988281\n",
      "batch = 1, mean loss = 1.0235786437988281\n",
      "time per epoch: 0.04444098472595215\n",
      "=== Epoch: 4===\n",
      "batch = 0, mean loss = 1.0168006420135498\n",
      "batch = 1, mean loss = 1.0168006420135498\n",
      "time per epoch: 0.042067527770996094\n",
      "=== Epoch: 5===\n",
      "batch = 0, mean loss = 0.9995940327644348\n",
      "batch = 1, mean loss = 0.9995940327644348\n",
      "time per epoch: 0.04700016975402832\n",
      "=== Epoch: 6===\n",
      "batch = 0, mean loss = 0.9761587381362915\n",
      "batch = 1, mean loss = 0.9761587381362915\n",
      "time per epoch: 0.04300093650817871\n",
      "=== Epoch: 7===\n",
      "batch = 0, mean loss = 0.9971631765365601\n",
      "batch = 1, mean loss = 0.9971631765365601\n",
      "time per epoch: 0.04198122024536133\n",
      "=== Epoch: 8===\n",
      "batch = 0, mean loss = 0.9707096815109253\n",
      "batch = 1, mean loss = 0.9707096815109253\n",
      "time per epoch: 0.055155277252197266\n",
      "=== Epoch: 9===\n",
      "batch = 0, mean loss = 0.9665328860282898\n",
      "batch = 1, mean loss = 0.9665328860282898\n",
      "time per epoch: 0.06300115585327148\n",
      "=== Epoch: 10===\n",
      "batch = 0, mean loss = 0.9701288938522339\n",
      "batch = 1, mean loss = 0.9701288938522339\n",
      "time per epoch: 0.05499434471130371\n",
      "=== Epoch: 11===\n",
      "batch = 0, mean loss = 0.9714877605438232\n",
      "batch = 1, mean loss = 0.9714877605438232\n",
      "time per epoch: 0.051000356674194336\n",
      "=== Epoch: 12===\n",
      "batch = 0, mean loss = 0.9680887460708618\n",
      "batch = 1, mean loss = 0.9680887460708618\n",
      "time per epoch: 0.04900074005126953\n",
      "=== Epoch: 13===\n",
      "batch = 0, mean loss = 0.9666404128074646\n",
      "batch = 1, mean loss = 0.9666404128074646\n",
      "time per epoch: 0.0534205436706543\n",
      "=== Epoch: 14===\n",
      "batch = 0, mean loss = 0.9665446281433105\n",
      "batch = 1, mean loss = 0.9665446281433105\n",
      "time per epoch: 0.05600237846374512\n",
      "=== Epoch: 15===\n",
      "batch = 0, mean loss = 0.9575152397155762\n",
      "batch = 1, mean loss = 0.9575152397155762\n",
      "time per epoch: 0.05599617958068848\n",
      "=== Epoch: 16===\n",
      "batch = 0, mean loss = 0.9646738767623901\n",
      "batch = 1, mean loss = 0.9646738767623901\n",
      "time per epoch: 0.04700326919555664\n",
      "=== Epoch: 17===\n",
      "batch = 0, mean loss = 0.9530519247055054\n",
      "batch = 1, mean loss = 0.9530519247055054\n",
      "time per epoch: 0.04199647903442383\n",
      "=== Epoch: 18===\n",
      "batch = 0, mean loss = 0.9736337661743164\n",
      "batch = 1, mean loss = 0.9736337661743164\n",
      "time per epoch: 0.03599834442138672\n",
      "=== Epoch: 19===\n",
      "batch = 0, mean loss = 0.9482196569442749\n",
      "batch = 1, mean loss = 0.9482196569442749\n",
      "time per epoch: 0.04800224304199219\n",
      "=== Epoch: 20===\n",
      "batch = 0, mean loss = 0.9484400749206543\n",
      "batch = 1, mean loss = 0.9484400749206543\n",
      "time per epoch: 0.0395205020904541\n",
      "=== Epoch: 21===\n",
      "batch = 0, mean loss = 0.9410430192947388\n",
      "batch = 1, mean loss = 0.9410430192947388\n",
      "time per epoch: 0.04552125930786133\n",
      "=== Epoch: 22===\n",
      "batch = 0, mean loss = 0.9395991563796997\n",
      "batch = 1, mean loss = 0.9395991563796997\n",
      "time per epoch: 0.043000221252441406\n",
      "=== Epoch: 23===\n",
      "batch = 0, mean loss = 0.9351733922958374\n",
      "batch = 1, mean loss = 0.9351733922958374\n",
      "time per epoch: 0.04326272010803223\n",
      "=== Epoch: 24===\n",
      "batch = 0, mean loss = 0.9312888979911804\n",
      "batch = 1, mean loss = 0.9312888979911804\n",
      "time per epoch: 0.062296152114868164\n",
      "=== Epoch: 25===\n",
      "batch = 0, mean loss = 0.9307392835617065\n",
      "batch = 1, mean loss = 0.9307392835617065\n",
      "time per epoch: 0.0585634708404541\n",
      "=== Epoch: 26===\n",
      "batch = 0, mean loss = 0.929680347442627\n",
      "batch = 1, mean loss = 0.929680347442627\n",
      "time per epoch: 0.05754566192626953\n",
      "=== Epoch: 27===\n",
      "batch = 0, mean loss = 0.9257436990737915\n",
      "batch = 1, mean loss = 0.9257436990737915\n",
      "time per epoch: 0.0709998607635498\n",
      "=== Epoch: 28===\n",
      "batch = 0, mean loss = 0.9224673509597778\n",
      "batch = 1, mean loss = 0.9224673509597778\n",
      "time per epoch: 0.0729985237121582\n",
      "=== Epoch: 29===\n",
      "batch = 0, mean loss = 0.9199681878089905\n",
      "batch = 1, mean loss = 0.9199681878089905\n",
      "time per epoch: 0.06713080406188965\n",
      "=== Epoch: 30===\n",
      "batch = 0, mean loss = 0.918602705001831\n",
      "batch = 1, mean loss = 0.918602705001831\n",
      "time per epoch: 0.06699895858764648\n",
      "=== Epoch: 31===\n",
      "batch = 0, mean loss = 0.9231629371643066\n",
      "batch = 1, mean loss = 0.9231629371643066\n",
      "time per epoch: 0.07400083541870117\n",
      "=== Epoch: 32===\n",
      "batch = 0, mean loss = 0.9182828664779663\n",
      "batch = 1, mean loss = 0.9182828664779663\n",
      "time per epoch: 0.044997453689575195\n",
      "=== Epoch: 33===\n",
      "batch = 0, mean loss = 0.9122871160507202\n",
      "batch = 1, mean loss = 0.9122871160507202\n",
      "time per epoch: 0.04123258590698242\n",
      "=== Epoch: 34===\n",
      "batch = 0, mean loss = 0.9096869826316833\n",
      "batch = 1, mean loss = 0.9096869826316833\n",
      "time per epoch: 0.03999972343444824\n",
      "=== Epoch: 35===\n",
      "batch = 0, mean loss = 0.9086302518844604\n",
      "batch = 1, mean loss = 0.9086302518844604\n",
      "time per epoch: 0.03674936294555664\n",
      "=== Epoch: 36===\n",
      "batch = 0, mean loss = 0.9070061445236206\n",
      "batch = 1, mean loss = 0.9070061445236206\n",
      "time per epoch: 0.041198015213012695\n",
      "=== Epoch: 37===\n",
      "batch = 0, mean loss = 0.9050061106681824\n",
      "batch = 1, mean loss = 0.9050061106681824\n",
      "time per epoch: 0.03499746322631836\n",
      "=== Epoch: 38===\n",
      "batch = 0, mean loss = 0.9024159908294678\n",
      "batch = 1, mean loss = 0.9024159908294678\n",
      "time per epoch: 0.04199981689453125\n",
      "=== Epoch: 39===\n",
      "batch = 0, mean loss = 0.9058331251144409\n",
      "batch = 1, mean loss = 0.9058331251144409\n",
      "time per epoch: 0.04700160026550293\n",
      "=== Epoch: 40===\n",
      "batch = 0, mean loss = 0.9037354588508606\n",
      "batch = 1, mean loss = 0.9037354588508606\n",
      "time per epoch: 0.05201101303100586\n",
      "=== Epoch: 41===\n",
      "batch = 0, mean loss = 0.901837170124054\n",
      "batch = 1, mean loss = 0.901837170124054\n",
      "time per epoch: 0.041068077087402344\n",
      "=== Epoch: 42===\n",
      "batch = 0, mean loss = 0.9014520645141602\n",
      "batch = 1, mean loss = 0.9014520645141602\n",
      "time per epoch: 0.048381805419921875\n",
      "=== Epoch: 43===\n",
      "batch = 0, mean loss = 0.9025942087173462\n",
      "batch = 1, mean loss = 0.9025942087173462\n",
      "time per epoch: 0.050444841384887695\n",
      "=== Epoch: 44===\n",
      "batch = 0, mean loss = 0.897477388381958\n",
      "batch = 1, mean loss = 0.897477388381958\n",
      "time per epoch: 0.05062294006347656\n",
      "=== Epoch: 45===\n",
      "batch = 0, mean loss = 0.9013751745223999\n",
      "batch = 1, mean loss = 0.9013751745223999\n",
      "time per epoch: 0.05023598670959473\n",
      "=== Epoch: 46===\n",
      "batch = 0, mean loss = 0.8980416655540466\n",
      "batch = 1, mean loss = 0.8980416655540466\n",
      "time per epoch: 0.038308143615722656\n",
      "=== Epoch: 47===\n",
      "batch = 0, mean loss = 0.8934108018875122\n",
      "batch = 1, mean loss = 0.8934108018875122\n",
      "time per epoch: 0.03766965866088867\n",
      "=== Epoch: 48===\n",
      "batch = 0, mean loss = 0.8933486938476562\n",
      "batch = 1, mean loss = 0.8933486938476562\n",
      "time per epoch: 0.04387307167053223\n",
      "=== Epoch: 49===\n",
      "batch = 0, mean loss = 0.8910282850265503\n",
      "batch = 1, mean loss = 0.8910282850265503\n",
      "time per epoch: 0.0520017147064209\n",
      "=== Epoch: 50===\n",
      "batch = 0, mean loss = 0.8894766569137573\n",
      "batch = 1, mean loss = 0.8894766569137573\n",
      "time per epoch: 0.04415774345397949\n",
      "=== Epoch: 51===\n",
      "batch = 0, mean loss = 0.8885189890861511\n",
      "batch = 1, mean loss = 0.8885189890861511\n",
      "time per epoch: 0.04801058769226074\n",
      "=== Epoch: 52===\n",
      "batch = 0, mean loss = 0.8875742554664612\n",
      "batch = 1, mean loss = 0.8875742554664612\n",
      "time per epoch: 0.04216146469116211\n",
      "=== Epoch: 53===\n",
      "batch = 0, mean loss = 0.8847557902336121\n",
      "batch = 1, mean loss = 0.8847557902336121\n",
      "time per epoch: 0.04001426696777344\n",
      "=== Epoch: 54===\n",
      "batch = 0, mean loss = 0.8835465908050537\n",
      "batch = 1, mean loss = 0.8835465908050537\n",
      "time per epoch: 0.04725003242492676\n",
      "=== Epoch: 55===\n",
      "batch = 0, mean loss = 0.882074773311615\n",
      "batch = 1, mean loss = 0.882074773311615\n",
      "time per epoch: 0.05003690719604492\n",
      "=== Epoch: 56===\n",
      "batch = 0, mean loss = 0.8807804584503174\n",
      "batch = 1, mean loss = 0.8807804584503174\n",
      "time per epoch: 0.04500007629394531\n",
      "=== Epoch: 57===\n",
      "batch = 0, mean loss = 0.8811064958572388\n",
      "batch = 1, mean loss = 0.8811064958572388\n",
      "time per epoch: 0.04735422134399414\n",
      "=== Epoch: 58===\n",
      "batch = 0, mean loss = 0.883590042591095\n",
      "batch = 1, mean loss = 0.883590042591095\n",
      "time per epoch: 0.04420661926269531\n",
      "=== Epoch: 59===\n",
      "batch = 0, mean loss = 0.8786957859992981\n",
      "batch = 1, mean loss = 0.8786957859992981\n",
      "time per epoch: 0.04408407211303711\n",
      "=== Epoch: 60===\n",
      "batch = 0, mean loss = 0.887168288230896\n",
      "batch = 1, mean loss = 0.887168288230896\n",
      "time per epoch: 0.05099773406982422\n",
      "=== Epoch: 61===\n",
      "batch = 0, mean loss = 0.8783314228057861\n",
      "batch = 1, mean loss = 0.8783314228057861\n",
      "time per epoch: 0.05204319953918457\n",
      "=== Epoch: 62===\n",
      "batch = 0, mean loss = 0.8742237687110901\n",
      "batch = 1, mean loss = 0.8742237687110901\n",
      "time per epoch: 0.04712224006652832\n",
      "=== Epoch: 63===\n",
      "batch = 0, mean loss = 0.8733651638031006\n",
      "batch = 1, mean loss = 0.8733651638031006\n",
      "time per epoch: 0.048012733459472656\n",
      "=== Epoch: 64===\n",
      "batch = 0, mean loss = 0.8719860315322876\n",
      "batch = 1, mean loss = 0.8719860315322876\n",
      "time per epoch: 0.05200052261352539\n",
      "=== Epoch: 65===\n",
      "batch = 0, mean loss = 0.870689332485199\n",
      "batch = 1, mean loss = 0.870689332485199\n",
      "time per epoch: 0.05502820014953613\n",
      "=== Epoch: 66===\n",
      "batch = 0, mean loss = 0.8687907457351685\n",
      "batch = 1, mean loss = 0.8687907457351685\n",
      "time per epoch: 0.056079864501953125\n",
      "=== Epoch: 67===\n",
      "batch = 0, mean loss = 0.8712871670722961\n",
      "batch = 1, mean loss = 0.8712871670722961\n",
      "time per epoch: 0.060861825942993164\n",
      "=== Epoch: 68===\n",
      "batch = 0, mean loss = 0.8711298704147339\n",
      "batch = 1, mean loss = 0.8711298704147339\n",
      "time per epoch: 0.0530850887298584\n",
      "=== Epoch: 69===\n",
      "batch = 0, mean loss = 0.8681461811065674\n",
      "batch = 1, mean loss = 0.8681461811065674\n",
      "time per epoch: 0.05812430381774902\n",
      "=== Epoch: 70===\n",
      "batch = 0, mean loss = 0.8651242256164551\n",
      "batch = 1, mean loss = 0.8651242256164551\n",
      "time per epoch: 0.06401300430297852\n",
      "=== Epoch: 71===\n",
      "batch = 0, mean loss = 0.865578293800354\n",
      "batch = 1, mean loss = 0.865578293800354\n",
      "time per epoch: 0.05470871925354004\n",
      "=== Epoch: 72===\n",
      "batch = 0, mean loss = 0.8631151914596558\n",
      "batch = 1, mean loss = 0.8631151914596558\n",
      "time per epoch: 0.0547947883605957\n",
      "=== Epoch: 73===\n",
      "batch = 0, mean loss = 0.8612769842147827\n",
      "batch = 1, mean loss = 0.8612769842147827\n",
      "time per epoch: 0.047688961029052734\n",
      "=== Epoch: 74===\n",
      "batch = 0, mean loss = 0.8596022725105286\n",
      "batch = 1, mean loss = 0.8596022725105286\n",
      "time per epoch: 0.05299997329711914\n",
      "=== Epoch: 75===\n",
      "batch = 0, mean loss = 0.8588292598724365\n",
      "batch = 1, mean loss = 0.8588292598724365\n",
      "time per epoch: 0.055565595626831055\n",
      "=== Epoch: 76===\n",
      "batch = 0, mean loss = 0.8573156595230103\n",
      "batch = 1, mean loss = 0.8573156595230103\n",
      "time per epoch: 0.0551455020904541\n",
      "=== Epoch: 77===\n",
      "batch = 0, mean loss = 0.8561119437217712\n",
      "batch = 1, mean loss = 0.8561119437217712\n",
      "time per epoch: 0.06000256538391113\n",
      "=== Epoch: 78===\n",
      "batch = 0, mean loss = 0.8544573187828064\n",
      "batch = 1, mean loss = 0.8544573187828064\n",
      "time per epoch: 0.06064653396606445\n",
      "=== Epoch: 79===\n",
      "batch = 0, mean loss = 0.8533836603164673\n",
      "batch = 1, mean loss = 0.8533836603164673\n",
      "time per epoch: 0.06261873245239258\n",
      "=== Epoch: 80===\n",
      "batch = 0, mean loss = 0.8521085977554321\n",
      "batch = 1, mean loss = 0.8521085977554321\n",
      "time per epoch: 0.0586240291595459\n",
      "=== Epoch: 81===\n",
      "batch = 0, mean loss = 0.8507422208786011\n",
      "batch = 1, mean loss = 0.8507422208786011\n",
      "time per epoch: 0.06502342224121094\n",
      "=== Epoch: 82===\n",
      "batch = 0, mean loss = 0.8496721982955933\n",
      "batch = 1, mean loss = 0.8496721982955933\n",
      "time per epoch: 0.05322098731994629\n",
      "=== Epoch: 83===\n",
      "batch = 0, mean loss = 0.8488049507141113\n",
      "batch = 1, mean loss = 0.8488049507141113\n",
      "time per epoch: 0.059226274490356445\n",
      "=== Epoch: 84===\n",
      "batch = 0, mean loss = 0.8475120067596436\n",
      "batch = 1, mean loss = 0.8475120067596436\n",
      "time per epoch: 0.06800436973571777\n",
      "=== Epoch: 85===\n",
      "batch = 0, mean loss = 0.8460570573806763\n",
      "batch = 1, mean loss = 0.8460570573806763\n",
      "time per epoch: 0.06863069534301758\n",
      "=== Epoch: 86===\n",
      "batch = 0, mean loss = 0.8446791172027588\n",
      "batch = 1, mean loss = 0.8446791172027588\n",
      "time per epoch: 0.06707358360290527\n",
      "=== Epoch: 87===\n",
      "batch = 0, mean loss = 0.8436164855957031\n",
      "batch = 1, mean loss = 0.8436164855957031\n",
      "time per epoch: 0.07711410522460938\n",
      "=== Epoch: 88===\n",
      "batch = 0, mean loss = 0.8427194356918335\n",
      "batch = 1, mean loss = 0.8427194356918335\n",
      "time per epoch: 0.06602263450622559\n",
      "=== Epoch: 89===\n",
      "batch = 0, mean loss = 0.8417537212371826\n",
      "batch = 1, mean loss = 0.8417537212371826\n",
      "time per epoch: 0.055943965911865234\n",
      "=== Epoch: 90===\n",
      "batch = 0, mean loss = 0.8405881524085999\n",
      "batch = 1, mean loss = 0.8405881524085999\n",
      "time per epoch: 0.057129621505737305\n",
      "=== Epoch: 91===\n",
      "batch = 0, mean loss = 0.8396841287612915\n",
      "batch = 1, mean loss = 0.8396841287612915\n",
      "time per epoch: 0.05753469467163086\n",
      "=== Epoch: 92===\n",
      "batch = 0, mean loss = 0.8388302326202393\n",
      "batch = 1, mean loss = 0.8388302326202393\n",
      "time per epoch: 0.05810880661010742\n",
      "=== Epoch: 93===\n",
      "batch = 0, mean loss = 0.8382290601730347\n",
      "batch = 1, mean loss = 0.8382290601730347\n",
      "time per epoch: 0.053057193756103516\n",
      "=== Epoch: 94===\n",
      "batch = 0, mean loss = 0.8368245959281921\n",
      "batch = 1, mean loss = 0.8368245959281921\n",
      "time per epoch: 0.0588529109954834\n",
      "=== Epoch: 95===\n",
      "batch = 0, mean loss = 0.8369032144546509\n",
      "batch = 1, mean loss = 0.8369032144546509\n",
      "time per epoch: 0.05499553680419922\n",
      "=== Epoch: 96===\n",
      "batch = 0, mean loss = 0.835486650466919\n",
      "batch = 1, mean loss = 0.835486650466919\n",
      "time per epoch: 0.06027078628540039\n",
      "=== Epoch: 97===\n",
      "batch = 0, mean loss = 0.8347336649894714\n",
      "batch = 1, mean loss = 0.8347336649894714\n",
      "time per epoch: 0.05917191505432129\n",
      "=== Epoch: 98===\n",
      "batch = 0, mean loss = 0.8342254757881165\n",
      "batch = 1, mean loss = 0.8342254757881165\n",
      "time per epoch: 0.06000089645385742\n",
      "=== Epoch: 99===\n",
      "batch = 0, mean loss = 0.8332431316375732\n",
      "batch = 1, mean loss = 0.8332431316375732\n",
      "time per epoch: 0.05714845657348633\n",
      "=== Epoch: 100===\n",
      "batch = 0, mean loss = 0.8323922753334045\n",
      "batch = 1, mean loss = 0.8323922753334045\n",
      "time per epoch: 0.0615229606628418\n",
      "=== Epoch: 101===\n",
      "batch = 0, mean loss = 0.8323488831520081\n",
      "batch = 1, mean loss = 0.8323488831520081\n",
      "time per epoch: 0.06100201606750488\n",
      "=== Epoch: 102===\n",
      "batch = 0, mean loss = 0.8313353061676025\n",
      "batch = 1, mean loss = 0.8313353061676025\n",
      "time per epoch: 0.06200051307678223\n",
      "=== Epoch: 103===\n",
      "batch = 0, mean loss = 0.8306045532226562\n",
      "batch = 1, mean loss = 0.8306045532226562\n",
      "time per epoch: 0.061511993408203125\n",
      "=== Epoch: 104===\n",
      "batch = 0, mean loss = 0.830350399017334\n",
      "batch = 1, mean loss = 0.830350399017334\n",
      "time per epoch: 0.07318592071533203\n",
      "=== Epoch: 105===\n",
      "batch = 0, mean loss = 0.8364531993865967\n",
      "batch = 1, mean loss = 0.8364531993865967\n",
      "time per epoch: 0.08135819435119629\n",
      "=== Epoch: 106===\n",
      "batch = 0, mean loss = 0.8293403387069702\n",
      "batch = 1, mean loss = 0.8293403387069702\n",
      "time per epoch: 0.06273078918457031\n",
      "=== Epoch: 107===\n",
      "batch = 0, mean loss = 0.829939603805542\n",
      "batch = 1, mean loss = 0.829939603805542\n",
      "time per epoch: 0.06299948692321777\n",
      "=== Epoch: 108===\n",
      "batch = 0, mean loss = 0.8295150995254517\n",
      "batch = 1, mean loss = 0.8295150995254517\n",
      "time per epoch: 0.06728625297546387\n",
      "=== Epoch: 109===\n",
      "batch = 0, mean loss = 0.8276676535606384\n",
      "batch = 1, mean loss = 0.8276676535606384\n",
      "time per epoch: 0.068023681640625\n",
      "=== Epoch: 110===\n",
      "batch = 0, mean loss = 0.8265990018844604\n",
      "batch = 1, mean loss = 0.8265990018844604\n",
      "time per epoch: 0.060021400451660156\n",
      "=== Epoch: 111===\n",
      "batch = 0, mean loss = 0.8255318403244019\n",
      "batch = 1, mean loss = 0.8255318403244019\n",
      "time per epoch: 0.06998968124389648\n",
      "=== Epoch: 112===\n",
      "batch = 0, mean loss = 0.8252931237220764\n",
      "batch = 1, mean loss = 0.8252931237220764\n",
      "time per epoch: 0.06600117683410645\n",
      "=== Epoch: 113===\n",
      "batch = 0, mean loss = 0.8256125450134277\n",
      "batch = 1, mean loss = 0.8256125450134277\n",
      "time per epoch: 0.0599973201751709\n",
      "=== Epoch: 114===\n",
      "batch = 0, mean loss = 0.8246808052062988\n",
      "batch = 1, mean loss = 0.8246808052062988\n",
      "time per epoch: 0.07958006858825684\n",
      "=== Epoch: 115===\n",
      "batch = 0, mean loss = 0.8235117197036743\n",
      "batch = 1, mean loss = 0.8235117197036743\n",
      "time per epoch: 0.06899833679199219\n",
      "=== Epoch: 116===\n",
      "batch = 0, mean loss = 0.8226568698883057\n",
      "batch = 1, mean loss = 0.8226568698883057\n",
      "time per epoch: 0.07102036476135254\n",
      "=== Epoch: 117===\n",
      "batch = 0, mean loss = 0.823564887046814\n",
      "batch = 1, mean loss = 0.823564887046814\n",
      "time per epoch: 0.06998729705810547\n",
      "=== Epoch: 118===\n",
      "batch = 0, mean loss = 0.8266244530677795\n",
      "batch = 1, mean loss = 0.8266244530677795\n",
      "time per epoch: 0.08699440956115723\n",
      "=== Epoch: 119===\n",
      "batch = 0, mean loss = 0.8223962187767029\n",
      "batch = 1, mean loss = 0.8223962187767029\n",
      "time per epoch: 0.06805038452148438\n",
      "=== Epoch: 120===\n",
      "batch = 0, mean loss = 0.8238710761070251\n",
      "batch = 1, mean loss = 0.8238710761070251\n",
      "time per epoch: 0.06699824333190918\n",
      "=== Epoch: 121===\n",
      "batch = 0, mean loss = 0.8262375593185425\n",
      "batch = 1, mean loss = 0.8262375593185425\n",
      "time per epoch: 0.06399965286254883\n",
      "=== Epoch: 122===\n",
      "batch = 0, mean loss = 0.8212209939956665\n",
      "batch = 1, mean loss = 0.8212209939956665\n",
      "time per epoch: 0.06500244140625\n",
      "=== Epoch: 123===\n",
      "batch = 0, mean loss = 0.8222847580909729\n",
      "batch = 1, mean loss = 0.8222847580909729\n",
      "time per epoch: 0.0689995288848877\n",
      "=== Epoch: 124===\n",
      "batch = 0, mean loss = 0.8246870040893555\n",
      "batch = 1, mean loss = 0.8246870040893555\n",
      "time per epoch: 0.058998823165893555\n",
      "=== Epoch: 125===\n",
      "batch = 0, mean loss = 0.8199245929718018\n",
      "batch = 1, mean loss = 0.8199245929718018\n",
      "time per epoch: 0.0676426887512207\n",
      "=== Epoch: 126===\n",
      "batch = 0, mean loss = 0.8194960355758667\n",
      "batch = 1, mean loss = 0.8194960355758667\n",
      "time per epoch: 0.06503939628601074\n",
      "=== Epoch: 127===\n",
      "batch = 0, mean loss = 0.8189696669578552\n",
      "batch = 1, mean loss = 0.8189696669578552\n",
      "time per epoch: 0.0661768913269043\n",
      "=== Epoch: 128===\n",
      "batch = 0, mean loss = 0.8184666037559509\n",
      "batch = 1, mean loss = 0.8184666037559509\n",
      "time per epoch: 0.07510757446289062\n",
      "=== Epoch: 129===\n",
      "batch = 0, mean loss = 0.8178004622459412\n",
      "batch = 1, mean loss = 0.8178004622459412\n",
      "time per epoch: 0.06501412391662598\n",
      "=== Epoch: 130===\n",
      "batch = 0, mean loss = 0.817013680934906\n",
      "batch = 1, mean loss = 0.817013680934906\n",
      "time per epoch: 0.061083078384399414\n",
      "=== Epoch: 131===\n",
      "batch = 0, mean loss = 0.8162447214126587\n",
      "batch = 1, mean loss = 0.8162447214126587\n",
      "time per epoch: 0.06093478202819824\n",
      "=== Epoch: 132===\n",
      "batch = 0, mean loss = 0.8153131604194641\n",
      "batch = 1, mean loss = 0.8153131604194641\n",
      "time per epoch: 0.06099987030029297\n",
      "=== Epoch: 133===\n",
      "batch = 0, mean loss = 0.8145460486412048\n",
      "batch = 1, mean loss = 0.8145460486412048\n",
      "time per epoch: 0.07590198516845703\n",
      "=== Epoch: 134===\n",
      "batch = 0, mean loss = 0.8136096000671387\n",
      "batch = 1, mean loss = 0.8136096000671387\n",
      "time per epoch: 0.06098628044128418\n",
      "=== Epoch: 135===\n",
      "batch = 0, mean loss = 0.8129502534866333\n",
      "batch = 1, mean loss = 0.8129502534866333\n",
      "time per epoch: 0.058001041412353516\n",
      "=== Epoch: 136===\n",
      "batch = 0, mean loss = 0.8121907114982605\n",
      "batch = 1, mean loss = 0.8121907114982605\n",
      "time per epoch: 0.061638593673706055\n",
      "=== Epoch: 137===\n",
      "batch = 0, mean loss = 0.8115901947021484\n",
      "batch = 1, mean loss = 0.8115901947021484\n",
      "time per epoch: 0.058017730712890625\n",
      "=== Epoch: 138===\n",
      "batch = 0, mean loss = 0.8106469511985779\n",
      "batch = 1, mean loss = 0.8106469511985779\n",
      "time per epoch: 0.057898521423339844\n",
      "=== Epoch: 139===\n",
      "batch = 0, mean loss = 0.810020387172699\n",
      "batch = 1, mean loss = 0.810020387172699\n",
      "time per epoch: 0.05910849571228027\n",
      "=== Epoch: 140===\n",
      "batch = 0, mean loss = 0.8093251585960388\n",
      "batch = 1, mean loss = 0.8093251585960388\n",
      "time per epoch: 0.07115793228149414\n",
      "=== Epoch: 141===\n",
      "batch = 0, mean loss = 0.8086299300193787\n",
      "batch = 1, mean loss = 0.8086299300193787\n",
      "time per epoch: 0.06800007820129395\n",
      "=== Epoch: 142===\n",
      "batch = 0, mean loss = 0.8081866502761841\n",
      "batch = 1, mean loss = 0.8081866502761841\n",
      "time per epoch: 0.06481337547302246\n",
      "=== Epoch: 143===\n",
      "batch = 0, mean loss = 0.8075987696647644\n",
      "batch = 1, mean loss = 0.8075987696647644\n",
      "time per epoch: 0.06479072570800781\n",
      "=== Epoch: 144===\n",
      "batch = 0, mean loss = 0.8072169423103333\n",
      "batch = 1, mean loss = 0.8072169423103333\n",
      "time per epoch: 0.05102348327636719\n",
      "=== Epoch: 145===\n",
      "batch = 0, mean loss = 0.8068093061447144\n",
      "batch = 1, mean loss = 0.8068093061447144\n",
      "time per epoch: 0.054126739501953125\n",
      "=== Epoch: 146===\n",
      "batch = 0, mean loss = 0.8065781593322754\n",
      "batch = 1, mean loss = 0.8065781593322754\n",
      "time per epoch: 0.0598447322845459\n",
      "=== Epoch: 147===\n",
      "batch = 0, mean loss = 0.8062161207199097\n",
      "batch = 1, mean loss = 0.8062161207199097\n",
      "time per epoch: 0.05649423599243164\n",
      "=== Epoch: 148===\n",
      "batch = 0, mean loss = 0.8058203458786011\n",
      "batch = 1, mean loss = 0.8058203458786011\n",
      "time per epoch: 0.060001373291015625\n",
      "=== Epoch: 149===\n",
      "batch = 0, mean loss = 0.8055261373519897\n",
      "batch = 1, mean loss = 0.8055261373519897\n",
      "time per epoch: 0.06066298484802246\n",
      "=== Epoch: 150===\n",
      "batch = 0, mean loss = 0.8068108558654785\n",
      "batch = 1, mean loss = 0.8068108558654785\n",
      "time per epoch: 0.0631263256072998\n",
      "=== Epoch: 151===\n",
      "batch = 0, mean loss = 0.8061844706535339\n",
      "batch = 1, mean loss = 0.8061844706535339\n",
      "time per epoch: 0.05600094795227051\n",
      "=== Epoch: 152===\n",
      "batch = 0, mean loss = 0.804861843585968\n",
      "batch = 1, mean loss = 0.804861843585968\n",
      "time per epoch: 0.06827163696289062\n",
      "=== Epoch: 153===\n",
      "batch = 0, mean loss = 0.8045738935470581\n",
      "batch = 1, mean loss = 0.8045738935470581\n",
      "time per epoch: 0.07221770286560059\n",
      "=== Epoch: 154===\n",
      "batch = 0, mean loss = 0.8039831519126892\n",
      "batch = 1, mean loss = 0.8039831519126892\n",
      "time per epoch: 0.07599949836730957\n",
      "=== Epoch: 155===\n",
      "batch = 0, mean loss = 0.8032575845718384\n",
      "batch = 1, mean loss = 0.8032575845718384\n",
      "time per epoch: 0.07159638404846191\n",
      "=== Epoch: 156===\n",
      "batch = 0, mean loss = 0.8029013872146606\n",
      "batch = 1, mean loss = 0.8029013872146606\n",
      "time per epoch: 0.061469078063964844\n",
      "=== Epoch: 157===\n",
      "batch = 0, mean loss = 0.8031322956085205\n",
      "batch = 1, mean loss = 0.8031322956085205\n",
      "time per epoch: 0.06066393852233887\n",
      "=== Epoch: 158===\n",
      "batch = 0, mean loss = 0.8035769462585449\n",
      "batch = 1, mean loss = 0.8035769462585449\n",
      "time per epoch: 0.05758261680603027\n",
      "=== Epoch: 159===\n",
      "batch = 0, mean loss = 0.8033320903778076\n",
      "batch = 1, mean loss = 0.8033320903778076\n",
      "time per epoch: 0.056566715240478516\n",
      "=== Epoch: 160===\n",
      "batch = 0, mean loss = 0.8025151491165161\n",
      "batch = 1, mean loss = 0.8025151491165161\n",
      "time per epoch: 0.05640530586242676\n",
      "=== Epoch: 161===\n",
      "batch = 0, mean loss = 0.8018205761909485\n",
      "batch = 1, mean loss = 0.8018205761909485\n",
      "time per epoch: 0.053282737731933594\n",
      "=== Epoch: 162===\n",
      "batch = 0, mean loss = 0.8016070127487183\n",
      "batch = 1, mean loss = 0.8016070127487183\n",
      "time per epoch: 0.04399847984313965\n",
      "=== Epoch: 163===\n",
      "batch = 0, mean loss = 0.8013368844985962\n",
      "batch = 1, mean loss = 0.8013368844985962\n",
      "time per epoch: 0.05724167823791504\n",
      "=== Epoch: 164===\n",
      "batch = 0, mean loss = 0.8009341359138489\n",
      "batch = 1, mean loss = 0.8009341359138489\n",
      "time per epoch: 0.05336642265319824\n",
      "=== Epoch: 165===\n",
      "batch = 0, mean loss = 0.8004708290100098\n",
      "batch = 1, mean loss = 0.8004708290100098\n",
      "time per epoch: 0.05588865280151367\n",
      "=== Epoch: 166===\n",
      "batch = 0, mean loss = 0.800017774105072\n",
      "batch = 1, mean loss = 0.800017774105072\n",
      "time per epoch: 0.06055283546447754\n",
      "=== Epoch: 167===\n",
      "batch = 0, mean loss = 0.7997493743896484\n",
      "batch = 1, mean loss = 0.7997493743896484\n",
      "time per epoch: 0.05386495590209961\n",
      "=== Epoch: 168===\n",
      "batch = 0, mean loss = 0.8053288459777832\n",
      "batch = 1, mean loss = 0.8053288459777832\n",
      "time per epoch: 0.05462312698364258\n",
      "=== Epoch: 169===\n",
      "batch = 0, mean loss = 0.7996135354042053\n",
      "batch = 1, mean loss = 0.7996135354042053\n",
      "time per epoch: 0.05608510971069336\n",
      "=== Epoch: 170===\n",
      "batch = 0, mean loss = 0.7994458079338074\n",
      "batch = 1, mean loss = 0.7994458079338074\n",
      "time per epoch: 0.05997014045715332\n",
      "=== Epoch: 171===\n",
      "batch = 0, mean loss = 0.7995100021362305\n",
      "batch = 1, mean loss = 0.7995100021362305\n",
      "time per epoch: 0.05864596366882324\n",
      "=== Epoch: 172===\n",
      "batch = 0, mean loss = 0.7992520928382874\n",
      "batch = 1, mean loss = 0.7992520928382874\n",
      "time per epoch: 0.05835437774658203\n",
      "=== Epoch: 173===\n",
      "batch = 0, mean loss = 0.7989877462387085\n",
      "batch = 1, mean loss = 0.7989877462387085\n",
      "time per epoch: 0.058630943298339844\n",
      "=== Epoch: 174===\n",
      "batch = 0, mean loss = 0.7990564703941345\n",
      "batch = 1, mean loss = 0.7990564703941345\n",
      "time per epoch: 0.05547642707824707\n",
      "=== Epoch: 175===\n",
      "batch = 0, mean loss = 0.7989402413368225\n",
      "batch = 1, mean loss = 0.7989402413368225\n",
      "time per epoch: 0.05923008918762207\n",
      "=== Epoch: 176===\n",
      "batch = 0, mean loss = 0.7986606359481812\n",
      "batch = 1, mean loss = 0.7986606359481812\n",
      "time per epoch: 0.05645298957824707\n",
      "=== Epoch: 177===\n",
      "batch = 0, mean loss = 0.7983279228210449\n",
      "batch = 1, mean loss = 0.7983279228210449\n",
      "time per epoch: 0.055506229400634766\n",
      "=== Epoch: 178===\n",
      "batch = 0, mean loss = 0.7982386946678162\n",
      "batch = 1, mean loss = 0.7982386946678162\n",
      "time per epoch: 0.053923606872558594\n",
      "=== Epoch: 179===\n",
      "batch = 0, mean loss = 0.8004447817802429\n",
      "batch = 1, mean loss = 0.8004447817802429\n",
      "time per epoch: 0.05489349365234375\n",
      "=== Epoch: 180===\n",
      "batch = 0, mean loss = 0.8008021116256714\n",
      "batch = 1, mean loss = 0.8008021116256714\n",
      "time per epoch: 0.05355072021484375\n",
      "=== Epoch: 181===\n",
      "batch = 0, mean loss = 0.7981530427932739\n",
      "batch = 1, mean loss = 0.7981530427932739\n",
      "time per epoch: 0.056311845779418945\n",
      "=== Epoch: 182===\n",
      "batch = 0, mean loss = 0.7991946935653687\n",
      "batch = 1, mean loss = 0.7991946935653687\n",
      "time per epoch: 0.05925703048706055\n",
      "=== Epoch: 183===\n",
      "batch = 0, mean loss = 0.7994445562362671\n",
      "batch = 1, mean loss = 0.7994445562362671\n",
      "time per epoch: 0.061756134033203125\n",
      "=== Epoch: 184===\n",
      "batch = 0, mean loss = 0.8000166416168213\n",
      "batch = 1, mean loss = 0.8000166416168213\n",
      "time per epoch: 0.06501269340515137\n",
      "=== Epoch: 185===\n",
      "batch = 0, mean loss = 0.8002035617828369\n",
      "batch = 1, mean loss = 0.8002035617828369\n",
      "time per epoch: 0.060276031494140625\n",
      "=== Epoch: 186===\n",
      "batch = 0, mean loss = 0.7998273372650146\n",
      "batch = 1, mean loss = 0.7998273372650146\n",
      "time per epoch: 0.05910158157348633\n",
      "=== Epoch: 187===\n",
      "batch = 0, mean loss = 0.7995491623878479\n",
      "batch = 1, mean loss = 0.7995491623878479\n",
      "time per epoch: 0.051854610443115234\n",
      "=== Epoch: 188===\n",
      "batch = 0, mean loss = 0.7989016175270081\n",
      "batch = 1, mean loss = 0.7989016175270081\n",
      "time per epoch: 0.051242828369140625\n",
      "=== Epoch: 189===\n",
      "batch = 0, mean loss = 0.7984312772750854\n",
      "batch = 1, mean loss = 0.7984312772750854\n",
      "time per epoch: 0.05269646644592285\n",
      "=== Epoch: 190===\n",
      "batch = 0, mean loss = 0.7979905605316162\n",
      "batch = 1, mean loss = 0.7979905605316162\n",
      "time per epoch: 0.05153298377990723\n",
      "=== Epoch: 191===\n",
      "batch = 0, mean loss = 0.7973977327346802\n",
      "batch = 1, mean loss = 0.7973977327346802\n",
      "time per epoch: 0.06095623970031738\n",
      "=== Epoch: 192===\n",
      "batch = 0, mean loss = 0.7971813678741455\n",
      "batch = 1, mean loss = 0.7971813678741455\n",
      "time per epoch: 0.04915165901184082\n",
      "=== Epoch: 193===\n",
      "batch = 0, mean loss = 0.8012847900390625\n",
      "batch = 1, mean loss = 0.8012847900390625\n",
      "time per epoch: 0.046999216079711914\n",
      "=== Epoch: 194===\n",
      "batch = 0, mean loss = 0.799476683139801\n",
      "batch = 1, mean loss = 0.799476683139801\n",
      "time per epoch: 0.04684114456176758\n",
      "=== Epoch: 195===\n",
      "batch = 0, mean loss = 0.7971360683441162\n",
      "batch = 1, mean loss = 0.7971360683441162\n",
      "time per epoch: 0.04764199256896973\n",
      "=== Epoch: 196===\n",
      "batch = 0, mean loss = 0.7988839149475098\n",
      "batch = 1, mean loss = 0.7988839149475098\n",
      "time per epoch: 0.06023740768432617\n",
      "=== Epoch: 197===\n",
      "batch = 0, mean loss = 0.797195315361023\n",
      "batch = 1, mean loss = 0.797195315361023\n",
      "time per epoch: 0.07954835891723633\n",
      "=== Epoch: 198===\n",
      "batch = 0, mean loss = 0.7986880540847778\n",
      "batch = 1, mean loss = 0.7986880540847778\n",
      "time per epoch: 0.050780296325683594\n",
      "=== Epoch: 199===\n",
      "batch = 0, mean loss = 0.796986997127533\n",
      "batch = 1, mean loss = 0.796986997127533\n",
      "time per epoch: 0.05591082572937012\n",
      "=== Epoch: 200===\n",
      "batch = 0, mean loss = 0.7981687188148499\n",
      "batch = 1, mean loss = 0.7981687188148499\n",
      "time per epoch: 0.05375862121582031\n",
      "=== Epoch: 201===\n",
      "batch = 0, mean loss = 0.7979707717895508\n",
      "batch = 1, mean loss = 0.7979707717895508\n",
      "time per epoch: 0.049334049224853516\n",
      "=== Epoch: 202===\n",
      "batch = 0, mean loss = 0.7976137399673462\n",
      "batch = 1, mean loss = 0.7976137399673462\n",
      "time per epoch: 0.05080270767211914\n",
      "=== Epoch: 203===\n",
      "batch = 0, mean loss = 0.7971384525299072\n",
      "batch = 1, mean loss = 0.7971384525299072\n",
      "time per epoch: 0.04851794242858887\n",
      "=== Epoch: 204===\n",
      "batch = 0, mean loss = 0.7982574105262756\n",
      "batch = 1, mean loss = 0.7982574105262756\n",
      "time per epoch: 0.05211472511291504\n",
      "=== Epoch: 205===\n",
      "batch = 0, mean loss = 0.7981222867965698\n",
      "batch = 1, mean loss = 0.7981222867965698\n",
      "time per epoch: 0.054997920989990234\n",
      "=== Epoch: 206===\n",
      "batch = 0, mean loss = 0.7980944514274597\n",
      "batch = 1, mean loss = 0.7980944514274597\n",
      "time per epoch: 0.04849362373352051\n",
      "=== Epoch: 207===\n",
      "batch = 0, mean loss = 0.796751856803894\n",
      "batch = 1, mean loss = 0.796751856803894\n",
      "time per epoch: 0.04199957847595215\n",
      "=== Epoch: 208===\n",
      "batch = 0, mean loss = 0.797418475151062\n",
      "batch = 1, mean loss = 0.797418475151062\n",
      "time per epoch: 0.042000770568847656\n",
      "=== Epoch: 209===\n",
      "batch = 0, mean loss = 0.7972517013549805\n",
      "batch = 1, mean loss = 0.7972517013549805\n",
      "time per epoch: 0.051421403884887695\n",
      "=== Epoch: 210===\n",
      "batch = 0, mean loss = 0.7966083288192749\n",
      "batch = 1, mean loss = 0.7966083288192749\n",
      "time per epoch: 0.043000221252441406\n",
      "=== Epoch: 211===\n",
      "batch = 0, mean loss = 0.7965553998947144\n",
      "batch = 1, mean loss = 0.7965553998947144\n",
      "time per epoch: 0.04030442237854004\n",
      "=== Epoch: 212===\n",
      "batch = 0, mean loss = 0.7978020906448364\n",
      "batch = 1, mean loss = 0.7978020906448364\n",
      "time per epoch: 0.04904913902282715\n",
      "=== Epoch: 213===\n",
      "batch = 0, mean loss = 0.7979266047477722\n",
      "batch = 1, mean loss = 0.7979266047477722\n",
      "time per epoch: 0.05107617378234863\n",
      "=== Epoch: 214===\n",
      "batch = 0, mean loss = 0.7972590327262878\n",
      "batch = 1, mean loss = 0.7972590327262878\n",
      "time per epoch: 0.05151486396789551\n",
      "=== Epoch: 215===\n",
      "batch = 0, mean loss = 0.7967632412910461\n",
      "batch = 1, mean loss = 0.7967632412910461\n",
      "time per epoch: 0.05100059509277344\n",
      "=== Epoch: 216===\n",
      "batch = 0, mean loss = 0.7963509559631348\n",
      "batch = 1, mean loss = 0.7963509559631348\n",
      "time per epoch: 0.0508115291595459\n",
      "=== Epoch: 217===\n",
      "batch = 0, mean loss = 0.7958337664604187\n",
      "batch = 1, mean loss = 0.7958337664604187\n",
      "time per epoch: 0.04754161834716797\n",
      "=== Epoch: 218===\n",
      "batch = 0, mean loss = 0.7955851554870605\n",
      "batch = 1, mean loss = 0.7955851554870605\n",
      "time per epoch: 0.04799795150756836\n",
      "=== Epoch: 219===\n",
      "batch = 0, mean loss = 0.7961935997009277\n",
      "batch = 1, mean loss = 0.7961935997009277\n",
      "time per epoch: 0.050438880920410156\n",
      "=== Epoch: 220===\n",
      "batch = 0, mean loss = 0.7979205846786499\n",
      "batch = 1, mean loss = 0.7979205846786499\n",
      "time per epoch: 0.045360565185546875\n",
      "=== Epoch: 221===\n",
      "batch = 0, mean loss = 0.7988924384117126\n",
      "batch = 1, mean loss = 0.7988924384117126\n",
      "time per epoch: 0.05254411697387695\n",
      "=== Epoch: 222===\n",
      "batch = 0, mean loss = 0.7990701794624329\n",
      "batch = 1, mean loss = 0.7990701794624329\n",
      "time per epoch: 0.04600024223327637\n",
      "=== Epoch: 223===\n",
      "batch = 0, mean loss = 0.7993144989013672\n",
      "batch = 1, mean loss = 0.7993144989013672\n",
      "time per epoch: 0.052011966705322266\n",
      "=== Epoch: 224===\n",
      "batch = 0, mean loss = 0.7990249395370483\n",
      "batch = 1, mean loss = 0.7990249395370483\n",
      "time per epoch: 0.04088592529296875\n",
      "=== Epoch: 225===\n",
      "batch = 0, mean loss = 0.7987371683120728\n",
      "batch = 1, mean loss = 0.7987371683120728\n",
      "time per epoch: 0.04699897766113281\n",
      "=== Epoch: 226===\n",
      "batch = 0, mean loss = 0.7985096573829651\n",
      "batch = 1, mean loss = 0.7985096573829651\n",
      "time per epoch: 0.04481220245361328\n",
      "=== Epoch: 227===\n",
      "batch = 0, mean loss = 0.7982645630836487\n",
      "batch = 1, mean loss = 0.7982645630836487\n",
      "time per epoch: 0.04400992393493652\n",
      "=== Epoch: 228===\n",
      "batch = 0, mean loss = 0.7980189323425293\n",
      "batch = 1, mean loss = 0.7980189323425293\n",
      "time per epoch: 0.053011417388916016\n",
      "=== Epoch: 229===\n",
      "batch = 0, mean loss = 0.7977386116981506\n",
      "batch = 1, mean loss = 0.7977386116981506\n",
      "time per epoch: 0.050000667572021484\n",
      "=== Epoch: 230===\n",
      "batch = 0, mean loss = 0.7974814772605896\n",
      "batch = 1, mean loss = 0.7974814772605896\n",
      "time per epoch: 0.048055171966552734\n",
      "=== Epoch: 231===\n",
      "batch = 0, mean loss = 0.7970632314682007\n",
      "batch = 1, mean loss = 0.7970632314682007\n",
      "time per epoch: 0.04399871826171875\n",
      "=== Epoch: 232===\n",
      "batch = 0, mean loss = 0.7969272136688232\n",
      "batch = 1, mean loss = 0.7969272136688232\n",
      "time per epoch: 0.04699993133544922\n",
      "=== Epoch: 233===\n",
      "batch = 0, mean loss = 0.7965699434280396\n",
      "batch = 1, mean loss = 0.7965699434280396\n",
      "time per epoch: 0.05339646339416504\n",
      "=== Epoch: 234===\n",
      "batch = 0, mean loss = 0.7966392040252686\n",
      "batch = 1, mean loss = 0.7966392040252686\n",
      "time per epoch: 0.04498410224914551\n",
      "=== Epoch: 235===\n",
      "batch = 0, mean loss = 0.796660840511322\n",
      "batch = 1, mean loss = 0.796660840511322\n",
      "time per epoch: 0.049916744232177734\n",
      "=== Epoch: 236===\n",
      "batch = 0, mean loss = 0.7967243790626526\n",
      "batch = 1, mean loss = 0.7967243790626526\n",
      "time per epoch: 0.04900717735290527\n",
      "=== Epoch: 237===\n",
      "batch = 0, mean loss = 0.7964227795600891\n",
      "batch = 1, mean loss = 0.7964227795600891\n",
      "time per epoch: 0.04698514938354492\n",
      "=== Epoch: 238===\n",
      "batch = 0, mean loss = 0.7959511280059814\n",
      "batch = 1, mean loss = 0.7959511280059814\n",
      "time per epoch: 0.05053234100341797\n",
      "=== Epoch: 239===\n",
      "batch = 0, mean loss = 0.7955629825592041\n",
      "batch = 1, mean loss = 0.7955629825592041\n",
      "time per epoch: 0.05082082748413086\n",
      "=== Epoch: 240===\n",
      "batch = 0, mean loss = 0.7956204414367676\n",
      "batch = 1, mean loss = 0.7956204414367676\n",
      "time per epoch: 0.05199861526489258\n",
      "=== Epoch: 241===\n",
      "batch = 0, mean loss = 0.7986862063407898\n",
      "batch = 1, mean loss = 0.7986862063407898\n",
      "time per epoch: 0.045343637466430664\n",
      "=== Epoch: 242===\n",
      "batch = 0, mean loss = 0.7953426837921143\n",
      "batch = 1, mean loss = 0.7953426837921143\n",
      "time per epoch: 0.04788517951965332\n",
      "=== Epoch: 243===\n",
      "batch = 0, mean loss = 0.7957206964492798\n",
      "batch = 1, mean loss = 0.7957206964492798\n",
      "time per epoch: 0.04054427146911621\n",
      "=== Epoch: 244===\n",
      "batch = 0, mean loss = 0.7953916192054749\n",
      "batch = 1, mean loss = 0.7953916192054749\n",
      "time per epoch: 0.0560002326965332\n",
      "=== Epoch: 245===\n",
      "batch = 0, mean loss = 0.7956001162528992\n",
      "batch = 1, mean loss = 0.7956001162528992\n",
      "time per epoch: 0.05536985397338867\n",
      "=== Epoch: 246===\n",
      "batch = 0, mean loss = 0.7956193685531616\n",
      "batch = 1, mean loss = 0.7956193685531616\n",
      "time per epoch: 0.043900489807128906\n",
      "=== Epoch: 247===\n",
      "batch = 0, mean loss = 0.7957092523574829\n",
      "batch = 1, mean loss = 0.7957092523574829\n",
      "time per epoch: 0.053012847900390625\n",
      "=== Epoch: 248===\n",
      "batch = 0, mean loss = 0.7955992817878723\n",
      "batch = 1, mean loss = 0.7955992817878723\n",
      "time per epoch: 0.041257619857788086\n",
      "=== Epoch: 249===\n",
      "batch = 0, mean loss = 0.7953284978866577\n",
      "batch = 1, mean loss = 0.7953284978866577\n",
      "time per epoch: 0.054479122161865234\n",
      "=== Epoch: 250===\n",
      "batch = 0, mean loss = 0.7951213717460632\n",
      "batch = 1, mean loss = 0.7951213717460632\n",
      "time per epoch: 0.0610194206237793\n",
      "=== Epoch: 251===\n",
      "batch = 0, mean loss = 0.7950681447982788\n",
      "batch = 1, mean loss = 0.7950681447982788\n",
      "time per epoch: 0.052999019622802734\n",
      "=== Epoch: 252===\n",
      "batch = 0, mean loss = 0.7989040613174438\n",
      "batch = 1, mean loss = 0.7989040613174438\n",
      "time per epoch: 0.06201505661010742\n",
      "=== Epoch: 253===\n",
      "batch = 0, mean loss = 0.7949865460395813\n",
      "batch = 1, mean loss = 0.7949865460395813\n",
      "time per epoch: 0.06201481819152832\n",
      "=== Epoch: 254===\n",
      "batch = 0, mean loss = 0.7955267429351807\n",
      "batch = 1, mean loss = 0.7955267429351807\n",
      "time per epoch: 0.06299972534179688\n",
      "=== Epoch: 255===\n",
      "batch = 0, mean loss = 0.795498788356781\n",
      "batch = 1, mean loss = 0.795498788356781\n",
      "time per epoch: 0.060027122497558594\n",
      "=== Epoch: 256===\n",
      "batch = 0, mean loss = 0.7951565980911255\n",
      "batch = 1, mean loss = 0.7951565980911255\n",
      "time per epoch: 0.050516366958618164\n",
      "=== Epoch: 257===\n",
      "batch = 0, mean loss = 0.7957789301872253\n",
      "batch = 1, mean loss = 0.7957789301872253\n",
      "time per epoch: 0.05501508712768555\n",
      "=== Epoch: 258===\n",
      "batch = 0, mean loss = 0.7948148250579834\n",
      "batch = 1, mean loss = 0.7948148250579834\n",
      "time per epoch: 0.049892425537109375\n",
      "=== Epoch: 259===\n",
      "batch = 0, mean loss = 0.7956305146217346\n",
      "batch = 1, mean loss = 0.7956305146217346\n",
      "time per epoch: 0.060975074768066406\n",
      "=== Epoch: 260===\n",
      "batch = 0, mean loss = 0.7947279810905457\n",
      "batch = 1, mean loss = 0.7947279810905457\n",
      "time per epoch: 0.05899691581726074\n",
      "=== Epoch: 261===\n",
      "batch = 0, mean loss = 0.7955970764160156\n",
      "batch = 1, mean loss = 0.7955970764160156\n",
      "time per epoch: 0.05211615562438965\n",
      "=== Epoch: 262===\n",
      "batch = 0, mean loss = 0.7949408888816833\n",
      "batch = 1, mean loss = 0.7949408888816833\n",
      "time per epoch: 0.06586480140686035\n",
      "=== Epoch: 263===\n",
      "batch = 0, mean loss = 0.7951653599739075\n",
      "batch = 1, mean loss = 0.7951653599739075\n",
      "time per epoch: 0.05976104736328125\n",
      "=== Epoch: 264===\n",
      "batch = 0, mean loss = 0.7949004173278809\n",
      "batch = 1, mean loss = 0.7949004173278809\n",
      "time per epoch: 0.05699896812438965\n",
      "=== Epoch: 265===\n",
      "batch = 0, mean loss = 0.7948462963104248\n",
      "batch = 1, mean loss = 0.7948462963104248\n",
      "time per epoch: 0.057132720947265625\n",
      "=== Epoch: 266===\n",
      "batch = 0, mean loss = 0.7955304384231567\n",
      "batch = 1, mean loss = 0.7955304384231567\n",
      "time per epoch: 0.05807042121887207\n",
      "=== Epoch: 267===\n",
      "batch = 0, mean loss = 0.7947765588760376\n",
      "batch = 1, mean loss = 0.7947765588760376\n",
      "time per epoch: 0.05429887771606445\n",
      "=== Epoch: 268===\n",
      "batch = 0, mean loss = 0.7954340577125549\n",
      "batch = 1, mean loss = 0.7954340577125549\n",
      "time per epoch: 0.055037498474121094\n",
      "=== Epoch: 269===\n",
      "batch = 0, mean loss = 0.7946557402610779\n",
      "batch = 1, mean loss = 0.7946557402610779\n",
      "time per epoch: 0.05806422233581543\n",
      "=== Epoch: 270===\n",
      "batch = 0, mean loss = 0.7945109605789185\n",
      "batch = 1, mean loss = 0.7945109605789185\n",
      "time per epoch: 0.06299805641174316\n",
      "=== Epoch: 271===\n",
      "batch = 0, mean loss = 0.795987606048584\n",
      "batch = 1, mean loss = 0.795987606048584\n",
      "time per epoch: 0.05501532554626465\n",
      "=== Epoch: 272===\n",
      "batch = 0, mean loss = 0.7945276498794556\n",
      "batch = 1, mean loss = 0.7945276498794556\n",
      "time per epoch: 0.058748483657836914\n",
      "=== Epoch: 273===\n",
      "batch = 0, mean loss = 0.7949318289756775\n",
      "batch = 1, mean loss = 0.7949318289756775\n",
      "time per epoch: 0.061002492904663086\n",
      "=== Epoch: 274===\n",
      "batch = 0, mean loss = 0.794723391532898\n",
      "batch = 1, mean loss = 0.794723391532898\n",
      "time per epoch: 0.048012733459472656\n",
      "=== Epoch: 275===\n",
      "batch = 0, mean loss = 0.795066237449646\n",
      "batch = 1, mean loss = 0.795066237449646\n",
      "time per epoch: 0.05837750434875488\n",
      "=== Epoch: 276===\n",
      "batch = 0, mean loss = 0.7945775389671326\n",
      "batch = 1, mean loss = 0.7945775389671326\n",
      "time per epoch: 0.06000161170959473\n",
      "=== Epoch: 277===\n",
      "batch = 0, mean loss = 0.7948586940765381\n",
      "batch = 1, mean loss = 0.7948586940765381\n",
      "time per epoch: 0.05627608299255371\n",
      "=== Epoch: 278===\n",
      "batch = 0, mean loss = 0.794455349445343\n",
      "batch = 1, mean loss = 0.794455349445343\n",
      "time per epoch: 0.06131291389465332\n",
      "=== Epoch: 279===\n",
      "batch = 0, mean loss = 0.7957174777984619\n",
      "batch = 1, mean loss = 0.7957174777984619\n",
      "time per epoch: 0.05924630165100098\n",
      "=== Epoch: 280===\n",
      "batch = 0, mean loss = 0.7944331169128418\n",
      "batch = 1, mean loss = 0.7944331169128418\n",
      "time per epoch: 0.057498931884765625\n",
      "=== Epoch: 281===\n",
      "batch = 0, mean loss = 0.7949192523956299\n",
      "batch = 1, mean loss = 0.7949192523956299\n",
      "time per epoch: 0.06005859375\n",
      "=== Epoch: 282===\n",
      "batch = 0, mean loss = 0.7945102453231812\n",
      "batch = 1, mean loss = 0.7945102453231812\n",
      "time per epoch: 0.06054949760437012\n",
      "=== Epoch: 283===\n",
      "batch = 0, mean loss = 0.7947074770927429\n",
      "batch = 1, mean loss = 0.7947074770927429\n",
      "time per epoch: 0.049848318099975586\n",
      "=== Epoch: 284===\n",
      "batch = 0, mean loss = 0.7945085167884827\n",
      "batch = 1, mean loss = 0.7945085167884827\n",
      "time per epoch: 0.04646039009094238\n",
      "=== Epoch: 285===\n",
      "batch = 0, mean loss = 0.7945987582206726\n",
      "batch = 1, mean loss = 0.7945987582206726\n",
      "time per epoch: 0.05959153175354004\n",
      "=== Epoch: 286===\n",
      "batch = 0, mean loss = 0.7945255041122437\n",
      "batch = 1, mean loss = 0.7945255041122437\n",
      "time per epoch: 0.06408238410949707\n",
      "=== Epoch: 287===\n",
      "batch = 0, mean loss = 0.7945123314857483\n",
      "batch = 1, mean loss = 0.7945123314857483\n",
      "time per epoch: 0.05288505554199219\n",
      "=== Epoch: 288===\n",
      "batch = 0, mean loss = 0.7945466637611389\n",
      "batch = 1, mean loss = 0.7945466637611389\n",
      "time per epoch: 0.0550684928894043\n",
      "=== Epoch: 289===\n",
      "batch = 0, mean loss = 0.7945558428764343\n",
      "batch = 1, mean loss = 0.7945558428764343\n",
      "time per epoch: 0.05899763107299805\n",
      "=== Epoch: 290===\n",
      "batch = 0, mean loss = 0.7956030368804932\n",
      "batch = 1, mean loss = 0.7956030368804932\n",
      "time per epoch: 0.05400228500366211\n",
      "=== Epoch: 291===\n",
      "batch = 0, mean loss = 0.7976906299591064\n",
      "batch = 1, mean loss = 0.7976906299591064\n",
      "time per epoch: 0.061524391174316406\n",
      "=== Epoch: 292===\n",
      "batch = 0, mean loss = 0.7990079522132874\n",
      "batch = 1, mean loss = 0.7990079522132874\n",
      "time per epoch: 0.06299757957458496\n",
      "=== Epoch: 293===\n",
      "batch = 0, mean loss = 0.8009426593780518\n",
      "batch = 1, mean loss = 0.8009426593780518\n",
      "time per epoch: 0.05982780456542969\n",
      "=== Epoch: 294===\n",
      "batch = 0, mean loss = 0.804044246673584\n",
      "batch = 1, mean loss = 0.804044246673584\n",
      "time per epoch: 0.0599362850189209\n",
      "=== Epoch: 295===\n",
      "batch = 0, mean loss = 0.8064804077148438\n",
      "batch = 1, mean loss = 0.8064804077148438\n",
      "time per epoch: 0.0500032901763916\n",
      "=== Epoch: 296===\n",
      "batch = 0, mean loss = 0.8087899088859558\n",
      "batch = 1, mean loss = 0.8087899088859558\n",
      "time per epoch: 0.05189228057861328\n",
      "=== Epoch: 297===\n",
      "batch = 0, mean loss = 0.8112703561782837\n",
      "batch = 1, mean loss = 0.8112703561782837\n",
      "time per epoch: 0.06747961044311523\n",
      "=== Epoch: 298===\n",
      "batch = 0, mean loss = 0.8127316236495972\n",
      "batch = 1, mean loss = 0.8127316236495972\n",
      "time per epoch: 0.05994153022766113\n",
      "=== Epoch: 299===\n",
      "batch = 0, mean loss = 0.8136508464813232\n",
      "batch = 1, mean loss = 0.8136508464813232\n",
      "time per epoch: 0.05519294738769531\n",
      "=== Epoch: 300===\n",
      "batch = 0, mean loss = 0.8142659664154053\n",
      "batch = 1, mean loss = 0.8142659664154053\n",
      "time per epoch: 0.06009078025817871\n",
      "=== Epoch: 301===\n",
      "batch = 0, mean loss = 0.8145821690559387\n",
      "batch = 1, mean loss = 0.8145821690559387\n",
      "time per epoch: 0.0630025863647461\n",
      "=== Epoch: 302===\n",
      "batch = 0, mean loss = 0.815650463104248\n",
      "batch = 1, mean loss = 0.815650463104248\n",
      "time per epoch: 0.056925296783447266\n",
      "=== Epoch: 303===\n",
      "batch = 0, mean loss = 0.8161846399307251\n",
      "batch = 1, mean loss = 0.8161846399307251\n",
      "time per epoch: 0.06344342231750488\n",
      "=== Epoch: 304===\n",
      "batch = 0, mean loss = 0.816227912902832\n",
      "batch = 1, mean loss = 0.816227912902832\n",
      "time per epoch: 0.06004047393798828\n",
      "=== Epoch: 305===\n",
      "batch = 0, mean loss = 0.8163955211639404\n",
      "batch = 1, mean loss = 0.8163955211639404\n",
      "time per epoch: 0.06186079978942871\n",
      "=== Epoch: 306===\n",
      "batch = 0, mean loss = 0.8162399530410767\n",
      "batch = 1, mean loss = 0.8162399530410767\n",
      "time per epoch: 0.06225419044494629\n",
      "=== Epoch: 307===\n",
      "batch = 0, mean loss = 0.8159918785095215\n",
      "batch = 1, mean loss = 0.8159918785095215\n",
      "time per epoch: 0.052580833435058594\n",
      "=== Epoch: 308===\n",
      "batch = 0, mean loss = 0.8153280019760132\n",
      "batch = 1, mean loss = 0.8153280019760132\n",
      "time per epoch: 0.06301665306091309\n",
      "=== Epoch: 309===\n",
      "batch = 0, mean loss = 0.814509391784668\n",
      "batch = 1, mean loss = 0.814509391784668\n",
      "time per epoch: 0.060461997985839844\n",
      "=== Epoch: 310===\n",
      "batch = 0, mean loss = 0.8133676052093506\n",
      "batch = 1, mean loss = 0.8133676052093506\n",
      "time per epoch: 0.05959057807922363\n",
      "=== Epoch: 311===\n",
      "batch = 0, mean loss = 0.8119760751724243\n",
      "batch = 1, mean loss = 0.8119760751724243\n",
      "time per epoch: 0.06500005722045898\n",
      "=== Epoch: 312===\n",
      "batch = 0, mean loss = 0.8101918697357178\n",
      "batch = 1, mean loss = 0.8101918697357178\n",
      "time per epoch: 0.05606222152709961\n",
      "=== Epoch: 313===\n",
      "batch = 0, mean loss = 0.808345377445221\n",
      "batch = 1, mean loss = 0.808345377445221\n",
      "time per epoch: 0.05935359001159668\n",
      "=== Epoch: 314===\n",
      "batch = 0, mean loss = 0.8063417077064514\n",
      "batch = 1, mean loss = 0.8063417077064514\n",
      "time per epoch: 0.06599974632263184\n",
      "=== Epoch: 315===\n",
      "batch = 0, mean loss = 0.8041653037071228\n",
      "batch = 1, mean loss = 0.8041653037071228\n",
      "time per epoch: 0.05101943016052246\n",
      "=== Epoch: 316===\n",
      "batch = 0, mean loss = 0.8020603060722351\n",
      "batch = 1, mean loss = 0.8020603060722351\n",
      "time per epoch: 0.05901646614074707\n",
      "=== Epoch: 317===\n",
      "batch = 0, mean loss = 0.8005977272987366\n",
      "batch = 1, mean loss = 0.8005977272987366\n",
      "time per epoch: 0.05915331840515137\n",
      "=== Epoch: 318===\n",
      "batch = 0, mean loss = 0.7997704744338989\n",
      "batch = 1, mean loss = 0.7997704744338989\n",
      "time per epoch: 0.05710268020629883\n",
      "=== Epoch: 319===\n",
      "batch = 0, mean loss = 0.7993252277374268\n",
      "batch = 1, mean loss = 0.7993252277374268\n",
      "time per epoch: 0.059850215911865234\n",
      "=== Epoch: 320===\n",
      "batch = 0, mean loss = 0.7988396883010864\n",
      "batch = 1, mean loss = 0.7988396883010864\n",
      "time per epoch: 0.059000253677368164\n",
      "=== Epoch: 321===\n",
      "batch = 0, mean loss = 0.7985658645629883\n",
      "batch = 1, mean loss = 0.7985658645629883\n",
      "time per epoch: 0.056014060974121094\n",
      "=== Epoch: 322===\n",
      "batch = 0, mean loss = 0.7983530759811401\n",
      "batch = 1, mean loss = 0.7983530759811401\n",
      "time per epoch: 0.060338735580444336\n",
      "=== Epoch: 323===\n",
      "batch = 0, mean loss = 0.7988459467887878\n",
      "batch = 1, mean loss = 0.7988459467887878\n",
      "time per epoch: 0.05592083930969238\n",
      "=== Epoch: 324===\n",
      "batch = 0, mean loss = 0.7999595403671265\n",
      "batch = 1, mean loss = 0.7999595403671265\n",
      "time per epoch: 0.06498527526855469\n",
      "=== Epoch: 325===\n",
      "batch = 0, mean loss = 0.8006077408790588\n",
      "batch = 1, mean loss = 0.8006077408790588\n",
      "time per epoch: 0.05399751663208008\n",
      "=== Epoch: 326===\n",
      "batch = 0, mean loss = 0.8011544942855835\n",
      "batch = 1, mean loss = 0.8011544942855835\n",
      "time per epoch: 0.055718421936035156\n",
      "=== Epoch: 327===\n",
      "batch = 0, mean loss = 0.8004430532455444\n",
      "batch = 1, mean loss = 0.8004430532455444\n",
      "time per epoch: 0.057528018951416016\n",
      "=== Epoch: 328===\n",
      "batch = 0, mean loss = 0.7995660901069641\n",
      "batch = 1, mean loss = 0.7995660901069641\n",
      "time per epoch: 0.05601358413696289\n",
      "=== Epoch: 329===\n",
      "batch = 0, mean loss = 0.7986368536949158\n",
      "batch = 1, mean loss = 0.7986368536949158\n",
      "time per epoch: 0.06015157699584961\n",
      "=== Epoch: 330===\n",
      "batch = 0, mean loss = 0.7980185747146606\n",
      "batch = 1, mean loss = 0.7980185747146606\n",
      "time per epoch: 0.06328845024108887\n",
      "=== Epoch: 331===\n",
      "batch = 0, mean loss = 0.797594428062439\n",
      "batch = 1, mean loss = 0.797594428062439\n",
      "time per epoch: 0.06316065788269043\n",
      "=== Epoch: 332===\n",
      "batch = 0, mean loss = 0.7973867058753967\n",
      "batch = 1, mean loss = 0.7973867058753967\n",
      "time per epoch: 0.06129097938537598\n",
      "=== Epoch: 333===\n",
      "batch = 0, mean loss = 0.7972996830940247\n",
      "batch = 1, mean loss = 0.7972996830940247\n",
      "time per epoch: 0.05827784538269043\n",
      "=== Epoch: 334===\n",
      "batch = 0, mean loss = 0.7970902919769287\n",
      "batch = 1, mean loss = 0.7970902919769287\n",
      "time per epoch: 0.05553388595581055\n",
      "=== Epoch: 335===\n",
      "batch = 0, mean loss = 0.7968670129776001\n",
      "batch = 1, mean loss = 0.7968670129776001\n",
      "time per epoch: 0.056020498275756836\n",
      "=== Epoch: 336===\n",
      "batch = 0, mean loss = 0.7969380021095276\n",
      "batch = 1, mean loss = 0.7969380021095276\n",
      "time per epoch: 0.05637526512145996\n",
      "=== Epoch: 337===\n",
      "batch = 0, mean loss = 0.7970990538597107\n",
      "batch = 1, mean loss = 0.7970990538597107\n",
      "time per epoch: 0.046204328536987305\n",
      "=== Epoch: 338===\n",
      "batch = 0, mean loss = 0.7980360984802246\n",
      "batch = 1, mean loss = 0.7980360984802246\n",
      "time per epoch: 0.05400395393371582\n",
      "=== Epoch: 339===\n",
      "batch = 0, mean loss = 0.7982799410820007\n",
      "batch = 1, mean loss = 0.7982799410820007\n",
      "time per epoch: 0.048007965087890625\n",
      "=== Epoch: 340===\n",
      "batch = 0, mean loss = 0.7980844974517822\n",
      "batch = 1, mean loss = 0.7980844974517822\n",
      "time per epoch: 0.04364585876464844\n",
      "=== Epoch: 341===\n",
      "batch = 0, mean loss = 0.797721266746521\n",
      "batch = 1, mean loss = 0.797721266746521\n",
      "time per epoch: 0.05184650421142578\n",
      "=== Epoch: 342===\n",
      "batch = 0, mean loss = 0.7968672513961792\n",
      "batch = 1, mean loss = 0.7968672513961792\n",
      "time per epoch: 0.05200004577636719\n",
      "=== Epoch: 343===\n",
      "batch = 0, mean loss = 0.7962793111801147\n",
      "batch = 1, mean loss = 0.7962793111801147\n",
      "time per epoch: 0.04945206642150879\n",
      "=== Epoch: 344===\n",
      "batch = 0, mean loss = 0.7957537174224854\n",
      "batch = 1, mean loss = 0.7957537174224854\n",
      "time per epoch: 0.04996228218078613\n",
      "=== Epoch: 345===\n",
      "batch = 0, mean loss = 0.7952927350997925\n",
      "batch = 1, mean loss = 0.7952927350997925\n",
      "time per epoch: 0.04101276397705078\n",
      "=== Epoch: 346===\n",
      "batch = 0, mean loss = 0.7952128648757935\n",
      "batch = 1, mean loss = 0.7952128648757935\n",
      "time per epoch: 0.04599738121032715\n",
      "=== Epoch: 347===\n",
      "batch = 0, mean loss = 0.797015905380249\n",
      "batch = 1, mean loss = 0.797015905380249\n",
      "time per epoch: 0.04605507850646973\n",
      "=== Epoch: 348===\n",
      "batch = 0, mean loss = 0.7948806285858154\n",
      "batch = 1, mean loss = 0.7948806285858154\n",
      "time per epoch: 0.04901242256164551\n",
      "=== Epoch: 349===\n",
      "batch = 0, mean loss = 0.7957602739334106\n",
      "batch = 1, mean loss = 0.7957602739334106\n",
      "time per epoch: 0.04999899864196777\n",
      "=== Epoch: 350===\n",
      "batch = 0, mean loss = 0.7946964502334595\n",
      "batch = 1, mean loss = 0.7946964502334595\n",
      "time per epoch: 0.05502820014953613\n",
      "=== Epoch: 351===\n",
      "batch = 0, mean loss = 0.7942848801612854\n",
      "batch = 1, mean loss = 0.7942848801612854\n",
      "time per epoch: 0.04778122901916504\n",
      "=== Epoch: 352===\n",
      "batch = 0, mean loss = 0.794475793838501\n",
      "batch = 1, mean loss = 0.794475793838501\n",
      "time per epoch: 0.04352736473083496\n",
      "=== Epoch: 353===\n",
      "batch = 0, mean loss = 0.794008195400238\n",
      "batch = 1, mean loss = 0.794008195400238\n",
      "time per epoch: 0.04800057411193848\n",
      "=== Epoch: 354===\n",
      "batch = 0, mean loss = 0.7938418388366699\n",
      "batch = 1, mean loss = 0.7938418388366699\n",
      "time per epoch: 0.05276036262512207\n",
      "=== Epoch: 355===\n",
      "batch = 0, mean loss = 0.7937849760055542\n",
      "batch = 1, mean loss = 0.7937849760055542\n",
      "time per epoch: 0.04987525939941406\n",
      "=== Epoch: 356===\n",
      "batch = 0, mean loss = 0.7935453653335571\n",
      "batch = 1, mean loss = 0.7935453653335571\n",
      "time per epoch: 0.04400014877319336\n",
      "=== Epoch: 357===\n",
      "batch = 0, mean loss = 0.7933472394943237\n",
      "batch = 1, mean loss = 0.7933472394943237\n",
      "time per epoch: 0.04915785789489746\n",
      "=== Epoch: 358===\n",
      "batch = 0, mean loss = 0.7951552867889404\n",
      "batch = 1, mean loss = 0.7951552867889404\n",
      "time per epoch: 0.04639029502868652\n",
      "=== Epoch: 359===\n",
      "batch = 0, mean loss = 0.7933717966079712\n",
      "batch = 1, mean loss = 0.7933717966079712\n",
      "time per epoch: 0.04255390167236328\n",
      "=== Epoch: 360===\n",
      "batch = 0, mean loss = 0.7947292923927307\n",
      "batch = 1, mean loss = 0.7947292923927307\n",
      "time per epoch: 0.040999650955200195\n",
      "=== Epoch: 361===\n",
      "batch = 0, mean loss = 0.7933810949325562\n",
      "batch = 1, mean loss = 0.7933810949325562\n",
      "time per epoch: 0.04601478576660156\n",
      "=== Epoch: 362===\n",
      "batch = 0, mean loss = 0.7944472432136536\n",
      "batch = 1, mean loss = 0.7944472432136536\n",
      "time per epoch: 0.05001473426818848\n",
      "=== Epoch: 363===\n",
      "batch = 0, mean loss = 0.7933858633041382\n",
      "batch = 1, mean loss = 0.7933858633041382\n",
      "time per epoch: 0.050528764724731445\n",
      "=== Epoch: 364===\n",
      "batch = 0, mean loss = 0.7940759062767029\n",
      "batch = 1, mean loss = 0.7940759062767029\n",
      "time per epoch: 0.05099964141845703\n",
      "=== Epoch: 365===\n",
      "batch = 0, mean loss = 0.7931331396102905\n",
      "batch = 1, mean loss = 0.7931331396102905\n",
      "time per epoch: 0.0458831787109375\n",
      "=== Epoch: 366===\n",
      "batch = 0, mean loss = 0.7931408882141113\n",
      "batch = 1, mean loss = 0.7931408882141113\n",
      "time per epoch: 0.04256105422973633\n",
      "=== Epoch: 367===\n",
      "batch = 0, mean loss = 0.7934675216674805\n",
      "batch = 1, mean loss = 0.7934675216674805\n",
      "time per epoch: 0.04155111312866211\n",
      "=== Epoch: 368===\n",
      "batch = 0, mean loss = 0.7933698892593384\n",
      "batch = 1, mean loss = 0.7933698892593384\n",
      "time per epoch: 0.042999982833862305\n",
      "=== Epoch: 369===\n",
      "batch = 0, mean loss = 0.7932073473930359\n",
      "batch = 1, mean loss = 0.7932073473930359\n",
      "time per epoch: 0.04326486587524414\n",
      "=== Epoch: 370===\n",
      "batch = 0, mean loss = 0.7933617234230042\n",
      "batch = 1, mean loss = 0.7933617234230042\n",
      "time per epoch: 0.04021763801574707\n",
      "=== Epoch: 371===\n",
      "batch = 0, mean loss = 0.7934826612472534\n",
      "batch = 1, mean loss = 0.7934826612472534\n",
      "time per epoch: 0.05205345153808594\n",
      "=== Epoch: 372===\n",
      "batch = 0, mean loss = 0.7935026288032532\n",
      "batch = 1, mean loss = 0.7935026288032532\n",
      "time per epoch: 0.052854299545288086\n",
      "=== Epoch: 373===\n",
      "batch = 0, mean loss = 0.7934011220932007\n",
      "batch = 1, mean loss = 0.7934011220932007\n",
      "time per epoch: 0.04602646827697754\n",
      "=== Epoch: 374===\n",
      "batch = 0, mean loss = 0.7932959794998169\n",
      "batch = 1, mean loss = 0.7932959794998169\n",
      "time per epoch: 0.04286813735961914\n",
      "=== Epoch: 375===\n",
      "batch = 0, mean loss = 0.7932755947113037\n",
      "batch = 1, mean loss = 0.7932755947113037\n",
      "time per epoch: 0.0495610237121582\n",
      "=== Epoch: 376===\n",
      "batch = 0, mean loss = 0.7930854558944702\n",
      "batch = 1, mean loss = 0.7930854558944702\n",
      "time per epoch: 0.04200243949890137\n",
      "=== Epoch: 377===\n",
      "batch = 0, mean loss = 0.7929909229278564\n",
      "batch = 1, mean loss = 0.7929909229278564\n",
      "time per epoch: 0.04885721206665039\n",
      "=== Epoch: 378===\n",
      "batch = 0, mean loss = 0.7930376529693604\n",
      "batch = 1, mean loss = 0.7930376529693604\n",
      "time per epoch: 0.050048112869262695\n",
      "=== Epoch: 379===\n",
      "batch = 0, mean loss = 0.793015718460083\n",
      "batch = 1, mean loss = 0.793015718460083\n",
      "time per epoch: 0.05201101303100586\n",
      "=== Epoch: 380===\n",
      "batch = 0, mean loss = 0.7928708791732788\n",
      "batch = 1, mean loss = 0.7928708791732788\n",
      "time per epoch: 0.048947811126708984\n",
      "=== Epoch: 381===\n",
      "batch = 0, mean loss = 0.7926512956619263\n",
      "batch = 1, mean loss = 0.7926512956619263\n",
      "time per epoch: 0.04399251937866211\n",
      "=== Epoch: 382===\n",
      "batch = 0, mean loss = 0.7925927639007568\n",
      "batch = 1, mean loss = 0.7925927639007568\n",
      "time per epoch: 0.045021772384643555\n",
      "=== Epoch: 383===\n",
      "batch = 0, mean loss = 0.7924686670303345\n",
      "batch = 1, mean loss = 0.7924686670303345\n",
      "time per epoch: 0.045000314712524414\n",
      "=== Epoch: 384===\n",
      "batch = 0, mean loss = 0.7923710942268372\n",
      "batch = 1, mean loss = 0.7923710942268372\n",
      "time per epoch: 0.04120588302612305\n",
      "=== Epoch: 385===\n",
      "batch = 0, mean loss = 0.7958084344863892\n",
      "batch = 1, mean loss = 0.7958084344863892\n",
      "time per epoch: 0.04137992858886719\n",
      "=== Epoch: 386===\n",
      "batch = 0, mean loss = 0.7923396229743958\n",
      "batch = 1, mean loss = 0.7923396229743958\n",
      "time per epoch: 0.04805254936218262\n",
      "=== Epoch: 387===\n",
      "batch = 0, mean loss = 0.7925738096237183\n",
      "batch = 1, mean loss = 0.7925738096237183\n",
      "time per epoch: 0.049999237060546875\n",
      "=== Epoch: 388===\n",
      "batch = 0, mean loss = 0.7927743792533875\n",
      "batch = 1, mean loss = 0.7927743792533875\n",
      "time per epoch: 0.05622386932373047\n",
      "=== Epoch: 389===\n",
      "batch = 0, mean loss = 0.7927950620651245\n",
      "batch = 1, mean loss = 0.7927950620651245\n",
      "time per epoch: 0.05205059051513672\n",
      "=== Epoch: 390===\n",
      "batch = 0, mean loss = 0.7926656007766724\n",
      "batch = 1, mean loss = 0.7926656007766724\n",
      "time per epoch: 0.05199599266052246\n",
      "=== Epoch: 391===\n",
      "batch = 0, mean loss = 0.7923873662948608\n",
      "batch = 1, mean loss = 0.7923873662948608\n",
      "time per epoch: 0.03899979591369629\n",
      "=== Epoch: 392===\n",
      "batch = 0, mean loss = 0.7922697067260742\n",
      "batch = 1, mean loss = 0.7922697067260742\n",
      "time per epoch: 0.04806399345397949\n",
      "=== Epoch: 393===\n",
      "batch = 0, mean loss = 0.7921581268310547\n",
      "batch = 1, mean loss = 0.7921581268310547\n",
      "time per epoch: 0.05935549736022949\n",
      "=== Epoch: 394===\n",
      "batch = 0, mean loss = 0.7920204997062683\n",
      "batch = 1, mean loss = 0.7920204997062683\n",
      "time per epoch: 0.04702877998352051\n",
      "=== Epoch: 395===\n",
      "batch = 0, mean loss = 0.793789267539978\n",
      "batch = 1, mean loss = 0.793789267539978\n",
      "time per epoch: 0.04809379577636719\n",
      "=== Epoch: 396===\n",
      "batch = 0, mean loss = 0.7917914986610413\n",
      "batch = 1, mean loss = 0.7917914986610413\n",
      "time per epoch: 0.043479204177856445\n",
      "=== Epoch: 397===\n",
      "batch = 0, mean loss = 0.7920037508010864\n",
      "batch = 1, mean loss = 0.7920037508010864\n",
      "time per epoch: 0.044077157974243164\n",
      "=== Epoch: 398===\n",
      "batch = 0, mean loss = 0.7921735048294067\n",
      "batch = 1, mean loss = 0.7921735048294067\n",
      "time per epoch: 0.04999971389770508\n",
      "=== Epoch: 399===\n",
      "batch = 0, mean loss = 0.7921699285507202\n",
      "batch = 1, mean loss = 0.7921699285507202\n",
      "time per epoch: 0.05323910713195801\n",
      "=== Epoch: 400===\n",
      "batch = 0, mean loss = 0.7919026017189026\n",
      "batch = 1, mean loss = 0.7919026017189026\n",
      "time per epoch: 0.05435657501220703\n",
      "=== Epoch: 401===\n",
      "batch = 0, mean loss = 0.7917612195014954\n",
      "batch = 1, mean loss = 0.7917612195014954\n",
      "time per epoch: 0.051210880279541016\n",
      "=== Epoch: 402===\n",
      "batch = 0, mean loss = 0.7918438911437988\n",
      "batch = 1, mean loss = 0.7918438911437988\n",
      "time per epoch: 0.042999267578125\n",
      "=== Epoch: 403===\n",
      "batch = 0, mean loss = 0.7917397618293762\n",
      "batch = 1, mean loss = 0.7917397618293762\n",
      "time per epoch: 0.04518532752990723\n",
      "=== Epoch: 404===\n",
      "batch = 0, mean loss = 0.7918004393577576\n",
      "batch = 1, mean loss = 0.7918004393577576\n",
      "time per epoch: 0.04437398910522461\n",
      "=== Epoch: 405===\n",
      "batch = 0, mean loss = 0.7925698757171631\n",
      "batch = 1, mean loss = 0.7925698757171631\n",
      "time per epoch: 0.04900336265563965\n",
      "=== Epoch: 406===\n",
      "batch = 0, mean loss = 0.7927788496017456\n",
      "batch = 1, mean loss = 0.7927788496017456\n",
      "time per epoch: 0.046319007873535156\n",
      "=== Epoch: 407===\n",
      "batch = 0, mean loss = 0.7932730317115784\n",
      "batch = 1, mean loss = 0.7932730317115784\n",
      "time per epoch: 0.04900860786437988\n",
      "=== Epoch: 408===\n",
      "batch = 0, mean loss = 0.7933619022369385\n",
      "batch = 1, mean loss = 0.7933619022369385\n",
      "time per epoch: 0.05305051803588867\n",
      "=== Epoch: 409===\n",
      "batch = 0, mean loss = 0.7936004400253296\n",
      "batch = 1, mean loss = 0.7936004400253296\n",
      "time per epoch: 0.04499983787536621\n",
      "=== Epoch: 410===\n",
      "batch = 0, mean loss = 0.7932130098342896\n",
      "batch = 1, mean loss = 0.7932130098342896\n",
      "time per epoch: 0.043975114822387695\n",
      "=== Epoch: 411===\n",
      "batch = 0, mean loss = 0.7930648326873779\n",
      "batch = 1, mean loss = 0.7930648326873779\n",
      "time per epoch: 0.0460968017578125\n",
      "=== Epoch: 412===\n",
      "batch = 0, mean loss = 0.7928234338760376\n",
      "batch = 1, mean loss = 0.7928234338760376\n",
      "time per epoch: 0.04999709129333496\n",
      "=== Epoch: 413===\n",
      "batch = 0, mean loss = 0.7924099564552307\n",
      "batch = 1, mean loss = 0.7924099564552307\n",
      "time per epoch: 0.0512850284576416\n",
      "=== Epoch: 414===\n",
      "batch = 0, mean loss = 0.7921351194381714\n",
      "batch = 1, mean loss = 0.7921351194381714\n",
      "time per epoch: 0.058594465255737305\n",
      "=== Epoch: 415===\n",
      "batch = 0, mean loss = 0.7920329570770264\n",
      "batch = 1, mean loss = 0.7920329570770264\n",
      "time per epoch: 0.040418148040771484\n",
      "=== Epoch: 416===\n",
      "batch = 0, mean loss = 0.7921620011329651\n",
      "batch = 1, mean loss = 0.7921620011329651\n",
      "time per epoch: 0.051999807357788086\n",
      "=== Epoch: 417===\n",
      "batch = 0, mean loss = 0.7920595407485962\n",
      "batch = 1, mean loss = 0.7920595407485962\n",
      "time per epoch: 0.05298495292663574\n",
      "=== Epoch: 418===\n",
      "batch = 0, mean loss = 0.792109489440918\n",
      "batch = 1, mean loss = 0.792109489440918\n",
      "time per epoch: 0.052616119384765625\n",
      "=== Epoch: 419===\n",
      "batch = 0, mean loss = 0.7920396327972412\n",
      "batch = 1, mean loss = 0.7920396327972412\n",
      "time per epoch: 0.046036720275878906\n",
      "=== Epoch: 420===\n",
      "batch = 0, mean loss = 0.791827380657196\n",
      "batch = 1, mean loss = 0.791827380657196\n",
      "time per epoch: 0.041997432708740234\n",
      "=== Epoch: 421===\n",
      "batch = 0, mean loss = 0.7917619347572327\n",
      "batch = 1, mean loss = 0.7917619347572327\n",
      "time per epoch: 0.04200005531311035\n",
      "=== Epoch: 422===\n",
      "batch = 0, mean loss = 0.791599690914154\n",
      "batch = 1, mean loss = 0.791599690914154\n",
      "time per epoch: 0.04002237319946289\n",
      "=== Epoch: 423===\n",
      "batch = 0, mean loss = 0.7913864254951477\n",
      "batch = 1, mean loss = 0.7913864254951477\n",
      "time per epoch: 0.0400235652923584\n",
      "=== Epoch: 424===\n",
      "batch = 0, mean loss = 0.7911577224731445\n",
      "batch = 1, mean loss = 0.7911577224731445\n",
      "time per epoch: 0.048566579818725586\n",
      "=== Epoch: 425===\n",
      "batch = 0, mean loss = 0.7909879684448242\n",
      "batch = 1, mean loss = 0.7909879684448242\n",
      "time per epoch: 0.055292606353759766\n",
      "=== Epoch: 426===\n",
      "batch = 0, mean loss = 0.7908447980880737\n",
      "batch = 1, mean loss = 0.7908447980880737\n",
      "time per epoch: 0.04901933670043945\n",
      "=== Epoch: 427===\n",
      "batch = 0, mean loss = 0.7907680869102478\n",
      "batch = 1, mean loss = 0.7907680869102478\n",
      "time per epoch: 0.045693397521972656\n",
      "=== Epoch: 428===\n",
      "batch = 0, mean loss = 0.790713369846344\n",
      "batch = 1, mean loss = 0.790713369846344\n",
      "time per epoch: 0.04500102996826172\n",
      "=== Epoch: 429===\n",
      "batch = 0, mean loss = 0.7906186580657959\n",
      "batch = 1, mean loss = 0.7906186580657959\n",
      "time per epoch: 0.04903268814086914\n",
      "=== Epoch: 430===\n",
      "batch = 0, mean loss = 0.7904473543167114\n",
      "batch = 1, mean loss = 0.7904473543167114\n",
      "time per epoch: 0.056038856506347656\n",
      "=== Epoch: 431===\n",
      "batch = 0, mean loss = 0.7903916239738464\n",
      "batch = 1, mean loss = 0.7903916239738464\n",
      "time per epoch: 0.043999671936035156\n",
      "=== Epoch: 432===\n",
      "batch = 0, mean loss = 0.7904951572418213\n",
      "batch = 1, mean loss = 0.7904951572418213\n",
      "time per epoch: 0.04100322723388672\n",
      "=== Epoch: 433===\n",
      "batch = 0, mean loss = 0.7904582023620605\n",
      "batch = 1, mean loss = 0.7904582023620605\n",
      "time per epoch: 0.046671390533447266\n",
      "=== Epoch: 434===\n",
      "batch = 0, mean loss = 0.7903979420661926\n",
      "batch = 1, mean loss = 0.7903979420661926\n",
      "time per epoch: 0.0450589656829834\n",
      "=== Epoch: 435===\n",
      "batch = 0, mean loss = 0.7904267311096191\n",
      "batch = 1, mean loss = 0.7904267311096191\n",
      "time per epoch: 0.05103945732116699\n",
      "=== Epoch: 436===\n",
      "batch = 0, mean loss = 0.7904411554336548\n",
      "batch = 1, mean loss = 0.7904411554336548\n",
      "time per epoch: 0.04946255683898926\n",
      "=== Epoch: 437===\n",
      "batch = 0, mean loss = 0.7903096079826355\n",
      "batch = 1, mean loss = 0.7903096079826355\n",
      "time per epoch: 0.0410001277923584\n",
      "=== Epoch: 438===\n",
      "batch = 0, mean loss = 0.790141761302948\n",
      "batch = 1, mean loss = 0.790141761302948\n",
      "time per epoch: 0.04704856872558594\n",
      "=== Epoch: 439===\n",
      "batch = 0, mean loss = 0.7899785041809082\n",
      "batch = 1, mean loss = 0.7899785041809082\n",
      "time per epoch: 0.17888259887695312\n",
      "=== Epoch: 440===\n",
      "batch = 0, mean loss = 0.7898575067520142\n",
      "batch = 1, mean loss = 0.7898575067520142\n",
      "time per epoch: 0.049012184143066406\n",
      "=== Epoch: 441===\n",
      "batch = 0, mean loss = 0.789665699005127\n",
      "batch = 1, mean loss = 0.789665699005127\n",
      "time per epoch: 0.05015754699707031\n",
      "=== Epoch: 442===\n",
      "batch = 0, mean loss = 0.7895476818084717\n",
      "batch = 1, mean loss = 0.7895476818084717\n",
      "time per epoch: 0.0512542724609375\n",
      "=== Epoch: 443===\n",
      "batch = 0, mean loss = 0.7893529534339905\n",
      "batch = 1, mean loss = 0.7893529534339905\n",
      "time per epoch: 0.05982255935668945\n",
      "=== Epoch: 444===\n",
      "batch = 0, mean loss = 0.7890810966491699\n",
      "batch = 1, mean loss = 0.7890810966491699\n",
      "time per epoch: 0.06001996994018555\n",
      "=== Epoch: 445===\n",
      "batch = 0, mean loss = 0.7893775701522827\n",
      "batch = 1, mean loss = 0.7893775701522827\n",
      "time per epoch: 0.055300235748291016\n",
      "=== Epoch: 446===\n",
      "batch = 0, mean loss = 0.789750337600708\n",
      "batch = 1, mean loss = 0.789750337600708\n",
      "time per epoch: 0.060944557189941406\n",
      "=== Epoch: 447===\n",
      "batch = 0, mean loss = 0.7900677919387817\n",
      "batch = 1, mean loss = 0.7900677919387817\n",
      "time per epoch: 0.05900168418884277\n",
      "=== Epoch: 448===\n",
      "batch = 0, mean loss = 0.7904283404350281\n",
      "batch = 1, mean loss = 0.7904283404350281\n",
      "time per epoch: 0.05832219123840332\n",
      "=== Epoch: 449===\n",
      "batch = 0, mean loss = 0.7907813191413879\n",
      "batch = 1, mean loss = 0.7907813191413879\n",
      "time per epoch: 0.0500798225402832\n",
      "=== Epoch: 450===\n",
      "batch = 0, mean loss = 0.7909488677978516\n",
      "batch = 1, mean loss = 0.7909488677978516\n",
      "time per epoch: 0.049046993255615234\n",
      "=== Epoch: 451===\n",
      "batch = 0, mean loss = 0.7907331585884094\n",
      "batch = 1, mean loss = 0.7907331585884094\n",
      "time per epoch: 0.06300520896911621\n",
      "=== Epoch: 452===\n",
      "batch = 0, mean loss = 0.7906466722488403\n",
      "batch = 1, mean loss = 0.7906466722488403\n",
      "time per epoch: 0.0599055290222168\n",
      "=== Epoch: 453===\n",
      "batch = 0, mean loss = 0.7903995513916016\n",
      "batch = 1, mean loss = 0.7903995513916016\n",
      "time per epoch: 0.06064009666442871\n",
      "=== Epoch: 454===\n",
      "batch = 0, mean loss = 0.7901871800422668\n",
      "batch = 1, mean loss = 0.7901871800422668\n",
      "time per epoch: 0.05412650108337402\n",
      "=== Epoch: 455===\n",
      "batch = 0, mean loss = 0.7902086973190308\n",
      "batch = 1, mean loss = 0.7902086973190308\n",
      "time per epoch: 0.05924820899963379\n",
      "=== Epoch: 456===\n",
      "batch = 0, mean loss = 0.7898532748222351\n",
      "batch = 1, mean loss = 0.7898532748222351\n",
      "time per epoch: 0.055702924728393555\n",
      "=== Epoch: 457===\n",
      "batch = 0, mean loss = 0.7896177768707275\n",
      "batch = 1, mean loss = 0.7896177768707275\n",
      "time per epoch: 0.06501555442810059\n",
      "=== Epoch: 458===\n",
      "batch = 0, mean loss = 0.7894095182418823\n",
      "batch = 1, mean loss = 0.7894095182418823\n",
      "time per epoch: 0.06151580810546875\n",
      "=== Epoch: 459===\n",
      "batch = 0, mean loss = 0.7892885208129883\n",
      "batch = 1, mean loss = 0.7892885208129883\n",
      "time per epoch: 0.06817412376403809\n",
      "=== Epoch: 460===\n",
      "batch = 0, mean loss = 0.7890950441360474\n",
      "batch = 1, mean loss = 0.7890950441360474\n",
      "time per epoch: 0.06000208854675293\n",
      "=== Epoch: 461===\n",
      "batch = 0, mean loss = 0.7889997959136963\n",
      "batch = 1, mean loss = 0.7889997959136963\n",
      "time per epoch: 0.059870243072509766\n",
      "=== Epoch: 462===\n",
      "batch = 0, mean loss = 0.7889212369918823\n",
      "batch = 1, mean loss = 0.7889212369918823\n",
      "time per epoch: 0.06211209297180176\n",
      "=== Epoch: 463===\n",
      "batch = 0, mean loss = 0.7888954877853394\n",
      "batch = 1, mean loss = 0.7888954877853394\n",
      "time per epoch: 0.052997589111328125\n",
      "=== Epoch: 464===\n",
      "batch = 0, mean loss = 0.7888738512992859\n",
      "batch = 1, mean loss = 0.7888738512992859\n",
      "time per epoch: 0.057971954345703125\n",
      "=== Epoch: 465===\n",
      "batch = 0, mean loss = 0.7888109683990479\n",
      "batch = 1, mean loss = 0.7888109683990479\n",
      "time per epoch: 0.06351661682128906\n",
      "=== Epoch: 466===\n",
      "batch = 0, mean loss = 0.7886950969696045\n",
      "batch = 1, mean loss = 0.7886950969696045\n",
      "time per epoch: 0.06100273132324219\n",
      "=== Epoch: 467===\n",
      "batch = 0, mean loss = 0.7885403037071228\n",
      "batch = 1, mean loss = 0.7885403037071228\n",
      "time per epoch: 0.0638582706451416\n",
      "=== Epoch: 468===\n",
      "batch = 0, mean loss = 0.7884944677352905\n",
      "batch = 1, mean loss = 0.7884944677352905\n",
      "time per epoch: 0.07200860977172852\n",
      "=== Epoch: 469===\n",
      "batch = 0, mean loss = 0.7908542156219482\n",
      "batch = 1, mean loss = 0.7908542156219482\n",
      "time per epoch: 0.06399917602539062\n",
      "=== Epoch: 470===\n",
      "batch = 0, mean loss = 0.7892162799835205\n",
      "batch = 1, mean loss = 0.7892162799835205\n",
      "time per epoch: 0.06000041961669922\n",
      "=== Epoch: 471===\n",
      "batch = 0, mean loss = 0.789619505405426\n",
      "batch = 1, mean loss = 0.789619505405426\n",
      "time per epoch: 0.05899858474731445\n",
      "=== Epoch: 472===\n",
      "batch = 0, mean loss = 0.7900663614273071\n",
      "batch = 1, mean loss = 0.7900663614273071\n",
      "time per epoch: 0.06096053123474121\n",
      "=== Epoch: 473===\n",
      "batch = 0, mean loss = 0.7900680899620056\n",
      "batch = 1, mean loss = 0.7900680899620056\n",
      "time per epoch: 0.062474966049194336\n",
      "=== Epoch: 474===\n",
      "batch = 0, mean loss = 0.7898152470588684\n",
      "batch = 1, mean loss = 0.7898152470588684\n",
      "time per epoch: 0.06345748901367188\n",
      "=== Epoch: 475===\n",
      "batch = 0, mean loss = 0.7892665863037109\n",
      "batch = 1, mean loss = 0.7892665863037109\n",
      "time per epoch: 0.05915570259094238\n",
      "=== Epoch: 476===\n",
      "batch = 0, mean loss = 0.7889252305030823\n",
      "batch = 1, mean loss = 0.7889252305030823\n",
      "time per epoch: 0.0664362907409668\n",
      "=== Epoch: 477===\n",
      "batch = 0, mean loss = 0.7887414693832397\n",
      "batch = 1, mean loss = 0.7887414693832397\n",
      "time per epoch: 0.06200361251831055\n",
      "=== Epoch: 478===\n",
      "batch = 0, mean loss = 0.7883387804031372\n",
      "batch = 1, mean loss = 0.7883387804031372\n",
      "time per epoch: 0.06414985656738281\n",
      "=== Epoch: 479===\n",
      "batch = 0, mean loss = 0.7880507707595825\n",
      "batch = 1, mean loss = 0.7880507707595825\n",
      "time per epoch: 0.057074785232543945\n",
      "=== Epoch: 480===\n",
      "batch = 0, mean loss = 0.7879523038864136\n",
      "batch = 1, mean loss = 0.7879523038864136\n",
      "time per epoch: 0.05402827262878418\n",
      "=== Epoch: 481===\n",
      "batch = 0, mean loss = 0.7877825498580933\n",
      "batch = 1, mean loss = 0.7877825498580933\n",
      "time per epoch: 0.05765843391418457\n",
      "=== Epoch: 482===\n",
      "batch = 0, mean loss = 0.7876308560371399\n",
      "batch = 1, mean loss = 0.7876308560371399\n",
      "time per epoch: 0.05994725227355957\n",
      "=== Epoch: 483===\n",
      "batch = 0, mean loss = 0.7874513268470764\n",
      "batch = 1, mean loss = 0.7874513268470764\n",
      "time per epoch: 0.06100320816040039\n",
      "=== Epoch: 484===\n",
      "batch = 0, mean loss = 0.7873563766479492\n",
      "batch = 1, mean loss = 0.7873563766479492\n",
      "time per epoch: 0.0566256046295166\n",
      "=== Epoch: 485===\n",
      "batch = 0, mean loss = 0.7872998714447021\n",
      "batch = 1, mean loss = 0.7872998714447021\n",
      "time per epoch: 0.07172584533691406\n",
      "=== Epoch: 486===\n",
      "batch = 0, mean loss = 0.79094398021698\n",
      "batch = 1, mean loss = 0.79094398021698\n",
      "time per epoch: 0.05999922752380371\n",
      "=== Epoch: 487===\n",
      "batch = 0, mean loss = 0.787158727645874\n",
      "batch = 1, mean loss = 0.787158727645874\n",
      "time per epoch: 0.05201101303100586\n",
      "=== Epoch: 488===\n",
      "batch = 0, mean loss = 0.7871978282928467\n",
      "batch = 1, mean loss = 0.7871978282928467\n",
      "time per epoch: 0.061672210693359375\n",
      "=== Epoch: 489===\n",
      "batch = 0, mean loss = 0.7870254516601562\n",
      "batch = 1, mean loss = 0.7870254516601562\n",
      "time per epoch: 0.05907797813415527\n",
      "=== Epoch: 490===\n",
      "batch = 0, mean loss = 0.7872151136398315\n",
      "batch = 1, mean loss = 0.7872151136398315\n",
      "time per epoch: 0.0607757568359375\n",
      "=== Epoch: 491===\n",
      "batch = 0, mean loss = 0.7877750992774963\n",
      "batch = 1, mean loss = 0.7877750992774963\n",
      "time per epoch: 0.0580906867980957\n",
      "=== Epoch: 492===\n",
      "batch = 0, mean loss = 0.7883130311965942\n",
      "batch = 1, mean loss = 0.7883130311965942\n",
      "time per epoch: 0.05500006675720215\n",
      "=== Epoch: 493===\n",
      "batch = 0, mean loss = 0.7891004085540771\n",
      "batch = 1, mean loss = 0.7891004085540771\n",
      "time per epoch: 0.06413960456848145\n",
      "=== Epoch: 494===\n",
      "batch = 0, mean loss = 0.7912305593490601\n",
      "batch = 1, mean loss = 0.7912305593490601\n",
      "time per epoch: 0.06093144416809082\n",
      "=== Epoch: 495===\n",
      "batch = 0, mean loss = 0.7947283387184143\n",
      "batch = 1, mean loss = 0.7947283387184143\n",
      "time per epoch: 0.05100131034851074\n",
      "=== Epoch: 496===\n",
      "batch = 0, mean loss = 0.7978028059005737\n",
      "batch = 1, mean loss = 0.7978028059005737\n",
      "time per epoch: 0.06407356262207031\n",
      "=== Epoch: 497===\n",
      "batch = 0, mean loss = 0.8015815019607544\n",
      "batch = 1, mean loss = 0.8015815019607544\n",
      "time per epoch: 0.05308413505554199\n",
      "=== Epoch: 498===\n",
      "batch = 0, mean loss = 0.8040721416473389\n",
      "batch = 1, mean loss = 0.8040721416473389\n",
      "time per epoch: 0.06629467010498047\n",
      "=== Epoch: 499===\n",
      "batch = 0, mean loss = 0.8076720833778381\n",
      "batch = 1, mean loss = 0.8076720833778381\n",
      "time per epoch: 0.06508493423461914\n",
      "        time for training: 27.48083209991455\n",
      "        actual verification time 0.30710482597351074\n",
      "        time for verification: 0.4561448097229004\n",
      "aborting because of force break\n"
     ]
    }
   ],
   "source": [
    "group_size = 2\n",
    "icnn_factory = ICNNFactory(\"logical\", [10, 5, 1], force_positive_init=False, with_two_layers=False,\n",
    "                               init_scaling=10, init_all_with_zeros=False)\n",
    "#icnn_factory = ICNNFactory(\"standard\", [5, 5, 1])\n",
    "\n",
    "icnns, all_group_indices, fixed_neuron_per_layer_lower, fixed_neuron_per_layer_upper, bounds_affine_out, bounds_layer_out = \\\n",
    "    multidhov.start_verification(nn, test_image, icnn_factory, group_size, eps=eps, icnn_epochs=500, icnn_batch_size=1000,\n",
    "                                 sample_count=1000, sample_new=True, use_over_approximation=True, break_after=1,\n",
    "                                 sample_over_input_space=True, sample_over_output_space=True, use_icnn_bounds=True, use_fixed_neurons=True,\n",
    "                                 force_inclusion_steps=0, preemptive_stop=False, even_gradient_training=False,\n",
    "                                 keep_ambient_space=True, data_grad_descent_steps=0, opt_steps_gd=100, train_outer=False,\n",
    "                                 should_plot=\"none\", optimizer=\"SdLBFGS\", init_network=True, adapt_lambda=\"none\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1985, 2.2024, 3.5789, 3.2989, 3.1727, 2.7257, 3.1588, 2.9706, 2.3492,\n",
      "        2.3374, 2.2188, 3.5131, 2.9834, 3.2893, 2.7698, 2.7456, 3.0551, 2.7703,\n",
      "        2.4261, 2.7636, 2.3316, 2.5707, 3.1093, 2.7213, 3.2009, 2.8840, 2.6372,\n",
      "        3.2359, 2.7661, 3.7934, 1.9150, 3.2887, 2.6867, 3.5916, 2.4751, 3.0572,\n",
      "        2.5368, 2.8881, 2.4758, 2.3353, 2.7308, 2.2997, 2.9015, 2.8642, 2.6307,\n",
      "        2.6679, 2.1138, 2.7184, 2.5877, 2.4363, 2.8510, 2.2290, 2.7605, 2.9352,\n",
      "        2.5532, 2.4591, 2.0163, 3.2752, 2.3035, 2.7828, 2.5608, 2.5729, 2.1703,\n",
      "        2.6810, 2.4530, 2.5627, 2.7323, 3.0748, 2.3498, 3.0908, 2.9539, 2.4527,\n",
      "        2.4962, 2.8960, 2.6532, 2.6162, 2.2160, 3.6041, 3.0032, 2.8227, 2.6230,\n",
      "        3.2652, 2.3000, 2.5879, 2.6289, 3.2825, 2.4289, 3.2062, 2.0722, 2.9592,\n",
      "        2.0333, 2.4219, 2.9470, 3.5575, 2.5283, 2.6129, 2.5972, 2.9534, 2.9723,\n",
      "        2.5614, 2.8972, 2.7913, 2.9018, 1.8760, 3.3864, 3.4564, 2.7306, 3.0458,\n",
      "        2.2486, 3.0729, 2.5512, 2.5311, 2.8378, 2.2285, 3.0569, 2.5264, 2.6175,\n",
      "        2.5961, 2.5296, 2.6409, 2.6287, 2.5965, 2.9409, 2.4046, 2.7446, 2.3342,\n",
      "        2.9047, 2.5440, 3.0772, 1.9716, 2.1576, 2.7586, 2.4789, 2.6533, 2.2112,\n",
      "        1.8408, 2.9815, 2.7088, 2.7785, 2.7992, 3.3071, 3.1239, 2.4893, 3.1774,\n",
      "        2.4032, 2.8245, 2.6077, 3.3692, 2.4308, 2.2467, 1.9323, 2.7972, 2.7219,\n",
      "        3.2780, 2.9485, 1.9737, 2.9057, 3.7385, 3.2042, 2.6872, 2.8178, 2.6759,\n",
      "        2.4202, 2.7386, 2.2116, 2.8576, 3.0162, 2.2776, 3.1711, 2.4163, 3.9645,\n",
      "        2.4481, 2.7093, 2.1543, 2.6305, 2.5179, 2.1667, 2.6047, 2.6598, 2.0520,\n",
      "        3.2499, 2.4984, 3.2387, 1.9903, 2.1779, 2.6996, 3.1078, 3.0683, 2.8121,\n",
      "        2.5086, 2.6226, 2.2937, 2.8322, 2.4843, 2.4434, 2.6395, 2.6338, 2.3789,\n",
      "        2.7651, 2.4555, 2.8191, 2.7082, 1.9177, 1.8043, 2.0851, 2.5194, 2.5843,\n",
      "        2.2937, 2.0311, 2.0399, 2.4141, 2.8709, 2.6827, 3.2072, 2.4175, 2.9141,\n",
      "        2.7656, 2.7763, 2.8114, 2.5082, 1.9327, 2.6724, 2.2971, 2.3961, 2.4524,\n",
      "        2.7674, 2.5349, 3.2752, 2.6632, 2.7877, 2.4443, 2.6509, 2.4466, 2.1202,\n",
      "        2.9781, 2.3353, 2.5709, 2.1044, 2.5156, 2.9475, 3.4756, 2.5669, 2.3189,\n",
      "        2.3897, 2.2457, 3.0801, 3.5114, 2.4983, 2.5862, 2.5761, 3.1905, 2.3847,\n",
      "        2.0487, 2.6575, 2.6359, 3.1154, 2.4759, 2.8485, 3.0165, 2.8262, 2.6906,\n",
      "        2.8355, 2.7099, 2.5992, 1.6763, 2.7652, 2.6295, 2.3402, 2.8419, 2.9079,\n",
      "        2.4964, 2.8957, 2.8146, 2.8652, 2.3430, 2.9373, 1.6113, 2.4700, 1.9122,\n",
      "        2.3025, 2.5531, 2.2747, 2.6465, 2.9438, 2.1805, 2.2151, 3.0780, 2.2498,\n",
      "        2.4682, 2.1720, 1.9502, 2.3754, 3.0590, 2.9243, 2.5663, 2.1819, 1.9129,\n",
      "        2.4948, 2.9328, 2.1700, 2.6950, 2.9161, 3.1480, 2.9733, 2.6979, 1.7689,\n",
      "        2.1127, 2.9371, 2.5969, 3.9292, 3.1885, 2.4670, 2.7131, 2.7215, 2.7180,\n",
      "        2.5085, 3.2214, 3.0689, 3.8328, 2.5023, 2.7256, 2.1245, 2.3074, 2.0151,\n",
      "        2.5359, 2.9857, 2.3858, 2.7070, 2.9559, 2.5780, 2.9495, 2.1060, 2.3754,\n",
      "        2.7490, 2.9435, 2.4471, 2.6938, 2.2222, 2.7023, 2.6875, 2.6380, 2.3804,\n",
      "        2.8629, 2.6581, 2.5343, 2.1080, 3.1665, 2.9870, 2.4671, 3.0791, 2.9258,\n",
      "        2.0098, 2.9876, 2.4583, 3.1908, 1.8993, 2.4326, 3.2954, 2.3088, 2.7669,\n",
      "        2.3705, 2.6104, 2.2965, 2.8599, 3.0404, 3.1265, 2.3486, 2.6209, 2.5314,\n",
      "        2.9598, 2.1777, 3.2833, 2.4826, 2.1495, 2.1120, 2.6329, 2.0196, 2.5830,\n",
      "        2.9953, 2.7731, 2.1109, 2.6253, 2.6458, 3.1792, 2.3662, 2.9563, 2.5534,\n",
      "        3.6706, 2.4945, 3.0791, 2.2953, 2.7153, 3.2815, 2.2885, 2.4486, 2.0401,\n",
      "        3.1391, 2.0504, 3.0785, 2.2818, 2.9539, 2.3042, 2.9556, 2.9958, 1.6933,\n",
      "        2.8548, 2.2854, 2.5816, 3.0564, 2.0341, 2.3031, 2.5163, 2.3943, 2.1332,\n",
      "        2.5911, 2.6126, 2.3571, 2.4486, 1.9534, 3.2738, 2.5618, 2.5262, 2.7043,\n",
      "        2.9916, 3.1165, 2.2164, 3.1818, 2.5545, 2.2131, 3.1386, 3.0965, 2.8530,\n",
      "        1.9496, 2.5144, 2.0527, 2.6682, 2.6472, 2.7935, 2.5063, 3.1373, 3.1121,\n",
      "        2.6312, 2.4272, 2.1223, 2.9568, 2.5563, 2.5324, 3.5180, 2.0442, 2.8928,\n",
      "        3.0702, 2.2025, 2.4208, 3.1787, 2.5664, 2.6002, 2.0378, 2.5944, 2.5660,\n",
      "        2.8763, 2.4492, 2.1314, 3.1454, 2.7629, 3.0102, 3.0103, 2.5855, 2.3826,\n",
      "        2.2292, 2.7869, 2.7408, 1.9706, 2.4204, 2.4976, 3.1486, 2.0788, 2.7363,\n",
      "        2.4180, 2.0303, 2.9344, 2.0718, 2.6562, 3.4177, 3.0537, 2.7972, 2.2466,\n",
      "        3.6124, 3.4383, 1.8691, 2.8081, 2.1992, 2.7259, 1.9714, 2.4989, 2.9801,\n",
      "        3.0282, 2.6700, 2.6769, 2.3750, 2.2532, 3.5080, 2.4676, 2.6120, 2.4669,\n",
      "        2.5763, 2.6182, 3.6755, 2.8927, 2.4527, 1.9694, 3.1698, 2.4372],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(bounds_affine_out[1][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounds affine out \n",
      " tensor([2.1985, 2.2024, 3.5789, 3.2989, 3.1727, 2.7257, 3.1588, 2.9706, 2.3492,\n",
      "        2.3374, 2.2188, 3.5131, 2.9834, 3.2893, 2.7698, 2.7456, 3.0551, 2.7703,\n",
      "        2.4261, 2.7636, 2.3316, 2.5707, 3.1093, 2.7213, 3.2009, 2.8840, 2.6372,\n",
      "        3.2359, 2.7661, 3.7934, 1.9150, 3.2887, 2.6867, 3.5916, 2.4751, 3.0572,\n",
      "        2.5368, 2.8881, 2.4758, 2.3353, 2.7308, 2.2997, 2.9015, 2.8642, 2.6307,\n",
      "        2.6679, 2.1138, 2.7184, 2.5877, 2.4363, 2.8510, 2.2290, 2.7605, 2.9352,\n",
      "        2.5532, 2.4591, 2.0163, 3.2752, 2.3035, 2.7828, 2.5608, 2.5729, 2.1703,\n",
      "        2.6810, 2.4530, 2.5627, 2.7323, 3.0748, 2.3498, 3.0908, 2.9539, 2.4527,\n",
      "        2.4962, 2.8960, 2.6532, 2.6162, 2.2160, 3.6041, 3.0032, 2.8227, 2.6230,\n",
      "        3.2652, 2.3000, 2.5879, 2.6289, 3.2825, 2.4289, 3.2062, 2.0722, 2.9592,\n",
      "        2.0333, 2.4219, 2.9470, 3.5575, 2.5283, 2.6129, 2.5972, 2.9534, 2.9723,\n",
      "        2.5614, 2.8972, 2.7913, 2.9018, 1.8760, 3.3864, 3.4564, 2.7306, 3.0458,\n",
      "        2.2486, 3.0729, 2.5512, 2.5311, 2.8378, 2.2285, 3.0569, 2.5264, 2.6175,\n",
      "        2.5961, 2.5296, 2.6409, 2.6287, 2.5965, 2.9409, 2.4046, 2.7446, 2.3342,\n",
      "        2.9047, 2.5440, 3.0772, 1.9716, 2.1576, 2.7586, 2.4789, 2.6533, 2.2112,\n",
      "        1.8408, 2.9815, 2.7088, 2.7785, 2.7992, 3.3071, 3.1239, 2.4893, 3.1774,\n",
      "        2.4032, 2.8245, 2.6077, 3.3692, 2.4308, 2.2467, 1.9323, 2.7972, 2.7219,\n",
      "        3.2780, 2.9485, 1.9737, 2.9057, 3.7385, 3.2042, 2.6872, 2.8178, 2.6759,\n",
      "        2.4202, 2.7386, 2.2116, 2.8576, 3.0162, 2.2776, 3.1711, 2.4163, 3.9645,\n",
      "        2.4481, 2.7093, 2.1543, 2.6305, 2.5179, 2.1667, 2.6047, 2.6598, 2.0520,\n",
      "        3.2499, 2.4984, 3.2387, 1.9903, 2.1779, 2.6996, 3.1078, 3.0683, 2.8121,\n",
      "        2.5086, 2.6226, 2.2937, 2.8322, 2.4843, 2.4434, 2.6395, 2.6338, 2.3789,\n",
      "        2.7651, 2.4555, 2.8191, 2.7082, 1.9177, 1.8043, 2.0851, 2.5194, 2.5843,\n",
      "        2.2937, 2.0311, 2.0399, 2.4141, 2.8709, 2.6827, 3.2072, 2.4175, 2.9141,\n",
      "        2.7656, 2.7763, 2.8114, 2.5082, 1.9327, 2.6724, 2.2971, 2.3961, 2.4524,\n",
      "        2.7674, 2.5349, 3.2752, 2.6632, 2.7877, 2.4443, 2.6509, 2.4466, 2.1202,\n",
      "        2.9781, 2.3353, 2.5709, 2.1044, 2.5156, 2.9475, 3.4756, 2.5669, 2.3189,\n",
      "        2.3897, 2.2457, 3.0801, 3.5114, 2.4983, 2.5862, 2.5761, 3.1905, 2.3847,\n",
      "        2.0487, 2.6575, 2.6359, 3.1154, 2.4759, 2.8485, 3.0165, 2.8262, 2.6906,\n",
      "        2.8355, 2.7099, 2.5992, 1.6763, 2.7652, 2.6295, 2.3402, 2.8419, 2.9079,\n",
      "        2.4964, 2.8957, 2.8146, 2.8652, 2.3430, 2.9373, 1.6113, 2.4700, 1.9122,\n",
      "        2.3025, 2.5531, 2.2747, 2.6465, 2.9438, 2.1805, 2.2151, 3.0780, 2.2498,\n",
      "        2.4682, 2.1720, 1.9502, 2.3754, 3.0590, 2.9243, 2.5663, 2.1819, 1.9129,\n",
      "        2.4948, 2.9328, 2.1700, 2.6950, 2.9161, 3.1480, 2.9733, 2.6979, 1.7689,\n",
      "        2.1127, 2.9371, 2.5969, 3.9292, 3.1885, 2.4670, 2.7131, 2.7215, 2.7180,\n",
      "        2.5085, 3.2214, 3.0689, 3.8328, 2.5023, 2.7256, 2.1245, 2.3074, 2.0151,\n",
      "        2.5359, 2.9857, 2.3858, 2.7070, 2.9559, 2.5780, 2.9495, 2.1060, 2.3754,\n",
      "        2.7490, 2.9435, 2.4471, 2.6938, 2.2222, 2.7023, 2.6875, 2.6380, 2.3804,\n",
      "        2.8629, 2.6581, 2.5343, 2.1080, 3.1665, 2.9870, 2.4671, 3.0791, 2.9258,\n",
      "        2.0098, 2.9876, 2.4583, 3.1908, 1.8993, 2.4326, 3.2954, 2.3088, 2.7669,\n",
      "        2.3705, 2.6104, 2.2965, 2.8599, 3.0404, 3.1265, 2.3486, 2.6209, 2.5314,\n",
      "        2.9598, 2.1777, 3.2833, 2.4826, 2.1495, 2.1120, 2.6329, 2.0196, 2.5830,\n",
      "        2.9953, 2.7731, 2.1109, 2.6253, 2.6458, 3.1792, 2.3662, 2.9563, 2.5534,\n",
      "        3.6706, 2.4945, 3.0791, 2.2953, 2.7153, 3.2815, 2.2885, 2.4486, 2.0401,\n",
      "        3.1391, 2.0504, 3.0785, 2.2818, 2.9539, 2.3042, 2.9556, 2.9958, 1.6933,\n",
      "        2.8548, 2.2854, 2.5816, 3.0564, 2.0341, 2.3031, 2.5163, 2.3943, 2.1332,\n",
      "        2.5911, 2.6126, 2.3571, 2.4486, 1.9534, 3.2738, 2.5618, 2.5262, 2.7043,\n",
      "        2.9916, 3.1165, 2.2164, 3.1818, 2.5545, 2.2131, 3.1386, 3.0965, 2.8530,\n",
      "        1.9496, 2.5144, 2.0527, 2.6682, 2.6472, 2.7935, 2.5063, 3.1373, 3.1121,\n",
      "        2.6312, 2.4272, 2.1223, 2.9568, 2.5563, 2.5324, 3.5180, 2.0442, 2.8928,\n",
      "        3.0702, 2.2025, 2.4208, 3.1787, 2.5664, 2.6002, 2.0378, 2.5944, 2.5660,\n",
      "        2.8763, 2.4492, 2.1314, 3.1454, 2.7629, 3.0102, 3.0103, 2.5855, 2.3826,\n",
      "        2.2292, 2.7869, 2.7408, 1.9706, 2.4204, 2.4976, 3.1486, 2.0788, 2.7363,\n",
      "        2.4180, 2.0303, 2.9344, 2.0718, 2.6562, 3.4177, 3.0537, 2.7972, 2.2466,\n",
      "        3.6124, 3.4383, 1.8691, 2.8081, 2.1992, 2.7259, 1.9714, 2.4989, 2.9801,\n",
      "        3.0282, 2.6700, 2.6769, 2.3750, 2.2532, 3.5080, 2.4676, 2.6120, 2.4669,\n",
      "        2.5763, 2.6182, 3.6755, 2.8927, 2.4527, 1.9694, 3.1698, 2.4372],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_flattened = torch.flatten(test_image)\n",
    "bounds_affine_out, bounds_layer_out = nn.calculate_box_bounds([input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "print(bounds_affine_out[1][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dhov_model = icnn_model(icnns[layer_index][0], nn, test_image, eps, layer_index, 0, group_size, print_log=False)\n",
    "dhov_model.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "icnn_neuron_name = \"icnn_var[{}]\".format(neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dhov_copy = dhov_model.copy()\n",
    "dhov_copy.Params.LogToConsole = 0\n",
    "add_min_constr(dhov_copy, icnn_neuron_name)\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dhov_copy = dhov_model.copy()\n",
    "dhov_copy.Params.LogToConsole = 0\n",
    "add_max_constr(dhov_copy, icnn_neuron_name)\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for SNV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "snv_verifier = SingleNeuronVerifier(nn, test_image, eps, print_log=False)\n",
    "snv_verifier.generate_constraints_for_net()\n",
    "snv_model = snv_verifier.model\n",
    "snv_model.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "snv_copy = snv_model.copy()\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "add_min_constr(snv_copy, neuron_name)\n",
    "optimize_model(snv_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 1.2794941959311528\n"
     ]
    }
   ],
   "source": [
    "snv_copy = snv_model.copy()\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "add_max_constr(snv_copy, neuron_name)\n",
    "optimize_model(snv_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for MILP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-11-12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m neuron_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrelu_var\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m[\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39mlayer_index, \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m      2\u001B[0m milp_verifier \u001B[38;5;241m=\u001B[39m MILPVerifier(nn, test_image, eps, print_log\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mmilp_verifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_constraints_for_net\u001B[49m\u001B[43m(\u001B[49m\u001B[43muntil_layer_neuron\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mlayer_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mneuron_index\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m milp_model \u001B[38;5;241m=\u001B[39m milp_verifier\u001B[38;5;241m.\u001B[39mmodel\n\u001B[0;32m      5\u001B[0m milp_model\u001B[38;5;241m.\u001B[39mupdate()\n",
      "File \u001B[1;32m~\\Documents\\Programming\\ICNN_verification\\script\\Verification\\Verifier.py:199\u001B[0m, in \u001B[0;36mMILPVerifier.generate_constraints_for_net\u001B[1;34m(self, until_layer_neuron)\u001B[0m\n\u001B[0;32m    197\u001B[0m out_fet \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(b)\n\u001B[0;32m    198\u001B[0m out_vars \u001B[38;5;241m=\u001B[39m m\u001B[38;5;241m.\u001B[39maddMVar(out_fet, lb\u001B[38;5;241m=\u001B[39min_lb, ub\u001B[38;5;241m=\u001B[39min_ub, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maffine_var\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(i))\n\u001B[1;32m--> 199\u001B[0m const \u001B[38;5;241m=\u001B[39m \u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maddConstrs\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mW\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[43min_var\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mout_vars\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mW\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    201\u001B[0m relu_in_var \u001B[38;5;241m=\u001B[39m out_vars\n\u001B[0;32m    202\u001B[0m out_lb \u001B[38;5;241m=\u001B[39m bounds_layer_out[\u001B[38;5;28mint\u001B[39m(i \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m)][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[1;32msrc\\gurobipy\\model.pxi:3747\u001B[0m, in \u001B[0;36mgurobipy.Model.addConstrs\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\Documents\\Programming\\ICNN_verification\\script\\Verification\\Verifier.py:199\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    197\u001B[0m out_fet \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(b)\n\u001B[0;32m    198\u001B[0m out_vars \u001B[38;5;241m=\u001B[39m m\u001B[38;5;241m.\u001B[39maddMVar(out_fet, lb\u001B[38;5;241m=\u001B[39min_lb, ub\u001B[38;5;241m=\u001B[39min_ub, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maffine_var\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(i))\n\u001B[1;32m--> 199\u001B[0m const \u001B[38;5;241m=\u001B[39m m\u001B[38;5;241m.\u001B[39maddConstrs((\u001B[43mW\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[43min_var\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mout_vars\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(W))))\n\u001B[0;32m    201\u001B[0m relu_in_var \u001B[38;5;241m=\u001B[39m out_vars\n\u001B[0;32m    202\u001B[0m out_lb \u001B[38;5;241m=\u001B[39m bounds_layer_out[\u001B[38;5;28mint\u001B[39m(i \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m)][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[1;32msrc\\gurobipy\\mlinexpr.pxi:2195\u001B[0m, in \u001B[0;36mgurobipy.MLinExpr.__eq__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32msrc\\gurobipy\\tempconstr.pxi:22\u001B[0m, in \u001B[0;36mgurobipy.TempConstr.__init__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32msrc\\gurobipy\\mlinexpr.pxi:1385\u001B[0m, in \u001B[0;36mgurobipy.MLinExpr.__sub__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32msrc\\gurobipy\\mlinexpr.pxi:891\u001B[0m, in \u001B[0;36mgurobipy.MLinExpr.__add__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32msrc\\gurobipy\\mlinexpr.pxi:983\u001B[0m, in \u001B[0;36mgurobipy.MLinExpr._add_compact_mlinexpr\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32msrc\\gurobipy\\mlinexpr.pxi:1026\u001B[0m, in \u001B[0;36mgurobipy.MLinExpr._add_compact_mlinexpr_compact\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\torchCPU\\lib\\site-packages\\scipy\\sparse\\_construct.py:532\u001B[0m, in \u001B[0;36mhstack\u001B[1;34m(blocks, format, dtype)\u001B[0m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhstack\u001B[39m(blocks, \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    503\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    504\u001B[0m \u001B[38;5;124;03m    Stack sparse matrices horizontally (column wise)\u001B[39;00m\n\u001B[0;32m    505\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    530\u001B[0m \n\u001B[0;32m    531\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbmat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mblocks\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\torchCPU\\lib\\site-packages\\scipy\\sparse\\_construct.py:624\u001B[0m, in \u001B[0;36mbmat\u001B[1;34m(blocks, format, dtype)\u001B[0m\n\u001B[0;32m    620\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mformat\u001B[39m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(b, csr_matrix)\n\u001B[0;32m    621\u001B[0m                                     \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m blocks\u001B[38;5;241m.\u001B[39mflat)):\n\u001B[0;32m    622\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m N \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    623\u001B[0m         \u001B[38;5;66;03m# stack along columns (axis 1):\u001B[39;00m\n\u001B[1;32m--> 624\u001B[0m         blocks \u001B[38;5;241m=\u001B[39m [[_stack_along_minor_axis(blocks[b, :], \u001B[38;5;241m1\u001B[39m)]\n\u001B[0;32m    625\u001B[0m                   \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(M)]   \u001B[38;5;66;03m# must have shape: (M, 1)\u001B[39;00m\n\u001B[0;32m    626\u001B[0m         blocks \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(blocks, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobject\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# stack along rows (axis 0):\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\torchCPU\\lib\\site-packages\\scipy\\sparse\\_construct.py:624\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    620\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mformat\u001B[39m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(b, csr_matrix)\n\u001B[0;32m    621\u001B[0m                                     \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m blocks\u001B[38;5;241m.\u001B[39mflat)):\n\u001B[0;32m    622\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m N \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    623\u001B[0m         \u001B[38;5;66;03m# stack along columns (axis 1):\u001B[39;00m\n\u001B[1;32m--> 624\u001B[0m         blocks \u001B[38;5;241m=\u001B[39m [[\u001B[43m_stack_along_minor_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblocks\u001B[49m\u001B[43m[\u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m]\n\u001B[0;32m    625\u001B[0m                   \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(M)]   \u001B[38;5;66;03m# must have shape: (M, 1)\u001B[39;00m\n\u001B[0;32m    626\u001B[0m         blocks \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(blocks, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobject\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# stack along rows (axis 0):\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\torchCPU\\lib\\site-packages\\scipy\\sparse\\_construct.py:486\u001B[0m, in \u001B[0;36m_stack_along_minor_axis\u001B[1;34m(blocks, axis)\u001B[0m\n\u001B[0;32m    484\u001B[0m     indices \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mempty_like(indices_cat)\n\u001B[0;32m    485\u001B[0m     data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mempty_like(data_cat)\n\u001B[1;32m--> 486\u001B[0m     \u001B[43mcsr_hstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_blocks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconstant_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstack_dim_cat\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    487\u001B[0m \u001B[43m               \u001B[49m\u001B[43mindptr_cat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices_cat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_cat\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m               \u001B[49m\u001B[43mindptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    490\u001B[0m     indptr \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(constant_dim \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, dtype\u001B[38;5;241m=\u001B[39midx_dtype)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "neuron_name = \"relu_var{}[{}]\".format(2*layer_index, 0)\n",
    "milp_verifier = MILPVerifier(nn, test_image, eps, print_log=False)\n",
    "milp_verifier.generate_constraints_for_net(until_layer_neuron=[layer_index, neuron_index])\n",
    "milp_model = milp_verifier.model\n",
    "milp_model.update()\n",
    "\n",
    "\"\"\"all_var = milp_model.getVars()\n",
    "for var in all_var:\n",
    "    print(var)\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "milp_copy = milp_model.copy()\n",
    "milp_copy.Params.LogToConsole = 0\n",
    "add_min_constr(milp_copy, neuron_name)\n",
    "optimize_model(milp_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.5620409095272554\n"
     ]
    }
   ],
   "source": [
    "milp_copy = milp_model.copy()\n",
    "milp_copy.Params.LogToConsole = 0\n",
    "add_max_constr(milp_copy, neuron_name)\n",
    "optimize_model(milp_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}