{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from script.NeuralNets.Networks import SequentialNN, ICNN, ICNNApproxMax, ICNNLogical\n",
    "from script.settings import device, data_type\n",
    "import script.DHOV.MultiDHOV as multidhov\n",
    "from script.Verification.Verifier import SingleNeuronVerifier, MILPVerifier, DHOVVerifier\n",
    "import gurobipy as grp\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from script.NeuralNets.ICNNFactory import ICNNFactory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def add_max_constr(model, neuron_name):\n",
    "    neuron_var = model.getVarByName(neuron_name)\n",
    "    model.setObjective(neuron_var, grp.GRB.MAXIMIZE)\n",
    "\n",
    "def add_min_constr(model, neuron):\n",
    "    neuron_var = model.getVarByName(neuron)\n",
    "    model.setObjective(neuron_var, grp.GRB.MINIMIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def optimize_model(model, neuron_name):\n",
    "    model.update()\n",
    "    model.optimize()\n",
    "    if model.Status == grp.GRB.OPTIMAL:\n",
    "        print(\"opt value: {}\".format(model.getVarByName(neuron_name).getAttr(\"x\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def icnn_model(icnn, nn, input_x, eps, layer_index, from_neuron, to_neuron, print_log=False):\n",
    "    m = grp.Model()\n",
    "    if not print_log:\n",
    "        m.Params.LogToConsole = 0\n",
    "\n",
    "    input_flattened = torch.flatten(input_x)\n",
    "    bounds_affine_out, bounds_layer_out = nn.calculate_box_bounds(\n",
    "        [input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "\n",
    "    parameter_list = list(nn.parameters())\n",
    "\n",
    "    input_size = len(parameter_list[2*layer_index])\n",
    "    lb = bounds_layer_out[layer_index][0].detach().cpu().numpy()\n",
    "    ub = bounds_layer_out[layer_index][1].detach().cpu().numpy()\n",
    "    in_var = m.addMVar(input_size, lb=lb, ub=ub, name=\"icnn_var\")\n",
    "\n",
    "    low = bounds_layer_out[layer_index][0][from_neuron: to_neuron]\n",
    "    up = bounds_layer_out[layer_index][1][from_neuron: to_neuron]\n",
    "    constraint_bounds_affine_out, constraint_bounds_layer_out = icnn.calculate_box_bounds([low, up])\n",
    "    icnn.add_max_output_constraints(m, in_var[from_neuron: to_neuron], constraint_bounds_affine_out, constraint_bounds_layer_out)\n",
    "\n",
    "    return m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\"\"\"W1 = [1. 1.; 1. -1.]\n",
    "    b1 = [0., 0.]\n",
    "    W2 = [1. 1.; 1. -1.]\n",
    "    b2 = [-0.5, 0.]\n",
    "    W3 = [-1. 1.; 1. 1.]\n",
    "    b3 = [3., 0.] \"\"\"\n",
    "\n",
    "\"\"\"nn = SequentialNN([2, 2, 2, 2])\n",
    "\n",
    "with torch.no_grad():\n",
    "    parameter_list = list(nn.parameters())\n",
    "    parameter_list[0].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[1].data = torch.tensor([0, 0], dtype=data_type).to(device)\n",
    "    parameter_list[2].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[3].data = torch.tensor([-0.5, 0], dtype=data_type).to(device)\n",
    "    parameter_list[4].data = torch.tensor([[-1, 1], [1, 1]], dtype=data_type).to(device)\n",
    "    parameter_list[5].data = torch.tensor([3, 0], dtype=data_type).to(device)\n",
    "\n",
    "test_image = torch.tensor([[0, 0]], dtype=data_type).to(device)\"\"\"\n",
    "\n",
    "\"\"\"transform = Compose([ToTensor(),\n",
    "                         Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "                        )\n",
    "\n",
    "training_data = CIFAR10(root=\"../../cifar\", train=True, download=True, transform=transform)\n",
    "images, labels = training_data.__getitem__(0)\n",
    "test_image, test_label = torch.unsqueeze(images, 0).to(dtype=data_type).to(device), torch.unsqueeze(\n",
    "    torch.tensor(labels), 0).to(dtype=data_type).to(device)\n",
    "\n",
    "nn = SequentialNN([32 * 32 * 3, 1024, 512, 10])\n",
    "nn.load_state_dict(torch.load(\"../../cifar_fc.pth\", map_location=torch.device(device)), strict=False)\n",
    "parameter_list = list(nn.parameters())\"\"\"\n",
    "\n",
    "nn = SequentialNN([50, 50, 50, 7])\n",
    "test_image = torch.zeros((1, 50), dtype=data_type).to(device)\n",
    "parameter_list = list(nn.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "eps = 0.01\n",
    "layer_index = 1\n",
    "neuron_index = 0\n",
    "neuron_name = \"relu_var{}[{}]\".format(2*layer_index, neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for SNV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-11-12\n"
     ]
    }
   ],
   "source": [
    "snv_verifier = SingleNeuronVerifier(nn, test_image, eps, print_log=False)\n",
    "snv_verifier.generate_constraints_for_net()\n",
    "snv_model = snv_verifier.model\n",
    "snv_model.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "snv_copy = snv_model.copy()\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "add_min_constr(snv_copy, neuron_name)\n",
    "optimize_model(snv_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 1.2794941959311528\n"
     ]
    }
   ],
   "source": [
    "snv_copy = snv_model.copy()\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "add_max_constr(snv_copy, neuron_name)\n",
    "optimize_model(snv_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for MILP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'all_var = milp_model.getVars()\\nfor var in all_var:\\n    print(var)'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_name = \"relu_var{}[{}]\".format(2*layer_index, 0)\n",
    "milp_verifier = MILPVerifier(nn, test_image, eps, print_log=False)\n",
    "milp_verifier.generate_constraints_for_net(until_layer_neuron=[layer_index, neuron_index])\n",
    "milp_model = milp_verifier.model\n",
    "milp_model.update()\n",
    "\n",
    "\"\"\"all_var = milp_model.getVars()\n",
    "for var in all_var:\n",
    "    print(var)\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "milp_copy = milp_model.copy()\n",
    "milp_copy.Params.LogToConsole = 0\n",
    "add_min_constr(milp_copy, neuron_name)\n",
    "optimize_model(milp_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.5620409095272554\n"
     ]
    }
   ],
   "source": [
    "milp_copy = milp_model.copy()\n",
    "milp_copy.Params.LogToConsole = 0\n",
    "add_max_constr(milp_copy, neuron_name)\n",
    "optimize_model(milp_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for DHOV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "approximation of layer: 0\n",
      "    number of fixed neurons for current layer: 33\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-11-12\n",
      "    layer progress, group 1 of 6 \n",
      "        time for training: 0.08463048934936523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ufuk\\Documents\\Programming\\ICNN_verification\\script\\Optimizer\\sdlbfgs.py:83: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1420.)\n",
      "  p.data.add_(step_size, update[offset:offset + numel].view_as(p.data))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        actual verification time 0.01563429832458496\n",
      "        time for verification: 0.21597766876220703\n",
      "        lower 0.0\n",
      "        upper 0.03829004615545273\n",
      "        lower 0.0\n",
      "        upper 0.014630567282438278\n",
      "        lower 0.0\n",
      "        upper 0.055084407329559326\n",
      "    layer progress, group 2 of 6 \n",
      "        time for training: 0.062050580978393555\n",
      "        actual verification time 0.00201416015625\n",
      "        time for verification: 0.16524648666381836\n",
      "        lower 0.0\n",
      "        upper 0.02521830129817282\n",
      "        lower 0.0\n",
      "        upper 0.006415143609046936\n",
      "        lower 0.0\n",
      "        upper 0.04361312035566126\n",
      "    layer progress, group 3 of 6 \n",
      "        time for training: 0.05032706260681152\n",
      "        actual verification time 0.010158300399780273\n",
      "        time for verification: 0.16325163841247559\n",
      "        lower 0.0\n",
      "        upper 0.026150763034820557\n",
      "        lower 0.0\n",
      "        upper 0.031326234340667725\n",
      "        lower 0.0\n",
      "        upper 0.0026340633630752563\n",
      "    layer progress, group 4 of 6 \n",
      "        time for training: 0.060476064682006836\n",
      "        actual verification time 0.010076761245727539\n",
      "        time for verification: 0.19139504432678223\n",
      "        lower 0.0\n",
      "        upper 6.452202796936035e-05\n",
      "        lower 0.0\n",
      "        upper 0.00866701826453209\n",
      "        lower 0.0\n",
      "        upper 0.048169467598199844\n",
      "    layer progress, group 5 of 6 \n",
      "        time for training: 0.051854848861694336\n",
      "        actual verification time 0.008020877838134766\n",
      "        time for verification: 0.20970511436462402\n",
      "        lower 0.0\n",
      "        upper 0.0046008192002773285\n",
      "        lower 0.0\n",
      "        upper 0.058007244020700455\n",
      "        lower 0.0\n",
      "        upper 0.05706323792718865\n",
      "    layer progress, group 6 of 6 \n",
      "        time for training: 0.06049823760986328\n",
      "        actual verification time 0.0\n",
      "        time for verification: 0.17348766326904297\n",
      "        lower 0.0\n",
      "        upper 0.04014357924461365\n",
      "        lower 0.0\n",
      "        upper 0.004203774034976959\n",
      "        lower 0.0\n",
      "        upper 0.03829004615545273\n",
      "        lower 0.0\n",
      "        upper 0.014630567282438278\n",
      "        lower 0.0\n",
      "        upper 0.055084407329559326\n",
      "        lower 0.0\n",
      "        upper 0.02521830129817282\n",
      "        lower 0.0\n",
      "        upper 0.006415143609046936\n",
      "        lower 0.0\n",
      "        upper 0.04361312035566126\n",
      "        lower 0.0\n",
      "        upper 0.026150763034820557\n",
      "        lower 0.0\n",
      "        upper 0.031326234340667725\n",
      "        lower 0.0\n",
      "        upper 0.0026340633630752563\n",
      "        lower 0.0\n",
      "        upper 6.452202796936035e-05\n",
      "        lower 0.0\n",
      "        upper 0.00866701826453209\n",
      "        lower 0.0\n",
      "        upper 0.048169467598199844\n",
      "        lower 0.0\n",
      "        upper 0.0046008192002773285\n",
      "        lower 0.0\n",
      "        upper 0.058007244020700455\n",
      "        lower 0.0\n",
      "        upper 0.05706323683261871\n",
      "        lower 0.0\n",
      "        upper 0.04014357924461365\n",
      "        lower 0.0\n",
      "        upper 0.004203774034976959\n",
      "    time for icnn_bound calculation: 0.5094056129455566\n",
      "included space num samples 2, ambient space num samples 8\n",
      "    time for regrouping method: 94.46084690093994\n",
      "\n",
      "approximation of layer: 1\n",
      "    number of fixed neurons for current layer: 31\n",
      "    layer progress, group 1 of 7 \n",
      "        time for training: 0.04687309265136719\n",
      "        actual verification time 0.030240535736083984\n",
      "        time for verification: 0.17032718658447266\n",
      "        lower 0.0\n",
      "        upper 0.012663182188331389\n",
      "        lower 0.0\n",
      "        upper 0.08393801277391319\n",
      "        lower 0.0\n",
      "        upper 0.09931915825477601\n",
      "    layer progress, group 2 of 7 \n",
      "        time for training: 0.0624384880065918\n",
      "        actual verification time 0.030680179595947266\n",
      "        time for verification: 0.1918327808380127\n",
      "        lower 0.0\n",
      "        upper 0.09896085486655304\n",
      "        lower 0.0\n",
      "        upper 0.06048726290464401\n",
      "        lower 0.0\n",
      "        upper 0.010980188846588135\n",
      "    layer progress, group 3 of 7 \n",
      "        time for training: 0.06039714813232422\n",
      "        actual verification time 0.03039264678955078\n",
      "        time for verification: 0.18152546882629395\n",
      "        lower 0.0\n",
      "        upper 0.03717361124187646\n",
      "        lower 0.0\n",
      "        upper 0.09330923551169461\n",
      "        lower 0.0\n",
      "        upper 0.0030637457966804504\n",
      "    layer progress, group 4 of 7 \n",
      "        time for training: 0.060454368591308594\n",
      "        actual verification time 0.01812005043029785\n",
      "        time for verification: 0.19945168495178223\n",
      "        lower 0.0\n",
      "        upper 0.0867139995098114\n",
      "        lower 0.0\n",
      "        upper 0.015951357781887054\n",
      "        lower 0.0\n",
      "        upper 0.08452668786048889\n",
      "    layer progress, group 5 of 7 \n",
      "        time for training: 0.05028700828552246\n",
      "        actual verification time 0.012113094329833984\n",
      "        time for verification: 0.17127323150634766\n",
      "        lower 0.0\n",
      "        upper 0.015287473797798157\n",
      "        lower 0.0\n",
      "        upper 0.02701589534322319\n",
      "        lower 0.0\n",
      "        upper 0.06929492950439453\n",
      "    layer progress, group 6 of 7 \n",
      "        time for training: 0.07888293266296387\n",
      "        actual verification time 0.02023625373840332\n",
      "        time for verification: 0.18158364295959473\n",
      "        lower 0.0\n",
      "        upper 0.018851548433303833\n",
      "        lower 0.0\n",
      "        upper 0.06481449985816364\n",
      "        lower 0.0\n",
      "        upper 0.07815404709603893\n",
      "    layer progress, group 7 of 7 \n",
      "        time for training: 0.05230259895324707\n",
      "        actual verification time 0.0\n",
      "        time for verification: 0.13115620613098145\n",
      "        lower 0.0\n",
      "        upper 0.1101540721020316\n",
      "        lower 0.0\n",
      "        upper 0.012663181871175766\n",
      "        lower 0.0\n",
      "        upper 0.08393801003694534\n",
      "        lower 0.0\n",
      "        upper 0.09931915825477601\n",
      "        lower 0.0\n",
      "        upper 0.09896085411310196\n",
      "        lower 0.0\n",
      "        upper 0.06048726290464401\n",
      "        lower 0.0\n",
      "        upper 0.010980188846588135\n",
      "        lower 0.0\n",
      "        upper 0.03717361018061638\n",
      "        lower 0.0\n",
      "        upper 0.09330923551169461\n",
      "        lower 0.0\n",
      "        upper 0.0030637457966804504\n",
      "        lower 0.0\n",
      "        upper 0.0867139995098114\n",
      "        lower 0.0\n",
      "        upper 0.015951357781887054\n",
      "        lower 0.0\n",
      "        upper 0.08452668786048889\n",
      "        lower 0.0\n",
      "        upper 0.015287473797798157\n",
      "        lower 0.0\n",
      "        upper 0.027015894044384984\n",
      "        lower 0.0\n",
      "        upper 0.06929492950439453\n",
      "        lower 0.0\n",
      "        upper 0.018851548433303833\n",
      "        lower 0.0\n",
      "        upper 0.06481449985816364\n",
      "        lower 0.0\n",
      "        upper 0.07815404709603893\n",
      "        lower 0.0\n",
      "        upper 0.11015406790851852\n",
      "    time for icnn_bound calculation: 0.5983273983001709\n",
      "included space num samples 0, ambient space num samples 10\n",
      "    time for regrouping method: 1.2036378383636475\n"
     ]
    }
   ],
   "source": [
    "group_size = 3\n",
    "icnn_factory = ICNNFactory(\"logical\", [5, 5, 1], force_positive_init=False, with_two_layers=False,\n",
    "                               init_scaling=10, init_all_with_zeros=False)\n",
    "#icnn_factory = ICNNFactory(\"standard\", [5, 5, 1])\n",
    "\n",
    "icnns, all_group_indices, fixed_neuron_per_layer_lower, fixed_neuron_per_layer_upper, bounds_affine_out, bounds_layer_out = \\\n",
    "    multidhov.start_verification(nn, test_image, icnn_factory, group_size, eps=eps, icnn_epochs=10, icnn_batch_size=1000,\n",
    "                                 sample_count=10, sample_new=True, use_over_approximation=True, break_after=152,\n",
    "                                 sample_over_input_space=False, sample_over_output_space=True, use_icnn_bounds=True, use_fixed_neurons=True,\n",
    "                                 force_inclusion_steps=0, preemptive_stop=False, even_gradient_training=False,\n",
    "                                 keep_ambient_space=True, data_grad_descent_steps=0, train_outer=False,\n",
    "                                 should_plot=\"none\", optimizer=\"SdLBFGS\", init_network=True, adapt_lambda=\"none\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([ 0.2088,  0.0196, -0.0026,  ..., -1.3163, -0.3677, -0.2236],\n",
      "       grad_fn=<AddBackward0>), tensor([ 0.7791,  0.5886,  0.5620,  ..., -0.7273,  0.2118,  0.3357],\n",
      "       grad_fn=<AddBackward0>)]]\n"
     ]
    }
   ],
   "source": [
    "print(bounds_affine_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounds affine out \n",
      " [[tensor([ 0.2088,  0.0196, -0.0026,  ..., -1.3163, -0.3677, -0.2236],\n",
      "       grad_fn=<AddBackward0>), tensor([ 0.7791,  0.5886,  0.5620,  ..., -0.7273,  0.2118,  0.3357],\n",
      "       grad_fn=<AddBackward0>)], [tensor([-2.3678, -2.2506, -1.4631, -1.5480, -1.6997, -2.3157, -2.0312, -2.1657,\n",
      "        -2.4451, -2.1094, -2.5736, -1.5114, -1.7204, -1.6585, -1.9900, -2.2936,\n",
      "        -1.8326, -1.9801, -2.0940, -1.9852, -2.4245, -2.3254, -1.7885, -2.0473,\n",
      "        -1.7248, -2.0310, -2.1796, -1.5130, -2.1948, -1.2174, -2.3810, -1.6069,\n",
      "        -2.2250, -1.0840, -2.1734, -1.6119, -2.2030, -2.1282, -2.2584, -2.3525,\n",
      "        -1.9250, -2.2268, -1.9972, -1.8989, -2.1081, -1.8777, -2.4823, -2.0515,\n",
      "        -2.2419, -2.3808, -2.0566, -2.1669, -1.8904, -2.0341, -2.4128, -2.7350,\n",
      "        -2.8463, -1.6933, -2.4030, -2.0562, -1.9528, -2.1218, -2.4711, -2.3628,\n",
      "        -2.2642, -2.0658, -1.8225, -1.7588, -2.5546, -1.6129, -1.8245, -2.1414,\n",
      "        -1.9952, -1.9148, -2.2306, -2.0037, -2.5366, -1.4191, -2.1562, -1.9158,\n",
      "        -2.1424, -1.8178, -2.2539, -2.0352, -2.1833, -1.5824, -2.2810, -1.4759,\n",
      "        -2.3608, -1.8562, -2.4729, -2.1235, -2.2414, -1.7541, -2.2816, -2.0879,\n",
      "        -2.0146, -1.8970, -2.4248, -2.0457, -1.6711, -2.2117, -1.8608, -2.7619,\n",
      "        -1.7872, -1.3919, -1.9690, -1.9393, -2.2661, -1.6468, -2.1895, -2.1893,\n",
      "        -1.9798, -2.1747, -1.8322, -2.2181, -2.1823, -1.9345, -2.2441, -1.9113,\n",
      "        -2.1066, -2.3348, -1.8618, -2.3357, -1.8482, -2.2501, -2.1368, -1.9601,\n",
      "        -1.7689, -2.5784, -2.6144, -2.2968, -2.0712, -2.2545, -2.4273, -2.6481,\n",
      "        -1.8894, -2.2630, -1.9883, -1.8003, -1.3780, -1.8716, -2.0415, -2.0463,\n",
      "        -2.5830, -2.0505, -1.8829, -1.3248, -2.2755, -2.2885, -2.6692, -2.1592,\n",
      "        -1.9485, -1.7881, -1.9013, -2.4198, -1.8273, -1.7009, -1.7606, -1.8754,\n",
      "        -1.7755, -1.9315, -2.2627, -2.0458, -2.3787, -1.7453, -2.1708, -2.3769,\n",
      "        -1.7394, -2.0193, -1.3378, -2.1757, -1.9578, -2.4132, -2.0921, -2.1697,\n",
      "        -2.3222, -2.1388, -1.9731, -2.4500, -1.7567, -2.0712, -1.8797, -2.4587,\n",
      "        -2.4394, -2.0947, -1.4238, -1.6812, -2.0884, -2.0478, -2.1802, -2.1793,\n",
      "        -1.7242, -2.2525, -2.0815, -2.1800, -2.2343, -2.2170, -2.2868, -2.3326,\n",
      "        -2.0985, -1.9025, -2.6216, -2.6766, -2.8230, -2.0409, -1.9765, -2.5223,\n",
      "        -2.5186, -2.3216, -2.1099, -1.8069, -1.8001, -1.8937, -2.3844, -1.5554,\n",
      "        -1.7413, -1.9307, -1.7702, -2.1569, -2.5157, -1.9025, -2.8545, -2.3963,\n",
      "        -1.9962, -2.0257, -2.0677, -1.7343, -1.7432, -1.9814, -2.0761, -1.9112,\n",
      "        -1.9711, -2.5830, -1.7412, -2.0081, -1.8990, -2.3547, -1.9318, -1.6319,\n",
      "        -1.3847, -2.1291, -2.3581, -2.3676, -2.3591, -1.6119, -1.5264, -2.2582,\n",
      "        -1.9452, -2.0983, -1.5434, -2.4950, -2.3965, -2.1024, -2.1247, -2.0916,\n",
      "        -2.4071, -1.6716, -2.2409, -2.0783, -1.9699, -1.7985, -1.9317, -1.9193,\n",
      "        -2.8491, -2.1171, -2.0579, -2.2669, -1.9235, -1.8752, -2.1481, -1.7179,\n",
      "        -2.2722, -2.0011, -2.3476, -1.9064, -2.6052, -1.9573, -2.5701, -2.5449,\n",
      "        -2.2295, -2.4069, -1.8491, -1.6295, -2.2801, -2.3843, -1.8899, -2.2901,\n",
      "        -2.2081, -2.2685, -2.5606, -2.3657, -2.0694, -1.8586, -2.1898, -2.7850,\n",
      "        -2.6666, -2.2256, -1.8080, -2.3675, -2.0387, -1.7699, -1.7594, -1.9638,\n",
      "        -1.7930, -2.5955, -2.2309, -2.1528, -2.1117, -1.1386, -1.7030, -2.1813,\n",
      "        -2.1974, -2.0460, -2.0127, -2.1019, -1.7086, -1.7625, -1.2394, -1.9954,\n",
      "        -2.0407, -2.5292, -2.1938, -2.6148, -1.9193, -1.8724, -2.0353, -1.8261,\n",
      "        -1.7046, -1.8707, -1.7427, -2.3210, -2.0953, -2.0234, -1.8730, -1.9157,\n",
      "        -2.1633, -2.2956, -1.8241, -1.9183, -1.9252, -2.2855, -1.7693, -2.0694,\n",
      "        -2.2078, -2.2395, -1.8100, -1.8931, -2.4937, -1.6027, -1.7344, -2.4556,\n",
      "        -1.7214, -2.1970, -1.7753, -2.5441, -2.1143, -1.7223, -2.5505, -1.8186,\n",
      "        -2.3532, -1.9206, -2.3041, -2.0582, -1.8424, -1.8498, -2.1913, -2.2310,\n",
      "        -2.1394, -2.0301, -2.6459, -1.6225, -2.2951, -2.5787, -2.3691, -2.5596,\n",
      "        -2.5056, -2.1484, -1.7632, -2.2438, -2.3388, -2.1026, -2.3081, -1.9033,\n",
      "        -2.3444, -1.8191, -1.9034, -1.3551, -2.2204, -1.6438, -2.2685, -1.7940,\n",
      "        -1.6682, -2.2030, -2.1190, -2.3994, -2.0798, -2.8044, -1.7596, -2.6453,\n",
      "        -1.6814, -2.1698, -1.7821, -1.6353, -2.7215, -1.7791, -2.2148, -2.1106,\n",
      "        -1.8514, -2.5462, -2.1293, -1.9078, -2.0379, -2.4073, -2.1459, -2.1028,\n",
      "        -2.7059, -2.1078, -2.5884, -1.8202, -2.0828, -2.1631, -2.0025, -1.8010,\n",
      "        -1.8327, -2.1799, -1.9555, -1.9659, -2.4192, -1.6459, -1.8146, -1.9345,\n",
      "        -2.6203, -1.9685, -2.5791, -2.2627, -2.0145, -1.9692, -2.2245, -1.6481,\n",
      "        -1.9672, -2.0471, -2.0556, -2.2650, -2.1470, -2.2929, -2.2956, -1.7933,\n",
      "        -2.4848, -1.8552, -1.7188, -2.2088, -2.2806, -1.4828, -1.8546, -2.1495,\n",
      "        -2.3400, -2.2611, -1.9456, -2.0526, -2.1521, -2.4529, -1.5742, -2.0786,\n",
      "        -1.8988, -1.7005, -2.1786, -2.0611, -2.4032, -1.8272, -2.2149, -2.3349,\n",
      "        -2.3801, -2.3148, -1.7153, -2.4166, -1.9706, -2.0655, -2.4320, -1.9155,\n",
      "        -2.3920, -2.0351, -1.7001, -2.1501, -1.9242, -2.3359, -1.5724, -1.7956,\n",
      "        -2.7937, -1.9470, -2.2252, -2.0580, -2.5420, -2.0681, -1.8897, -1.9469,\n",
      "        -1.9611, -1.8518, -2.0844, -2.6111, -1.7594, -2.0141, -1.9591, -1.8939,\n",
      "        -2.2650, -1.9786, -1.4302, -2.2497, -2.2228, -2.7537, -2.2954, -2.2246],\n",
      "       grad_fn=<AddBackward0>), tensor([2.1985, 2.2024, 3.5789, 3.2989, 3.1727, 2.7257, 3.1588, 2.9706, 2.3492,\n",
      "        2.3374, 2.2188, 3.5131, 2.9834, 3.2893, 2.7698, 2.7456, 3.0551, 2.7703,\n",
      "        2.4261, 2.7636, 2.3316, 2.5707, 3.1093, 2.7213, 3.2009, 2.8840, 2.6372,\n",
      "        3.2359, 2.7661, 3.7934, 1.9150, 3.2887, 2.6867, 3.5916, 2.4751, 3.0572,\n",
      "        2.5368, 2.8881, 2.4758, 2.3353, 2.7308, 2.2997, 2.9015, 2.8642, 2.6307,\n",
      "        2.6679, 2.1138, 2.7184, 2.5877, 2.4363, 2.8510, 2.2290, 2.7605, 2.9352,\n",
      "        2.5532, 2.4591, 2.0163, 3.2752, 2.3035, 2.7828, 2.5608, 2.5729, 2.1703,\n",
      "        2.6810, 2.4530, 2.5627, 2.7323, 3.0748, 2.3498, 3.0908, 2.9539, 2.4527,\n",
      "        2.4962, 2.8960, 2.6532, 2.6162, 2.2160, 3.6041, 3.0032, 2.8227, 2.6230,\n",
      "        3.2652, 2.3000, 2.5879, 2.6289, 3.2825, 2.4289, 3.2062, 2.0722, 2.9592,\n",
      "        2.0333, 2.4219, 2.9470, 3.5575, 2.5283, 2.6129, 2.5972, 2.9534, 2.9723,\n",
      "        2.5614, 2.8972, 2.7913, 2.9018, 1.8760, 3.3864, 3.4564, 2.7306, 3.0458,\n",
      "        2.2486, 3.0729, 2.5512, 2.5311, 2.8378, 2.2285, 3.0569, 2.5264, 2.6175,\n",
      "        2.5961, 2.5296, 2.6409, 2.6287, 2.5965, 2.9409, 2.4046, 2.7446, 2.3342,\n",
      "        2.9047, 2.5440, 3.0772, 1.9716, 2.1576, 2.7586, 2.4789, 2.6533, 2.2112,\n",
      "        1.8408, 2.9815, 2.7088, 2.7785, 2.7992, 3.3071, 3.1239, 2.4893, 3.1774,\n",
      "        2.4032, 2.8245, 2.6077, 3.3692, 2.4308, 2.2467, 1.9323, 2.7972, 2.7219,\n",
      "        3.2780, 2.9485, 1.9737, 2.9057, 3.7385, 3.2042, 2.6872, 2.8178, 2.6759,\n",
      "        2.4202, 2.7386, 2.2116, 2.8576, 3.0162, 2.2776, 3.1711, 2.4163, 3.9645,\n",
      "        2.4481, 2.7093, 2.1543, 2.6305, 2.5179, 2.1667, 2.6047, 2.6598, 2.0520,\n",
      "        3.2499, 2.4984, 3.2387, 1.9903, 2.1779, 2.6996, 3.1078, 3.0683, 2.8121,\n",
      "        2.5086, 2.6226, 2.2937, 2.8322, 2.4843, 2.4434, 2.6395, 2.6338, 2.3789,\n",
      "        2.7651, 2.4555, 2.8191, 2.7082, 1.9177, 1.8043, 2.0851, 2.5194, 2.5843,\n",
      "        2.2937, 2.0311, 2.0399, 2.4141, 2.8709, 2.6827, 3.2072, 2.4175, 2.9141,\n",
      "        2.7656, 2.7763, 2.8114, 2.5082, 1.9327, 2.6724, 2.2971, 2.3961, 2.4524,\n",
      "        2.7674, 2.5349, 3.2752, 2.6632, 2.7877, 2.4443, 2.6509, 2.4466, 2.1202,\n",
      "        2.9781, 2.3353, 2.5709, 2.1044, 2.5156, 2.9475, 3.4756, 2.5669, 2.3189,\n",
      "        2.3897, 2.2457, 3.0801, 3.5114, 2.4983, 2.5862, 2.5761, 3.1905, 2.3847,\n",
      "        2.0487, 2.6575, 2.6359, 3.1154, 2.4759, 2.8485, 3.0165, 2.8262, 2.6906,\n",
      "        2.8355, 2.7099, 2.5992, 1.6763, 2.7652, 2.6295, 2.3402, 2.8419, 2.9079,\n",
      "        2.4964, 2.8957, 2.8146, 2.8652, 2.3430, 2.9373, 1.6113, 2.4700, 1.9122,\n",
      "        2.3025, 2.5531, 2.2747, 2.6465, 2.9438, 2.1805, 2.2151, 3.0780, 2.2498,\n",
      "        2.4682, 2.1720, 1.9502, 2.3754, 3.0590, 2.9243, 2.5663, 2.1819, 1.9129,\n",
      "        2.4948, 2.9328, 2.1700, 2.6950, 2.9161, 3.1480, 2.9733, 2.6979, 1.7689,\n",
      "        2.1127, 2.9371, 2.5969, 3.9292, 3.1885, 2.4670, 2.7131, 2.7215, 2.7180,\n",
      "        2.5085, 3.2214, 3.0689, 3.8328, 2.5023, 2.7256, 2.1245, 2.3074, 2.0151,\n",
      "        2.5359, 2.9857, 2.3858, 2.7070, 2.9559, 2.5780, 2.9495, 2.1060, 2.3754,\n",
      "        2.7490, 2.9435, 2.4471, 2.6938, 2.2222, 2.7023, 2.6875, 2.6380, 2.3804,\n",
      "        2.8629, 2.6581, 2.5343, 2.1080, 3.1665, 2.9870, 2.4671, 3.0791, 2.9258,\n",
      "        2.0098, 2.9876, 2.4583, 3.1908, 1.8993, 2.4326, 3.2954, 2.3088, 2.7669,\n",
      "        2.3705, 2.6104, 2.2965, 2.8599, 3.0404, 3.1265, 2.3486, 2.6209, 2.5314,\n",
      "        2.9598, 2.1777, 3.2833, 2.4826, 2.1495, 2.1120, 2.6329, 2.0196, 2.5830,\n",
      "        2.9953, 2.7731, 2.1109, 2.6253, 2.6458, 3.1792, 2.3662, 2.9563, 2.5534,\n",
      "        3.6706, 2.4945, 3.0791, 2.2953, 2.7153, 3.2815, 2.2885, 2.4486, 2.0401,\n",
      "        3.1391, 2.0504, 3.0785, 2.2818, 2.9539, 2.3042, 2.9556, 2.9958, 1.6933,\n",
      "        2.8548, 2.2854, 2.5816, 3.0564, 2.0341, 2.3031, 2.5163, 2.3943, 2.1332,\n",
      "        2.5911, 2.6126, 2.3571, 2.4486, 1.9534, 3.2738, 2.5618, 2.5262, 2.7043,\n",
      "        2.9916, 3.1165, 2.2164, 3.1818, 2.5545, 2.2131, 3.1386, 3.0965, 2.8530,\n",
      "        1.9496, 2.5144, 2.0527, 2.6682, 2.6472, 2.7935, 2.5063, 3.1373, 3.1121,\n",
      "        2.6312, 2.4272, 2.1223, 2.9568, 2.5563, 2.5324, 3.5180, 2.0442, 2.8928,\n",
      "        3.0702, 2.2025, 2.4208, 3.1787, 2.5664, 2.6002, 2.0378, 2.5944, 2.5660,\n",
      "        2.8763, 2.4492, 2.1314, 3.1454, 2.7629, 3.0102, 3.0103, 2.5855, 2.3826,\n",
      "        2.2292, 2.7869, 2.7408, 1.9706, 2.4204, 2.4976, 3.1486, 2.0788, 2.7363,\n",
      "        2.4180, 2.0303, 2.9344, 2.0718, 2.6562, 3.4177, 3.0537, 2.7972, 2.2466,\n",
      "        3.6124, 3.4383, 1.8691, 2.8081, 2.1992, 2.7259, 1.9714, 2.4989, 2.9801,\n",
      "        3.0282, 2.6700, 2.6769, 2.3750, 2.2532, 3.5080, 2.4676, 2.6120, 2.4669,\n",
      "        2.5763, 2.6182, 3.6755, 2.8927, 2.4527, 1.9694, 3.1698, 2.4372],\n",
      "       grad_fn=<AddBackward0>)], [tensor([-35.7740, -45.8241, -38.7560, -31.5890, -35.1164, -38.4393, -42.1957,\n",
      "        -46.6409, -48.8005, -44.3439], grad_fn=<AddBackward0>), tensor([43.3247, 44.5450, 41.7424, 34.7020, 40.5605, 35.9051, 43.5192, 46.3586,\n",
      "        38.2934, 41.4183], grad_fn=<AddBackward0>)]]\n"
     ]
    }
   ],
   "source": [
    "input_flattened = torch.flatten(test_image)\n",
    "bounds_affine_out, bounds_layer_out = nn.calculate_box_bounds([input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "print(\"bounds affine out \\n {}\".format(bounds_affine_out))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "dhov_model = icnn_model(icnns[layer_index][0], nn, test_image, eps, layer_index, 0, group_size, print_log=False)\n",
    "dhov_model.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "icnn_neuron_name = \"icnn_var[{}]\".format(neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "dhov_copy = dhov_model.copy()\n",
    "dhov_copy.Params.LogToConsole = 0\n",
    "add_min_constr(dhov_copy, icnn_neuron_name)\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 2.198498487472534\n"
     ]
    }
   ],
   "source": [
    "dhov_copy = dhov_model.copy()\n",
    "dhov_copy.Params.LogToConsole = 0\n",
    "add_max_constr(dhov_copy, icnn_neuron_name)\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}