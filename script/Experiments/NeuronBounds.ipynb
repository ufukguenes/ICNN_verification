{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from script.NeuralNets.Networks import SequentialNN, ICNN, ICNNApproxMax, ICNNLogical\n",
    "from script.settings import device, data_type\n",
    "import script.DHOV.MultiDHOV as multidhov\n",
    "from script.Verification.Verifier import SingleNeuronVerifier, MILPVerifier, DHOVVerifier\n",
    "import gurobipy as grp\n",
    "from torchvision.datasets import CIFAR10, MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from script.NeuralNets.ICNNFactory import ICNNFactory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def add_max_constr(model, neuron_name):\n",
    "    neuron_var = model.getVarByName(neuron_name)\n",
    "    model.setObjective(neuron_var, grp.GRB.MAXIMIZE)\n",
    "\n",
    "def add_min_constr(model, neuron):\n",
    "    neuron_var = model.getVarByName(neuron)\n",
    "    model.setObjective(neuron_var, grp.GRB.MINIMIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def optimize_model(model, neuron_name):\n",
    "    model.update()\n",
    "    model.optimize()\n",
    "    if model.Status == grp.GRB.OPTIMAL:\n",
    "        print(\"opt value: {}\".format(model.getVarByName(neuron_name).getAttr(\"x\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def icnn_model(icnn, nn, input_x, eps, layer_index, from_neuron, to_neuron, print_log=False):\n",
    "    m = grp.Model()\n",
    "    if not print_log:\n",
    "        m.Params.LogToConsole = 0\n",
    "\n",
    "    input_flattened = torch.flatten(input_x)\n",
    "    bounds_affine_out, bounds_layer_out = nn.calculate_box_bounds(\n",
    "        [input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "\n",
    "    parameter_list = list(nn.parameters())\n",
    "\n",
    "    input_size = len(parameter_list[2*(layer_index-1)])\n",
    "    lb = bounds_layer_out[layer_index-1][0].detach().cpu().numpy()\n",
    "    ub = bounds_layer_out[layer_index-1][1].detach().cpu().numpy()\n",
    "    print(lb)\n",
    "    print(ub)\n",
    "    in_var = m.addMVar(input_size, lb=-float(\"inf\"), ub=float(\"inf\"), name=\"icnn_var\")\n",
    "\n",
    "    low = bounds_layer_out[layer_index - 1][0][from_neuron: to_neuron]\n",
    "    up = bounds_layer_out[layer_index - 1][1][from_neuron: to_neuron]\n",
    "    low = torch.zeros_like(low, dtype=data_type).to(device) - 1000\n",
    "    up = torch.zeros_like(low, dtype=data_type).to(device) + 1000\n",
    "    print(low)\n",
    "    print(up)\n",
    "    constraint_bounds_affine_out, constraint_bounds_layer_out = icnn.calculate_box_bounds([low, up])\n",
    "    icnn.add_max_output_constraints(m, in_var[from_neuron: to_neuron], constraint_bounds_affine_out, constraint_bounds_layer_out)\n",
    "\n",
    "    return m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'nn = SequentialNN([50, 50, 50, 7])\\ntest_image = torch.zeros((1, 50), dtype=data_type).to(device)\\nparameter_list = list(nn.parameters())'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"W1 = [1. 1.; 1. -1.]\n",
    "    b1 = [0., 0.]\n",
    "    W2 = [1. 1.; 1. -1.]\n",
    "    b2 = [-0.5, 0.]\n",
    "    W3 = [-1. 1.; 1. 1.]\n",
    "    b3 = [3., 0.] \"\"\"\n",
    "\n",
    "\"\"\"nn = SequentialNN([2, 2, 2, 2])\n",
    "\n",
    "with torch.no_grad():\n",
    "    parameter_list = list(nn.parameters())\n",
    "    parameter_list[0].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[1].data = torch.tensor([0, 0], dtype=data_type).to(device)\n",
    "    parameter_list[2].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[3].data = torch.tensor([-0.5, 0], dtype=data_type).to(device)\n",
    "    parameter_list[4].data = torch.tensor([[-1, 1], [1, 1]], dtype=data_type).to(device)\n",
    "    parameter_list[5].data = torch.tensor([3, 0], dtype=data_type).to(device)\n",
    "\n",
    "test_image = torch.tensor([[0, 0]], dtype=data_type).to(device)\"\"\"\n",
    "\n",
    "\"\"\"transform = Compose([ToTensor(),\n",
    "                         Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "                        )\n",
    "\n",
    "training_data = CIFAR10(root=\"../../cifar\", train=True, download=True, transform=transform)\n",
    "images, labels = training_data.__getitem__(0)\n",
    "test_image, test_label = torch.unsqueeze(images, 0).to(dtype=data_type).to(device), torch.unsqueeze(\n",
    "    torch.tensor(labels), 0).to(dtype=data_type).to(device)\n",
    "\n",
    "nn = SequentialNN([32 * 32 * 3, 1024, 512, 10])\n",
    "nn.load_state_dict(torch.load(\"../../cifar_fc.pth\", map_location=torch.device(device)), strict=False)\n",
    "\"\"\"\n",
    "\n",
    "transform = Compose([ToTensor(),\n",
    "                         Normalize(0.5, 0.5)]\n",
    "                        )\n",
    "\n",
    "training_data = MNIST(root=\"../../mnist\",\n",
    "                      train=True,\n",
    "                      download=True,\n",
    "                      transform=transform)\n",
    "images, labels = training_data.__getitem__(0)\n",
    "test_image, test_label = torch.unsqueeze(images, 0).to(dtype=data_type).to(device), torch.unsqueeze(\n",
    "    torch.tensor(labels), 0).to(dtype=data_type).to(device)\n",
    "\n",
    "nn = SequentialNN([28*28*1, 100, 30, 10])\n",
    "nn.load_state_dict(torch.load(\"../../mnist_fc.pth\", map_location=torch.device('cpu')), strict=False)\n",
    "\n",
    "parameter_list = list(nn.parameters())\n",
    "\n",
    "\"\"\"nn = SequentialNN([50, 50, 50, 7])\n",
    "test_image = torch.zeros((1, 50), dtype=data_type).to(device)\n",
    "parameter_list = list(nn.parameters())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "eps = 0.01\n",
    "layer_index = 1\n",
    "neuron_index = 5\n",
    "neuron_name = \"relu_var{}[{}]\".format(2*layer_index, neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for DHOV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "approximation of layer: 0\n",
      "    number of fixed neurons for current layer: 0\n",
      "    layer progress, group 1 of 50 \n",
      "        time for training: 3.170367956161499\n",
      "        actual verification time 0.04029536247253418\n",
      "        time for verification: 0.12329816818237305\n",
      "    layer progress, group 2 of 50 \n",
      "        time for training: 2.8368749618530273\n",
      "        actual verification time 0.030243396759033203\n",
      "        time for verification: 0.09078359603881836\n",
      "    layer progress, group 3 of 50 \n",
      "        time for training: 2.939046621322632\n",
      "        actual verification time 0.002048492431640625\n",
      "        time for verification: 0.06054854393005371\n",
      "    layer progress, group 4 of 50 \n",
      "        time for training: 2.817906379699707\n",
      "        actual verification time 0.0176849365234375\n",
      "        time for verification: 0.09895515441894531\n",
      "    layer progress, group 5 of 50 \n",
      "        time for training: 2.819840669631958\n",
      "        actual verification time 0.020237207412719727\n",
      "        time for verification: 0.08084392547607422\n",
      "    layer progress, group 6 of 50 \n",
      "        time for training: 2.7447142601013184\n",
      "        actual verification time 0.0\n",
      "        time for verification: 0.05255389213562012\n",
      "    layer progress, group 7 of 50 \n",
      "        time for training: 2.8755898475646973\n",
      "        actual verification time 0.020165681838989258\n",
      "        time for verification: 0.0827634334564209\n",
      "    layer progress, group 8 of 50 \n",
      "        time for training: 3.059769868850708\n",
      "        actual verification time 0.0020275115966796875\n",
      "        time for verification: 0.04036140441894531\n",
      "    layer progress, group 9 of 50 \n",
      "        time for training: 2.7568163871765137\n",
      "        actual verification time 0.028293132781982422\n",
      "        time for verification: 0.0909571647644043\n",
      "    layer progress, group 10 of 50 \n",
      "        time for training: 2.807884931564331\n",
      "        actual verification time 0.0\n",
      "        time for verification: 0.05063986778259277\n",
      "    layer progress, group 11 of 50 \n",
      "        time for training: 2.8363211154937744\n",
      "        actual verification time 0.03027796745300293\n",
      "        time for verification: 0.09077048301696777\n",
      "    layer progress, group 12 of 50 \n",
      "        time for training: 2.9193508625030518\n",
      "        actual verification time 0.03230428695678711\n",
      "        time for verification: 0.09087491035461426\n",
      "    layer progress, group 13 of 50 \n",
      "        time for training: 2.7579526901245117\n",
      "        actual verification time 0.0100860595703125\n",
      "        time for verification: 0.07072615623474121\n",
      "    layer progress, group 14 of 50 \n",
      "        time for training: 2.717869281768799\n",
      "        actual verification time 0.020199060440063477\n",
      "        time for verification: 0.08069276809692383\n",
      "    layer progress, group 15 of 50 \n",
      "        time for training: 2.8884644508361816\n",
      "        actual verification time 0.020180225372314453\n",
      "        time for verification: 0.08879590034484863\n",
      "    layer progress, group 16 of 50 \n",
      "        time for training: 2.9093563556671143\n",
      "        actual verification time 0.01751852035522461\n",
      "        time for verification: 0.040827035903930664\n",
      "    layer progress, group 17 of 50 \n",
      "        time for training: 2.60817289352417\n",
      "        actual verification time 0.0\n",
      "        time for verification: 0.0505061149597168\n",
      "    layer progress, group 18 of 50 \n",
      "        time for training: 2.7451765537261963\n",
      "        actual verification time 0.008070945739746094\n",
      "        time for verification: 0.04245162010192871\n",
      "    layer progress, group 19 of 50 \n",
      "        time for training: 2.747616767883301\n",
      "        actual verification time 0.0181124210357666\n",
      "        time for verification: 0.08069562911987305\n",
      "    layer progress, group 20 of 50 \n",
      "        time for training: 2.7865219116210938\n",
      "        actual verification time 0.0\n",
      "        time for verification: 0.05042672157287598\n",
      "    layer progress, group 21 of 50 \n",
      "        time for training: 2.89628005027771\n",
      "        actual verification time 0.020167112350463867\n",
      "        time for verification: 0.0827479362487793\n",
      "    layer progress, group 22 of 50 \n",
      "        time for training: 2.8685011863708496\n",
      "        actual verification time 0.0\n",
      "        time for verification: 0.05046415328979492\n",
      "    layer progress, group 23 of 50 \n",
      "        time for training: 2.8975558280944824\n",
      "        actual verification time 0.020173072814941406\n",
      "        time for verification: 0.08078837394714355\n",
      "    layer progress, group 24 of 50 \n",
      "        time for training: 2.8464901447296143\n",
      "        actual verification time 0.03829813003540039\n",
      "        time for verification: 0.09885048866271973\n",
      "    layer progress, group 25 of 50 \n",
      "        time for training: 2.7577388286590576\n",
      "        actual verification time 0.020167827606201172\n",
      "        time for verification: 0.07064509391784668\n",
      "    layer progress, group 26 of 50 \n",
      "        time for training: 2.7875540256500244\n",
      "        actual verification time 0.01007223129272461\n",
      "        time for verification: 0.07069540023803711\n",
      "    layer progress, group 27 of 50 \n",
      "        time for training: 2.653968572616577\n",
      "        actual verification time 0.008046627044677734\n",
      "        time for verification: 0.04236412048339844\n",
      "    layer progress, group 28 of 50 \n",
      "        time for training: 2.779442548751831\n",
      "        actual verification time 0.0\n",
      "        time for verification: 0.04040074348449707\n",
      "    layer progress, group 29 of 50 \n",
      "        time for training: 2.706439256668091\n",
      "        actual verification time 0.0\n",
      "        time for verification: 0.0302889347076416\n",
      "    layer progress, group 30 of 50 \n",
      "        time for training: 2.876499891281128\n",
      "        actual verification time 0.002032756805419922\n",
      "        time for verification: 0.0525670051574707\n",
      "    layer progress, group 31 of 50 \n",
      "        time for training: 3.001779079437256\n",
      "        actual verification time 0.020166873931884766\n",
      "        time for verification: 0.07069015502929688\n",
      "    layer progress, group 32 of 50 \n",
      "        time for training: 2.8890304565429688\n",
      "        actual verification time 0.0020537376403808594\n",
      "        time for verification: 0.05044150352478027\n",
      "    layer progress, group 33 of 50 \n",
      "        time for training: 2.887314558029175\n",
      "        actual verification time 0.012174844741821289\n",
      "        time for verification: 0.07276535034179688\n",
      "    layer progress, group 34 of 50 \n",
      "        time for training: 2.898578643798828\n",
      "        actual verification time 0.0\n",
      "        time for verification: 0.0302736759185791\n",
      "    layer progress, group 35 of 50 \n",
      "        time for training: 2.8862111568450928\n",
      "        actual verification time 0.04101109504699707\n",
      "        time for verification: 0.10149908065795898\n",
      "    layer progress, group 36 of 50 \n",
      "        time for training: 3.057774782180786\n",
      "        actual verification time 0.010080814361572266\n",
      "        time for verification: 0.060588836669921875\n",
      "    layer progress, group 37 of 50 \n",
      "        time for training: 3.167476177215576\n",
      "        actual verification time 0.01815962791442871\n",
      "        time for verification: 0.06854581832885742\n",
      "    layer progress, group 38 of 50 \n",
      "        time for training: 2.6823291778564453\n",
      "        actual verification time 0.0020258426666259766\n",
      "        time for verification: 0.04234623908996582\n",
      "    layer progress, group 39 of 50 \n",
      "        time for training: 2.733926773071289\n",
      "        actual verification time 0.0\n",
      "        time for verification: 0.03020787239074707\n",
      "    layer progress, group 40 of 50 \n",
      "        time for training: 3.2028934955596924\n",
      "        actual verification time 0.0\n",
      "        time for verification: 0.038404226303100586\n",
      "    layer progress, group 41 of 50 \n",
      "        time for training: 3.436707019805908\n",
      "        actual verification time 0.0\n",
      "        time for verification: 0.030234336853027344\n",
      "    layer progress, group 42 of 50 \n",
      "        time for training: 3.446552276611328\n",
      "        actual verification time 0.002038717269897461\n",
      "        time for verification: 0.052547454833984375\n",
      "    layer progress, group 43 of 50 \n",
      "        time for training: 3.272221565246582\n",
      "        actual verification time 0.0\n",
      "        time for verification: 0.06854772567749023\n",
      "    layer progress, group 44 of 50 \n",
      "        time for training: 3.226532459259033\n",
      "        actual verification time 0.01820969581604004\n",
      "        time for verification: 0.09108710289001465\n",
      "    layer progress, group 45 of 50 \n",
      "        time for training: 3.2846157550811768\n",
      "        actual verification time 0.02016425132751465\n",
      "        time for verification: 0.08890175819396973\n",
      "    layer progress, group 46 of 50 \n",
      "        time for training: 3.0523383617401123\n",
      "        actual verification time 0.008065223693847656\n",
      "        time for verification: 0.050527334213256836\n",
      "    layer progress, group 47 of 50 \n",
      "        time for training: 2.829622745513916\n",
      "        actual verification time 0.0\n",
      "        time for verification: 0.07883787155151367\n",
      "    layer progress, group 48 of 50 \n",
      "        time for training: 2.926254987716675\n",
      "        actual verification time 0.022237777709960938\n",
      "        time for verification: 0.07265377044677734\n",
      "    layer progress, group 49 of 50 \n",
      "        time for training: 3.559832811355591\n",
      "        actual verification time 0.030352354049682617\n",
      "        time for verification: 0.09093213081359863\n",
      "    layer progress, group 50 of 50 \n",
      "        time for training: 3.2824268341064453\n",
      "        actual verification time 0.010083436965942383\n",
      "        time for verification: 0.06050610542297363\n",
      "    time for icnn_bound calculation: 1.7711732387542725\n",
      "included space num samples 0, ambient space num samples 1000\n",
      "    time for regrouping method: 7.4909679889678955\n",
      "\n",
      "approximation of layer: 1\n",
      "    number of fixed neurons for current layer: 0\n",
      "    layer progress, group 1 of 15 \n",
      "        time for sampling for one group: 8.120686054229736\n",
      "        time for training: 10.271002292633057\n",
      "        actual verification time 0.06942033767700195\n",
      "        time for verification: 0.11981654167175293\n",
      "aborting because of force break\n"
     ]
    }
   ],
   "source": [
    "group_size = 2\n",
    "icnn_factory = ICNNFactory(\"logical\", [5, 5, 1], force_positive_init=False, with_two_layers=False,\n",
    "                               init_scaling=10, init_all_with_zeros=False)\n",
    "#icnn_factory = ICNNFactory(\"standard\", [5, 5, 1])\n",
    "\n",
    "icnns, all_group_indices, fixed_neuron_per_layer_lower, fixed_neuron_per_layer_upper, bounds_affine_out, bounds_layer_out = \\\n",
    "    multidhov.start_verification(nn, test_image, icnn_factory, group_size, eps=eps, icnn_epochs=100,\n",
    "                                     icnn_batch_size=10000, sample_count=1000, sample_new=True, use_over_approximation=True, break_after=51,\n",
    "                                     sample_over_input_space=False, sample_over_output_space=True, use_icnn_bounds=True,\n",
    "                                     use_fixed_neurons=True, sampling_method=\"per_group_sampling\",\n",
    "                                     force_inclusion_steps=0, preemptive_stop=False, even_gradient_training=False,\n",
    "                                     keep_ambient_space=True, data_grad_descent_steps=0, opt_steps_gd=100,\n",
    "                                     train_outer=False, print_training_loss=False,\n",
    "                                     should_plot=\"none\", optimizer=\"SdLBFGS\", init_network=True, adapt_lambda=\"none\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.5903,  6.9082,  2.4571, -2.6379,  3.3335,  0.0854,  2.2013,  0.5879,\n",
      "         3.4414,  1.9512,  2.7689,  4.5998,  3.4715, -0.5237, -0.3061,  7.3616,\n",
      "         2.0802,  4.2680, -0.2947,  6.6573,  1.2007,  7.4136,  3.3206,  6.7802,\n",
      "         8.9711, -0.0464,  5.7120,  6.0631,  2.2935,  5.0945],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(bounds_affine_out[1][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.5903,  6.9082,  2.4571, -2.6379,  3.3335,  0.0854,  2.2013,  0.5879,\n",
      "         3.4414,  1.9512,  2.7689,  4.5998,  3.4715, -0.5237, -0.3061,  7.3616,\n",
      "         2.0802,  4.2680, -0.2947,  6.6573,  1.2007,  7.4136,  3.3206,  6.7802,\n",
      "         8.9711, -0.0464,  5.7120,  6.0631,  2.2935,  5.0945],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_flattened = torch.flatten(test_image)\n",
    "bounds_affine_out, bounds_layer_out = nn.calculate_box_bounds([input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "print(bounds_affine_out[1][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70666748 0.         2.56957236 1.25056012 0.56577596 0.\n",
      " 2.24672561 1.10036216 3.08457109 0.42557193 1.06481606 0.\n",
      " 3.80799179 2.95306733 2.2914741  0.         1.45164122 3.88912043\n",
      " 0.         0.65890114 3.78516924 2.54575045 0.33975505 0.\n",
      " 0.30106137 0.         0.50057251 1.87296217 1.2716577  1.59314324\n",
      " 0.         0.         2.42074295 0.         1.69313686 0.\n",
      " 1.95689483 1.66914862 0.         0.27212066 2.14630917 1.68023284\n",
      " 0.32191143 0.         0.28490208 0.78442567 0.2704539  1.098196\n",
      " 0.68565325 1.74543125 2.29116924 0.         0.         1.77435549\n",
      " 0.         2.77659388 0.         0.         1.21580995 0.\n",
      " 0.         1.98215932 1.76104975 0.         4.24902551 1.01444244\n",
      " 0.         0.         0.         0.         2.16896675 0.\n",
      " 0.15547488 2.84610801 2.36071697 0.         0.         0.04042499\n",
      " 0.         0.         0.         0.         0.         0.49566225\n",
      " 0.         0.60572794 0.         1.69831855 1.74438874 2.23785683\n",
      " 0.57627976 0.         0.93811607 0.         0.08349044 0.92494106\n",
      " 0.         0.09807534 0.         0.10291365]\n",
      "[1.05326607 0.21060791 2.90228171 1.70707168 0.99744289 0.\n",
      " 2.61296484 1.39890945 3.39514539 0.73523746 1.38436963 0.\n",
      " 4.18312805 3.39869445 2.60043183 0.         1.77727599 4.32163615\n",
      " 0.         0.97373722 4.19106058 2.92009994 0.66617605 0.32468251\n",
      " 0.65823476 0.3012288  0.81418688 2.20378527 1.71164391 1.95107721\n",
      " 0.         0.         2.82045386 0.         2.01927985 0.\n",
      " 2.3245991  2.03800606 0.         0.62444403 2.47524555 2.01754495\n",
      " 0.65762716 0.         0.65138922 1.09947057 0.58862978 1.45234034\n",
      " 1.03637757 2.07641299 2.66826032 0.30892396 0.         2.09347426\n",
      " 0.         3.13987263 0.         0.         1.54760086 0.\n",
      " 0.21566038 2.31589581 2.10461637 0.         4.66341886 1.37089213\n",
      " 0.         0.         0.         0.20604243 2.51692896 0.\n",
      " 0.52416723 3.21451646 2.75055779 0.         0.         0.35382054\n",
      " 0.         0.         0.         0.         0.         0.84365304\n",
      " 0.         0.9073907  0.07848064 2.03960324 2.11782851 2.68318128\n",
      " 0.90762454 0.         1.27378477 0.         0.38367514 1.2389711\n",
      " 0.30637548 0.39643297 0.         0.5424053 ]\n",
      "tensor([-1000., -1000.], dtype=torch.float64)\n",
      "tensor([1000., 1000.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "dhov_model = icnn_model(icnns[layer_index][0], nn, test_image, eps, layer_index, 0, group_size, print_log=True)\n",
    "dhov_model.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "icnn_neuron_name = \"icnn_var[{}]\".format(neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 10.0.0 build v10.0.0rc2 (win64)\n",
      "\n",
      "CPU model: AMD Ryzen 7 5800H with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Optimize a model with 41 rows, 133 columns and 104 nonzeros\n",
      "Model fingerprint: 0x053be0be\n",
      "Model has 3 general constraints\n",
      "Variable types: 133 continuous, 0 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-05, 3e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 3e+04]\n",
      "  RHS range        [2e-02, 1e+01]\n",
      "Presolve removed 28 rows and 116 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 13 rows, 17 columns, 44 nonzeros\n",
      "Variable types: 13 continuous, 4 integer (4 binary)\n",
      "Found heuristic solution: objective 0.0000000\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.02 seconds (0.00 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 1: 0 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n",
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "dhov_copy = dhov_model.copy()\n",
    "dhov_copy.Params.LogToConsole = 1\n",
    "add_min_constr(dhov_copy, icnn_neuron_name)\n",
    "dhov_copy.update()\n",
    "all_var = dhov_copy.getVars()\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 1.590265447932639\n"
     ]
    }
   ],
   "source": [
    "dhov_copy = dhov_model.copy()\n",
    "dhov_copy.Params.LogToConsole = 0\n",
    "add_max_constr(dhov_copy, icnn_neuron_name)\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for SNV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "snv_verifier = SingleNeuronVerifier(nn, test_image, eps, print_log=False)\n",
    "snv_verifier.generate_constraints_for_net()\n",
    "snv_model = snv_verifier.model\n",
    "snv_model.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "snv_copy = snv_model.copy()\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "add_min_constr(snv_copy, neuron_name)\n",
    "optimize_model(snv_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 2.625\n"
     ]
    }
   ],
   "source": [
    "snv_copy = snv_model.copy()\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "add_max_constr(snv_copy, neuron_name)\n",
    "optimize_model(snv_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for MILP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'all_var = milp_model.getVars()\\nfor var in all_var:\\n    print(var)'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_name = \"relu_var{}[{}]\".format(2*layer_index, 0)\n",
    "milp_verifier = MILPVerifier(nn, test_image, eps, print_log=False)\n",
    "milp_verifier.generate_constraints_for_net(until_layer_neuron=[layer_index, neuron_index])\n",
    "milp_model = milp_verifier.model\n",
    "milp_model.update()\n",
    "\n",
    "\"\"\"all_var = milp_model.getVars()\n",
    "for var in all_var:\n",
    "    print(var)\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "milp_copy = milp_model.copy()\n",
    "milp_copy.Params.LogToConsole = 0\n",
    "add_min_constr(milp_copy, neuron_name)\n",
    "optimize_model(milp_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "milp_copy = milp_model.copy()\n",
    "milp_copy.Params.LogToConsole = 0\n",
    "add_max_constr(milp_copy, neuron_name)\n",
    "optimize_model(milp_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.5903,  6.9082,  2.4571, -2.6379,  3.3335,  0.0854,  2.2013,  0.5879,\n",
      "         3.4414,  1.9512,  2.7689,  4.5998,  3.4715, -0.5237, -0.3061,  7.3616,\n",
      "         2.0802,  4.2680, -0.2947,  6.6573,  1.2007,  7.4136,  3.3206,  6.7802,\n",
      "         8.9711, -0.0464,  5.7120,  6.0631,  2.2935,  5.0945],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(bounds_affine_out[1][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5622,  5.8829,  1.5250, -3.3748,  1.9779, -0.9429,  0.7452, -0.2541,\n",
      "         2.2339,  1.0210,  1.7514,  3.4973,  2.4593, -1.1550, -0.8883,  5.9632,\n",
      "         0.6167,  3.3430, -0.8186,  5.6432,  0.2598,  6.4190,  2.1272,  5.3496,\n",
      "         7.6800, -0.5891,  4.6769,  4.7965,  1.4821,  4.0188],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "in_var = []\n",
    "for i in range(28*28):\n",
    "    in_var.append(milp_copy.getVarByName(\"in_var[{}]\".format(i)).getAttr(\"X\"))\n",
    "\n",
    "inp = torch.tensor(in_var, dtype=torch.float64)\n",
    "par_list = list(nn.parameters())\n",
    "first_out = torch.matmul(par_list[0], inp).add(par_list[1])\n",
    "first_out = torch.nn.ReLU()(first_out)\n",
    "second_out = torch.matmul(par_list[2], first_out).add(par_list[3])\n",
    "print(second_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}