{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from script.NeuralNets.Networks import SequentialNN, ICNN, ICNNApproxMax, ICNNLogical\n",
    "from script.settings import device, data_type\n",
    "import script.DHOV.MultiDHOV as multidhov\n",
    "from script.Verification.Verifier import SingleNeuronVerifier, MILPVerifier, DHOVVerifier\n",
    "import gurobipy as grp\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def add_max_constr(model, neuron_name):\n",
    "    neuron_var = model.getVarByName(neuron_name)\n",
    "    model.setObjective(neuron_var, grp.GRB.MAXIMIZE)\n",
    "\n",
    "def add_min_constr(model, neuron):\n",
    "    neuron_var = model.getVarByName(neuron)\n",
    "    model.setObjective(neuron_var, grp.GRB.MINIMIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def optimize_model(model, neuron_name):\n",
    "    model.update()\n",
    "    model.optimize()\n",
    "    if model.Status == grp.GRB.OPTIMAL:\n",
    "        print(\"opt value: {}\".format(model.getVarByName(neuron_name).getAttr(\"x\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def icnn_model(icnn, nn, input_x, eps, layer_index, from_neuron, to_neuron, print_log=False):\n",
    "    m = grp.Model()\n",
    "    if not print_log:\n",
    "        m.Params.LogToConsole = 0\n",
    "\n",
    "    input_flattened = torch.flatten(input_x)\n",
    "    bounds_affine_out, bounds_layer_out = nn.calculate_box_bounds(\n",
    "        [input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "\n",
    "    parameter_list = list(nn.parameters())\n",
    "\n",
    "    input_size = len(parameter_list[2*layer_index])\n",
    "    lb = bounds_layer_out[layer_index][0].detach().cpu().numpy()\n",
    "    ub = bounds_layer_out[layer_index][1].detach().cpu().numpy()\n",
    "    in_var = m.addMVar(input_size, lb=lb, ub=ub, name=\"icnn_var\")\n",
    "\n",
    "    low = bounds_layer_out[layer_index][0][from_neuron: to_neuron]\n",
    "    up = bounds_layer_out[layer_index][1][from_neuron: to_neuron]\n",
    "    constraint_bounds_affine_out, constraint_bounds_layer_out = icnn.calculate_box_bounds([low, up])\n",
    "    icnn.add_max_output_constraints(m, in_var[from_neuron: to_neuron], constraint_bounds_affine_out, constraint_bounds_layer_out)\n",
    "\n",
    "    return m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\"\"\"W1 = [1. 1.; 1. -1.]\n",
    "    b1 = [0., 0.]\n",
    "    W2 = [1. 1.; 1. -1.]\n",
    "    b2 = [-0.5, 0.]\n",
    "    W3 = [-1. 1.; 1. 1.]\n",
    "    b3 = [3., 0.] \"\"\"\n",
    "\n",
    "\"\"\"nn = SequentialNN([2, 2, 2, 2])\n",
    "\n",
    "with torch.no_grad():\n",
    "    parameter_list = list(nn.parameters())\n",
    "    parameter_list[0].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[1].data = torch.tensor([0, 0], dtype=data_type).to(device)\n",
    "    parameter_list[2].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[3].data = torch.tensor([-0.5, 0], dtype=data_type).to(device)\n",
    "    parameter_list[4].data = torch.tensor([[-1, 1], [1, 1]], dtype=data_type).to(device)\n",
    "    parameter_list[5].data = torch.tensor([3, 0], dtype=data_type).to(device)\n",
    "\n",
    "test_image = torch.tensor([[0, 0]], dtype=data_type).to(device)\"\"\"\n",
    "\n",
    "transform = Compose([ToTensor(),\n",
    "                         Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "                        )\n",
    "\n",
    "training_data = CIFAR10(root=\"../../cifar\", train=True, download=True, transform=transform)\n",
    "images, labels = training_data.__getitem__(0)\n",
    "test_image, test_label = torch.unsqueeze(images, 0).to(dtype=data_type).to(device), torch.unsqueeze(\n",
    "    torch.tensor(labels), 0).to(dtype=data_type).to(device)\n",
    "\n",
    "nn = SequentialNN([32 * 32 * 3, 1024, 512, 10])\n",
    "nn.load_state_dict(torch.load(\"../../cifar_fc.pth\", map_location=torch.device(device)), strict=False)\n",
    "parameter_list = list(nn.parameters())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "\n",
      "approximation of layer: 0\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-11-12\n",
      "layer progress, group 0 of 205 \n",
      "        time for training: 0.10000109672546387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ufuk\\Documents\\Programming\\ICNN_verification\\script\\Optimizer\\sdlbfgs.py:83: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1420.)\n",
      "  p.data.add_(step_size, update[offset:offset + numel].view_as(p.data))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        actual verification time 1.0236430168151855\n",
      "        time for verification: 1.2656474113464355\n",
      "layer progress, group 1 of 205 \n",
      "        time for training: 0.08800315856933594\n",
      "        actual verification time 0.5114672183990479\n",
      "        time for verification: 0.7114701271057129\n",
      "layer progress, group 2 of 205 \n",
      "        time for training: 0.08539867401123047\n",
      "        actual verification time 0.42699742317199707\n",
      "        time for verification: 0.6399893760681152\n",
      "layer progress, group 3 of 205 \n",
      "        time for training: 0.10799908638000488\n",
      "        actual verification time 0.6539962291717529\n",
      "        time for verification: 0.8696577548980713\n",
      "layer progress, group 4 of 205 \n",
      "        time for training: 0.09399938583374023\n",
      "        actual verification time 1.2190470695495605\n",
      "        time for verification: 1.4300508499145508\n",
      "layer progress, group 5 of 205 \n",
      "        time for training: 0.07999825477600098\n",
      "        actual verification time 0.1469898223876953\n",
      "        time for verification: 0.3439967632293701\n",
      "layer progress, group 6 of 205 \n",
      "        time for training: 0.0868675708770752\n",
      "        actual verification time 0.060999393463134766\n",
      "        time for verification: 0.24699926376342773\n",
      "layer progress, group 7 of 205 \n",
      "        time for training: 0.09200000762939453\n",
      "        actual verification time 0.6150476932525635\n",
      "        time for verification: 0.8206205368041992\n",
      "layer progress, group 8 of 205 \n",
      "        time for training: 0.08899807929992676\n",
      "        actual verification time 0.012003660202026367\n",
      "        time for verification: 0.16705036163330078\n",
      "layer progress, group 9 of 205 \n",
      "        time for training: 0.08999752998352051\n",
      "        actual verification time 0.36319828033447266\n",
      "        time for verification: 0.5931997299194336\n",
      "layer progress, group 10 of 205 \n",
      "        time for training: 0.1380023956298828\n",
      "        actual verification time 0.5750606060028076\n",
      "        time for verification: 0.84305739402771\n",
      "layer progress, group 11 of 205 \n",
      "        time for training: 0.07699990272521973\n",
      "        actual verification time 0.3170003890991211\n",
      "        time for verification: 0.5250005722045898\n",
      "layer progress, group 12 of 205 \n",
      "        time for training: 0.08255815505981445\n",
      "        actual verification time 0.041998863220214844\n",
      "        time for verification: 0.22299718856811523\n",
      "layer progress, group 13 of 205 \n",
      "        time for training: 0.08199858665466309\n",
      "        actual verification time 0.14499974250793457\n",
      "        time for verification: 0.3650386333465576\n",
      "layer progress, group 14 of 205 \n",
      "        time for training: 0.08199930191040039\n",
      "        actual verification time 0.11100125312805176\n",
      "        time for verification: 0.3050045967102051\n",
      "layer progress, group 15 of 205 \n",
      "        time for training: 0.07599568367004395\n",
      "        actual verification time 0.012001514434814453\n",
      "        time for verification: 0.15700244903564453\n",
      "layer progress, group 16 of 205 \n",
      "        time for training: 0.0798802375793457\n",
      "        actual verification time 0.0039997100830078125\n",
      "        time for verification: 0.12399983406066895\n",
      "layer progress, group 17 of 205 \n",
      "        time for training: 0.09099888801574707\n",
      "        actual verification time 0.6929996013641357\n",
      "        time for verification: 0.8930466175079346\n",
      "layer progress, group 18 of 205 \n",
      "        time for training: 0.07700037956237793\n",
      "        actual verification time 1.6010313034057617\n",
      "        time for verification: 1.8110337257385254\n",
      "layer progress, group 19 of 205 \n",
      "        time for training: 0.0765523910522461\n",
      "        actual verification time 0.7702624797821045\n",
      "        time for verification: 0.9972636699676514\n",
      "layer progress, group 20 of 205 \n",
      "        time for training: 0.07699990272521973\n",
      "        actual verification time 0.5790927410125732\n",
      "        time for verification: 0.7760930061340332\n",
      "layer progress, group 21 of 205 \n",
      "        time for training: 0.07805061340332031\n",
      "        actual verification time 0.36899900436401367\n",
      "        time for verification: 0.5880048274993896\n",
      "layer progress, group 22 of 205 \n",
      "        time for training: 0.08499717712402344\n",
      "        actual verification time 1.011000156402588\n",
      "        time for verification: 1.2329676151275635\n",
      "layer progress, group 23 of 205 \n",
      "        time for training: 0.08199453353881836\n",
      "        actual verification time 0.4360013008117676\n",
      "        time for verification: 0.6618907451629639\n",
      "layer progress, group 24 of 205 \n",
      "        time for training: 0.10000014305114746\n",
      "        actual verification time 1.8870913982391357\n",
      "        time for verification: 2.1250946521759033\n",
      "layer progress, group 25 of 205 \n",
      "        time for training: 0.08599519729614258\n",
      "        actual verification time 0.7720005512237549\n",
      "        time for verification: 0.9990029335021973\n",
      "layer progress, group 26 of 205 \n",
      "        time for training: 0.08299636840820312\n",
      "        actual verification time 1.593569278717041\n",
      "        time for verification: 1.7925834655761719\n",
      "layer progress, group 27 of 205 \n",
      "        time for training: 0.07599854469299316\n",
      "        actual verification time 1.2576780319213867\n",
      "        time for verification: 1.478679895401001\n",
      "layer progress, group 28 of 205 \n",
      "        time for training: 0.07599949836730957\n",
      "        actual verification time 0.3215517997741699\n",
      "        time for verification: 0.5305590629577637\n",
      "layer progress, group 29 of 205 \n",
      "        time for training: 0.0959935188293457\n",
      "        actual verification time 0.7300012111663818\n",
      "        time for verification: 0.9525575637817383\n",
      "layer progress, group 30 of 205 \n",
      "        time for training: 0.08099627494812012\n",
      "        actual verification time 0.9220542907714844\n",
      "        time for verification: 1.1260590553283691\n",
      "layer progress, group 31 of 205 \n",
      "        time for training: 0.0939950942993164\n",
      "        actual verification time 0.3090031147003174\n",
      "        time for verification: 0.5340032577514648\n",
      "layer progress, group 32 of 205 \n",
      "        time for training: 0.0769968032836914\n",
      "        actual verification time 0.4600088596343994\n",
      "        time for verification: 0.6750466823577881\n",
      "layer progress, group 33 of 205 \n",
      "        time for training: 0.08499908447265625\n",
      "        actual verification time 0.44499945640563965\n",
      "        time for verification: 0.6549997329711914\n",
      "layer progress, group 34 of 205 \n",
      "        time for training: 0.08605027198791504\n",
      "        actual verification time 0.25999975204467773\n",
      "        time for verification: 0.4790043830871582\n",
      "layer progress, group 35 of 205 \n",
      "        time for training: 0.0845487117767334\n",
      "        actual verification time 0.5695650577545166\n",
      "        time for verification: 0.7905640602111816\n",
      "layer progress, group 36 of 205 \n",
      "        time for training: 0.09699845314025879\n",
      "        actual verification time 0.8210000991821289\n",
      "        time for verification: 1.0240001678466797\n",
      "layer progress, group 37 of 205 \n",
      "        time for training: 0.08900046348571777\n",
      "        actual verification time 0.3300001621246338\n",
      "        time for verification: 0.5575597286224365\n",
      "layer progress, group 38 of 205 \n",
      "        time for training: 0.0749964714050293\n",
      "        actual verification time 0.5765533447265625\n",
      "        time for verification: 0.7869892120361328\n",
      "layer progress, group 39 of 205 \n",
      "        time for training: 0.0879974365234375\n",
      "        actual verification time 0.7735500335693359\n",
      "        time for verification: 0.9865505695343018\n",
      "layer progress, group 40 of 205 \n",
      "        time for training: 0.08800005912780762\n",
      "        actual verification time 0.34999942779541016\n",
      "        time for verification: 0.5860650539398193\n",
      "layer progress, group 41 of 205 \n",
      "        time for training: 0.07599878311157227\n",
      "        actual verification time 0.19699978828430176\n",
      "        time for verification: 0.39405131340026855\n",
      "layer progress, group 42 of 205 \n",
      "        time for training: 0.08399510383605957\n",
      "        actual verification time 0.7631778717041016\n",
      "        time for verification: 1.0577561855316162\n",
      "layer progress, group 43 of 205 \n",
      "        time for training: 0.1000053882598877\n",
      "        actual verification time 0.7415869235992432\n",
      "        time for verification: 0.9606766700744629\n",
      "layer progress, group 44 of 205 \n",
      "        time for training: 0.085205078125\n",
      "        actual verification time 0.7231149673461914\n",
      "        time for verification: 0.9221060276031494\n",
      "layer progress, group 45 of 205 \n",
      "        time for training: 0.08358144760131836\n",
      "        actual verification time 0.2681117057800293\n",
      "        time for verification: 0.47811245918273926\n",
      "layer progress, group 46 of 205 \n",
      "        time for training: 0.09599947929382324\n",
      "        actual verification time 0.8271422386169434\n",
      "        time for verification: 1.0371475219726562\n",
      "layer progress, group 47 of 205 \n",
      "        time for training: 0.08700180053710938\n",
      "        actual verification time 0.32900023460388184\n",
      "        time for verification: 0.5579981803894043\n",
      "layer progress, group 48 of 205 \n",
      "        time for training: 0.07899999618530273\n",
      "        actual verification time 0.6140716075897217\n",
      "        time for verification: 0.8200716972351074\n",
      "layer progress, group 49 of 205 \n",
      "        time for training: 0.08199858665466309\n",
      "        actual verification time 0.21800017356872559\n",
      "        time for verification: 0.40900373458862305\n",
      "layer progress, group 50 of 205 \n",
      "        time for training: 0.0769965648651123\n",
      "        actual verification time 0.48804569244384766\n",
      "        time for verification: 0.6890459060668945\n",
      "layer progress, group 51 of 205 \n",
      "        time for training: 0.08499526977539062\n",
      "        actual verification time 0.354001522064209\n",
      "        time for verification: 0.5610008239746094\n",
      "layer progress, group 52 of 205 \n",
      "        time for training: 0.08199954032897949\n",
      "        actual verification time 1.2906181812286377\n",
      "        time for verification: 1.5186188220977783\n",
      "layer progress, group 53 of 205 \n",
      "        time for training: 0.07599902153015137\n",
      "        actual verification time 0.10699987411499023\n",
      "        time for verification: 0.3055901527404785\n",
      "layer progress, group 54 of 205 \n",
      "        time for training: 0.07999992370605469\n",
      "        actual verification time 0.47600317001342773\n",
      "        time for verification: 0.6779999732971191\n",
      "layer progress, group 55 of 205 \n",
      "        time for training: 0.07599997520446777\n",
      "        actual verification time 1.0669035911560059\n",
      "        time for verification: 1.2939043045043945\n",
      "layer progress, group 56 of 205 \n",
      "        time for training: 0.07699942588806152\n",
      "        actual verification time 1.280061960220337\n",
      "        time for verification: 1.5040643215179443\n",
      "layer progress, group 57 of 205 \n",
      "        time for training: 0.07599759101867676\n",
      "        actual verification time 0.7020924091339111\n",
      "        time for verification: 0.9376497268676758\n",
      "layer progress, group 58 of 205 \n",
      "        time for training: 0.07999944686889648\n",
      "        actual verification time 1.7370529174804688\n",
      "        time for verification: 1.9630532264709473\n",
      "layer progress, group 59 of 205 \n",
      "        time for training: 0.07599782943725586\n",
      "        actual verification time 0.8961739540100098\n",
      "        time for verification: 1.118173599243164\n",
      "layer progress, group 60 of 205 \n",
      "        time for training: 0.07999920845031738\n",
      "        actual verification time 0.1640000343322754\n",
      "        time for verification: 0.382000207901001\n",
      "layer progress, group 61 of 205 \n",
      "        time for training: 0.0969998836517334\n",
      "        actual verification time 0.31600046157836914\n",
      "        time for verification: 0.5520031452178955\n",
      "layer progress, group 62 of 205 \n",
      "        time for training: 0.07704710960388184\n",
      "        actual verification time 0.37000012397766113\n",
      "        time for verification: 0.5759999752044678\n",
      "layer progress, group 63 of 205 \n",
      "        time for training: 0.07700037956237793\n",
      "        actual verification time 0.4070000648498535\n",
      "        time for verification: 0.6210038661956787\n",
      "layer progress, group 64 of 205 \n",
      "        time for training: 0.08199596405029297\n",
      "        actual verification time 0.918999195098877\n",
      "        time for verification: 1.1376070976257324\n",
      "layer progress, group 65 of 205 \n",
      "        time for training: 0.07899880409240723\n",
      "        actual verification time 0.12304449081420898\n",
      "        time for verification: 0.31804442405700684\n",
      "layer progress, group 66 of 205 \n",
      "        time for training: 0.09299945831298828\n",
      "        actual verification time 0.5229930877685547\n",
      "        time for verification: 0.713005781173706\n",
      "layer progress, group 67 of 205 \n",
      "        time for training: 0.07999444007873535\n",
      "        actual verification time 0.42158937454223633\n",
      "        time for verification: 0.631594181060791\n",
      "layer progress, group 68 of 205 \n",
      "        time for training: 0.09399580955505371\n",
      "        actual verification time 0.39603447914123535\n",
      "        time for verification: 0.6290361881256104\n",
      "layer progress, group 69 of 205 \n",
      "        time for training: 0.08199810981750488\n",
      "        actual verification time 0.4759998321533203\n",
      "        time for verification: 0.6800031661987305\n",
      "layer progress, group 70 of 205 \n",
      "        time for training: 0.07599616050720215\n",
      "        actual verification time 0.6849994659423828\n",
      "        time for verification: 0.9012472629547119\n",
      "layer progress, group 71 of 205 \n",
      "        time for training: 0.08199405670166016\n",
      "        actual verification time 0.3190004825592041\n",
      "        time for verification: 0.5080063343048096\n",
      "layer progress, group 72 of 205 \n",
      "        time for training: 0.09099364280700684\n",
      "        actual verification time 0.23599982261657715\n",
      "        time for verification: 0.440000057220459\n",
      "layer progress, group 73 of 205 \n",
      "        time for training: 0.08500027656555176\n",
      "        actual verification time 0.21205496788024902\n",
      "        time for verification: 0.41805481910705566\n",
      "layer progress, group 74 of 205 \n",
      "        time for training: 0.09100055694580078\n",
      "        actual verification time 0.4459996223449707\n",
      "        time for verification: 0.6599998474121094\n",
      "layer progress, group 75 of 205 \n",
      "        time for training: 0.09099912643432617\n",
      "        actual verification time 1.0257797241210938\n",
      "        time for verification: 1.2317826747894287\n",
      "layer progress, group 76 of 205 \n",
      "        time for training: 0.07699775695800781\n",
      "        actual verification time 1.0209994316101074\n",
      "        time for verification: 1.2520029544830322\n",
      "layer progress, group 77 of 205 \n",
      "        time for training: 0.07899689674377441\n",
      "        actual verification time 0.5840451717376709\n",
      "        time for verification: 0.792048454284668\n",
      "layer progress, group 78 of 205 \n",
      "        time for training: 0.08899831771850586\n",
      "        actual verification time 0.4490842819213867\n",
      "        time for verification: 0.6620886325836182\n",
      "layer progress, group 79 of 205 \n",
      "        time for training: 0.07499575614929199\n",
      "        actual verification time 0.4529995918273926\n",
      "        time for verification: 0.6600031852722168\n",
      "layer progress, group 80 of 205 \n",
      "        time for training: 0.07999515533447266\n",
      "        actual verification time 0.5755538940429688\n",
      "        time for verification: 0.7785565853118896\n",
      "layer progress, group 81 of 205 \n",
      "        time for training: 0.07699751853942871\n",
      "        actual verification time 0.6775574684143066\n",
      "        time for verification: 0.883563756942749\n",
      "layer progress, group 82 of 205 \n",
      "        time for training: 0.08300018310546875\n",
      "        actual verification time 0.7579998970031738\n",
      "        time for verification: 0.9690032005310059\n",
      "layer progress, group 83 of 205 \n",
      "        time for training: 0.09499692916870117\n",
      "        actual verification time 0.5125701427459717\n",
      "        time for verification: 0.7235684394836426\n",
      "layer progress, group 84 of 205 \n",
      "        time for training: 0.0839996337890625\n",
      "        actual verification time 0.5900001525878906\n",
      "        time for verification: 0.797003984451294\n",
      "layer progress, group 85 of 205 \n",
      "        time for training: 0.08099651336669922\n",
      "        actual verification time 0.5100679397583008\n",
      "        time for verification: 0.7360708713531494\n",
      "layer progress, group 86 of 205 \n",
      "        time for training: 0.08099865913391113\n",
      "        actual verification time 0.5735495090484619\n",
      "        time for verification: 0.7855486869812012\n",
      "layer progress, group 87 of 205 \n",
      "        time for training: 0.09055376052856445\n",
      "        actual verification time 1.739999771118164\n",
      "        time for verification: 1.9800012111663818\n",
      "layer progress, group 88 of 205 \n",
      "        time for training: 0.07599711418151855\n",
      "        actual verification time 0.6519997119903564\n",
      "        time for verification: 0.867058277130127\n",
      "layer progress, group 89 of 205 \n",
      "        time for training: 0.07700347900390625\n",
      "        actual verification time 0.6129999160766602\n",
      "        time for verification: 0.8159959316253662\n",
      "layer progress, group 90 of 205 \n",
      "        time for training: 0.07599806785583496\n",
      "        actual verification time 0.925518274307251\n",
      "        time for verification: 1.1415212154388428\n",
      "layer progress, group 91 of 205 \n",
      "        time for training: 0.07599830627441406\n",
      "        actual verification time 0.5860724449157715\n",
      "        time for verification: 0.7916035652160645\n",
      "layer progress, group 92 of 205 \n",
      "        time for training: 0.07699871063232422\n",
      "        actual verification time 0.2359941005706787\n",
      "        time for verification: 0.41400146484375\n",
      "layer progress, group 93 of 205 \n",
      "        time for training: 0.08200383186340332\n",
      "        actual verification time 0.5280001163482666\n",
      "        time for verification: 0.7309970855712891\n",
      "layer progress, group 94 of 205 \n",
      "        time for training: 0.08799958229064941\n",
      "        actual verification time 1.2085583209991455\n",
      "        time for verification: 1.429555892944336\n",
      "layer progress, group 95 of 205 \n",
      "        time for training: 0.07899975776672363\n",
      "        actual verification time 0.6928696632385254\n",
      "        time for verification: 0.9088733196258545\n",
      "layer progress, group 96 of 205 \n",
      "        time for training: 0.08299612998962402\n",
      "        actual verification time 1.5469996929168701\n",
      "        time for verification: 1.7769999504089355\n",
      "layer progress, group 97 of 205 \n",
      "        time for training: 0.07700014114379883\n",
      "        actual verification time 1.531999111175537\n",
      "        time for verification: 1.7545413970947266\n",
      "layer progress, group 98 of 205 \n",
      "        time for training: 0.08799910545349121\n",
      "        actual verification time 0.44300007820129395\n",
      "        time for verification: 0.6507821083068848\n",
      "layer progress, group 99 of 205 \n",
      "        time for training: 0.08499979972839355\n",
      "        actual verification time 0.46004748344421387\n",
      "        time for verification: 0.6770486831665039\n",
      "layer progress, group 100 of 205 \n",
      "        time for training: 0.08999943733215332\n",
      "        actual verification time 0.6969993114471436\n",
      "        time for verification: 0.9005899429321289\n",
      "layer progress, group 101 of 205 \n",
      "        time for training: 0.08199715614318848\n",
      "        actual verification time 2.7051117420196533\n",
      "        time for verification: 2.93011212348938\n",
      "layer progress, group 102 of 205 \n",
      "        time for training: 0.09299945831298828\n",
      "        actual verification time 0.8555431365966797\n",
      "        time for verification: 1.0825436115264893\n",
      "layer progress, group 103 of 205 \n",
      "        time for training: 0.07900047302246094\n",
      "        actual verification time 1.0360000133514404\n",
      "        time for verification: 1.255002737045288\n",
      "layer progress, group 104 of 205 \n",
      "        time for training: 0.07599830627441406\n",
      "        actual verification time 0.016003847122192383\n",
      "        time for verification: 0.2720022201538086\n",
      "layer progress, group 105 of 205 \n",
      "        time for training: 0.08162188529968262\n",
      "        actual verification time 0.24699878692626953\n",
      "        time for verification: 0.4620029926300049\n",
      "layer progress, group 106 of 205 \n",
      "        time for training: 0.09099698066711426\n",
      "        actual verification time 0.6360001564025879\n",
      "        time for verification: 0.8560004234313965\n",
      "layer progress, group 107 of 205 \n",
      "        time for training: 0.07999968528747559\n",
      "        actual verification time 0.08300042152404785\n",
      "        time for verification: 0.29500317573547363\n",
      "layer progress, group 108 of 205 \n",
      "        time for training: 0.09599685668945312\n",
      "        actual verification time 0.2559983730316162\n",
      "        time for verification: 0.44899964332580566\n",
      "layer progress, group 109 of 205 \n",
      "        time for training: 0.08800029754638672\n",
      "        actual verification time 0.9931778907775879\n",
      "        time for verification: 1.2321817874908447\n",
      "layer progress, group 110 of 205 \n",
      "        time for training: 0.07899665832519531\n",
      "        actual verification time 0.7919983863830566\n",
      "        time for verification: 1.0480024814605713\n",
      "layer progress, group 111 of 205 \n",
      "        time for training: 0.07699775695800781\n",
      "        actual verification time 1.106043815612793\n",
      "        time for verification: 1.31404447555542\n",
      "layer progress, group 112 of 205 \n",
      "        time for training: 0.08699965476989746\n",
      "        actual verification time 0.5939998626708984\n",
      "        time for verification: 0.8090002536773682\n",
      "layer progress, group 113 of 205 \n",
      "        time for training: 0.08099961280822754\n",
      "        actual verification time 0.8836939334869385\n",
      "        time for verification: 1.0986993312835693\n",
      "layer progress, group 114 of 205 \n",
      "        time for training: 0.08199715614318848\n",
      "        actual verification time 0.590996265411377\n",
      "        time for verification: 0.7930014133453369\n",
      "layer progress, group 115 of 205 \n",
      "        time for training: 0.0749974250793457\n",
      "        actual verification time 0.3925490379333496\n",
      "        time for verification: 0.609553337097168\n",
      "layer progress, group 116 of 205 \n",
      "        time for training: 0.07599782943725586\n",
      "        actual verification time 0.20400047302246094\n",
      "        time for verification: 0.4060041904449463\n",
      "layer progress, group 117 of 205 \n",
      "        time for training: 0.07799863815307617\n",
      "        actual verification time 0.5530009269714355\n",
      "        time for verification: 0.780022144317627\n",
      "layer progress, group 118 of 205 \n",
      "        time for training: 0.07999944686889648\n",
      "        actual verification time 0.004000425338745117\n",
      "        time for verification: 0.09900069236755371\n",
      "layer progress, group 119 of 205 \n",
      "        time for training: 0.08099961280822754\n",
      "        actual verification time 0.5546982288360596\n",
      "        time for verification: 0.751697301864624\n",
      "layer progress, group 120 of 205 \n",
      "        time for training: 0.07599902153015137\n",
      "        actual verification time 0.1920020580291748\n",
      "        time for verification: 0.3820030689239502\n",
      "layer progress, group 121 of 205 \n",
      "        time for training: 0.07999801635742188\n",
      "        actual verification time 0.8580009937286377\n",
      "        time for verification: 1.0741708278656006\n",
      "layer progress, group 122 of 205 \n",
      "        time for training: 0.07899904251098633\n",
      "        actual verification time 0.06000113487243652\n",
      "        time for verification: 0.19800281524658203\n",
      "layer progress, group 123 of 205 \n",
      "        time for training: 0.0749974250793457\n",
      "        actual verification time 0.4530029296875\n",
      "        time for verification: 0.6500034332275391\n",
      "layer progress, group 124 of 205 \n",
      "        time for training: 0.07599687576293945\n",
      "        actual verification time 0.5260381698608398\n",
      "        time for verification: 0.7320406436920166\n",
      "layer progress, group 125 of 205 \n",
      "        time for training: 0.08399653434753418\n",
      "        actual verification time 0.5263652801513672\n",
      "        time for verification: 0.7223656177520752\n",
      "layer progress, group 126 of 205 \n",
      "        time for training: 0.08000016212463379\n",
      "        actual verification time 0.1810002326965332\n",
      "        time for verification: 0.38499951362609863\n",
      "layer progress, group 127 of 205 \n",
      "        time for training: 0.07799983024597168\n",
      "        actual verification time 1.1530840396881104\n",
      "        time for verification: 1.367086410522461\n",
      "layer progress, group 128 of 205 \n",
      "        time for training: 0.07999777793884277\n",
      "        actual verification time 0.5459997653961182\n",
      "        time for verification: 0.7669994831085205\n",
      "layer progress, group 129 of 205 \n",
      "        time for training: 0.08999991416931152\n",
      "        actual verification time 0.9305603504180908\n",
      "        time for verification: 1.1445634365081787\n",
      "layer progress, group 130 of 205 \n",
      "        time for training: 0.07999873161315918\n",
      "        actual verification time 0.01300048828125\n",
      "        time for verification: 0.17800116539001465\n",
      "layer progress, group 131 of 205 \n",
      "        time for training: 0.08399724960327148\n",
      "        actual verification time 0.014999151229858398\n",
      "        time for verification: 0.21500015258789062\n",
      "layer progress, group 132 of 205 \n",
      "        time for training: 0.08000016212463379\n",
      "        actual verification time 0.7249982357025146\n",
      "        time for verification: 0.9340004920959473\n",
      "layer progress, group 133 of 205 \n",
      "        time for training: 0.07899904251098633\n",
      "        actual verification time 0.4269998073577881\n",
      "        time for verification: 0.6220006942749023\n",
      "layer progress, group 134 of 205 \n",
      "        time for training: 0.09599924087524414\n",
      "        actual verification time 0.3989987373352051\n",
      "        time for verification: 0.6106400489807129\n",
      "layer progress, group 135 of 205 \n",
      "        time for training: 0.09700989723205566\n",
      "        actual verification time 1.7520451545715332\n",
      "        time for verification: 1.9595897197723389\n",
      "layer progress, group 136 of 205 \n",
      "        time for training: 0.07599973678588867\n",
      "        actual verification time 0.3445875644683838\n",
      "        time for verification: 0.5585880279541016\n",
      "layer progress, group 137 of 205 \n",
      "        time for training: 0.08299994468688965\n",
      "        actual verification time 0.7790031433105469\n",
      "        time for verification: 0.9890015125274658\n",
      "layer progress, group 138 of 205 \n",
      "        time for training: 0.08999872207641602\n",
      "        actual verification time 0.20899605751037598\n",
      "        time for verification: 0.39400410652160645\n",
      "layer progress, group 139 of 205 \n",
      "        time for training: 0.09799671173095703\n",
      "        actual verification time 0.9250643253326416\n",
      "        time for verification: 1.147068738937378\n",
      "layer progress, group 140 of 205 \n",
      "        time for training: 0.08299636840820312\n",
      "        actual verification time 1.18257737159729\n",
      "        time for verification: 1.3945789337158203\n",
      "layer progress, group 141 of 205 \n",
      "        time for training: 0.08100032806396484\n",
      "        actual verification time 0.49000072479248047\n",
      "        time for verification: 0.7010009288787842\n",
      "layer progress, group 142 of 205 \n",
      "        time for training: 0.07599902153015137\n",
      "        actual verification time 0.6399998664855957\n",
      "        time for verification: 0.8580012321472168\n",
      "layer progress, group 143 of 205 \n",
      "        time for training: 0.07699871063232422\n",
      "        actual verification time 0.6496846675872803\n",
      "        time for verification: 0.8786916732788086\n",
      "layer progress, group 144 of 205 \n",
      "        time for training: 0.07699775695800781\n",
      "        actual verification time 0.5579957962036133\n",
      "        time for verification: 0.7650010585784912\n",
      "layer progress, group 145 of 205 \n",
      "        time for training: 0.0709996223449707\n",
      "        actual verification time 0.06099557876586914\n",
      "        time for verification: 0.24700021743774414\n",
      "layer progress, group 146 of 205 \n",
      "        time for training: 0.08199954032897949\n",
      "        actual verification time 1.1956205368041992\n",
      "        time for verification: 1.4126198291778564\n",
      "layer progress, group 147 of 205 \n",
      "        time for training: 0.08599495887756348\n",
      "        actual verification time 0.35000014305114746\n",
      "        time for verification: 0.5500001907348633\n",
      "layer progress, group 148 of 205 \n",
      "        time for training: 0.08100008964538574\n",
      "        actual verification time 0.6160006523132324\n",
      "        time for verification: 0.8419995307922363\n",
      "layer progress, group 149 of 205 \n",
      "        time for training: 0.07700014114379883\n",
      "        actual verification time 0.20699429512023926\n",
      "        time for verification: 0.40400028228759766\n",
      "layer progress, group 150 of 205 \n",
      "        time for training: 0.08899974822998047\n",
      "        actual verification time 0.012999534606933594\n",
      "        time for verification: 0.17400169372558594\n",
      "layer progress, group 151 of 205 \n",
      "        time for training: 0.08045220375061035\n",
      "        actual verification time 0.0800008773803711\n",
      "        time for verification: 0.2800009250640869\n",
      "layer progress, group 152 of 205 \n",
      "        time for training: 0.09399890899658203\n",
      "        actual verification time 0.009999990463256836\n",
      "        time for verification: 0.192000150680542\n",
      "layer progress, group 153 of 205 \n",
      "        time for training: 0.08699917793273926\n",
      "        actual verification time 3.3711397647857666\n",
      "        time for verification: 3.5931408405303955\n",
      "layer progress, group 154 of 205 \n",
      "        time for training: 0.09000062942504883\n",
      "        actual verification time 0.9375925064086914\n",
      "        time for verification: 1.1815919876098633\n",
      "layer progress, group 155 of 205 \n",
      "        time for training: 0.08558106422424316\n",
      "        actual verification time 1.1729986667633057\n",
      "        time for verification: 1.4139995574951172\n",
      "layer progress, group 156 of 205 \n",
      "        time for training: 0.08199882507324219\n",
      "        actual verification time 0.20099949836730957\n",
      "        time for verification: 0.40300464630126953\n",
      "layer progress, group 157 of 205 \n",
      "        time for training: 0.07599544525146484\n",
      "        actual verification time 0.9840002059936523\n",
      "        time for verification: 1.2080504894256592\n",
      "layer progress, group 158 of 205 \n",
      "        time for training: 0.08099651336669922\n",
      "        actual verification time 0.9000842571258545\n",
      "        time for verification: 1.1500864028930664\n",
      "layer progress, group 159 of 205 \n",
      "        time for training: 0.0839991569519043\n",
      "        actual verification time 0.13000202178955078\n",
      "        time for verification: 0.32799744606018066\n",
      "layer progress, group 160 of 205 \n",
      "        time for training: 0.0780019760131836\n",
      "        actual verification time 0.9180006980895996\n",
      "        time for verification: 1.1535627841949463\n",
      "layer progress, group 161 of 205 \n",
      "        time for training: 0.08799600601196289\n",
      "        actual verification time 0.617997407913208\n",
      "        time for verification: 0.8390004634857178\n",
      "layer progress, group 162 of 205 \n",
      "        time for training: 0.07599925994873047\n",
      "        actual verification time 0.3229975700378418\n",
      "        time for verification: 0.5165176391601562\n",
      "layer progress, group 163 of 205 \n",
      "        time for training: 0.08199906349182129\n",
      "        actual verification time 0.13900017738342285\n",
      "        time for verification: 0.3310098648071289\n",
      "layer progress, group 164 of 205 \n",
      "        time for training: 0.09599041938781738\n",
      "        actual verification time 0.648003339767456\n",
      "        time for verification: 0.880002498626709\n",
      "layer progress, group 165 of 205 \n",
      "        time for training: 0.08599734306335449\n",
      "        actual verification time 0.9766225814819336\n",
      "        time for verification: 1.2156288623809814\n",
      "layer progress, group 166 of 205 \n",
      "        time for training: 0.0820016860961914\n",
      "        actual verification time 0.1829996109008789\n",
      "        time for verification: 0.4810061454772949\n",
      "layer progress, group 167 of 205 \n",
      "        time for training: 0.07999634742736816\n",
      "        actual verification time 0.3486461639404297\n",
      "        time for verification: 0.5526471138000488\n",
      "layer progress, group 168 of 205 \n",
      "        time for training: 0.0839991569519043\n",
      "        actual verification time 0.5875694751739502\n",
      "        time for verification: 0.8025696277618408\n",
      "layer progress, group 169 of 205 \n",
      "        time for training: 0.08000016212463379\n",
      "        actual verification time 0.2709991931915283\n",
      "        time for verification: 0.469005823135376\n",
      "layer progress, group 170 of 205 \n",
      "        time for training: 0.09599494934082031\n",
      "        actual verification time 0.5957434177398682\n",
      "        time for verification: 0.8217446804046631\n",
      "layer progress, group 171 of 205 \n",
      "        time for training: 0.08199834823608398\n",
      "        actual verification time 0.9310011863708496\n",
      "        time for verification: 1.1340010166168213\n",
      "layer progress, group 172 of 205 \n",
      "        time for training: 0.0782468318939209\n",
      "        actual verification time 0.6380038261413574\n",
      "        time for verification: 0.8510055541992188\n",
      "layer progress, group 173 of 205 \n",
      "        time for training: 0.07799649238586426\n",
      "        actual verification time 0.3359999656677246\n",
      "        time for verification: 0.5419981479644775\n",
      "layer progress, group 174 of 205 \n",
      "        time for training: 0.08800172805786133\n",
      "        actual verification time 0.5815823078155518\n",
      "        time for verification: 0.81858229637146\n",
      "layer progress, group 175 of 205 \n",
      "        time for training: 0.0879979133605957\n",
      "        actual verification time 0.2180008888244629\n",
      "        time for verification: 0.43200135231018066\n",
      "layer progress, group 176 of 205 \n",
      "        time for training: 0.08299827575683594\n",
      "        actual verification time 0.742002010345459\n",
      "        time for verification: 0.9720032215118408\n",
      "layer progress, group 177 of 205 \n",
      "        time for training: 0.09799838066101074\n",
      "        actual verification time 1.3341267108917236\n",
      "        time for verification: 1.5621302127838135\n",
      "layer progress, group 178 of 205 \n",
      "        time for training: 0.08999752998352051\n",
      "        actual verification time 1.168001413345337\n",
      "        time for verification: 1.3900020122528076\n",
      "layer progress, group 179 of 205 \n",
      "        time for training: 0.07599806785583496\n",
      "        actual verification time 0.9189980030059814\n",
      "        time for verification: 1.1420443058013916\n",
      "layer progress, group 180 of 205 \n",
      "        time for training: 0.07599949836730957\n",
      "        actual verification time 1.4547743797302246\n",
      "        time for verification: 1.6717770099639893\n",
      "layer progress, group 181 of 205 \n",
      "        time for training: 0.09199714660644531\n",
      "        actual verification time 0.26799988746643066\n",
      "        time for verification: 0.4920003414154053\n",
      "layer progress, group 182 of 205 \n",
      "        time for training: 0.07599949836730957\n",
      "        actual verification time 0.21899986267089844\n",
      "        time for verification: 0.4200022220611572\n",
      "layer progress, group 183 of 205 \n",
      "        time for training: 0.0859978199005127\n",
      "        actual verification time 0.2500002384185791\n",
      "        time for verification: 0.4510035514831543\n",
      "layer progress, group 184 of 205 \n",
      "        time for training: 0.08699822425842285\n",
      "        actual verification time 1.2025468349456787\n",
      "        time for verification: 1.4235460758209229\n",
      "layer progress, group 185 of 205 \n",
      "        time for training: 0.07599735260009766\n",
      "        actual verification time 1.8418190479278564\n",
      "        time for verification: 2.0558207035064697\n",
      "layer progress, group 186 of 205 \n",
      "        time for training: 0.07699775695800781\n",
      "        actual verification time 1.7070343494415283\n",
      "        time for verification: 1.957043170928955\n",
      "layer progress, group 187 of 205 \n",
      "        time for training: 0.07599353790283203\n",
      "        actual verification time 0.3379998207092285\n",
      "        time for verification: 0.5560002326965332\n",
      "layer progress, group 188 of 205 \n",
      "        time for training: 0.0800011157989502\n",
      "        actual verification time 0.8880007266998291\n",
      "        time for verification: 1.086000680923462\n",
      "layer progress, group 189 of 205 \n",
      "        time for training: 0.08499979972839355\n",
      "        actual verification time 0.586047887802124\n",
      "        time for verification: 0.8041086196899414\n",
      "layer progress, group 190 of 205 \n",
      "        time for training: 0.08655357360839844\n",
      "        actual verification time 0.09000992774963379\n",
      "        time for verification: 0.2810094356536865\n",
      "layer progress, group 191 of 205 \n",
      "        time for training: 0.09099054336547852\n",
      "        actual verification time 0.6630008220672607\n",
      "        time for verification: 0.8770008087158203\n",
      "layer progress, group 192 of 205 \n",
      "        time for training: 0.08899903297424316\n",
      "        actual verification time 0.6985640525817871\n",
      "        time for verification: 0.916569709777832\n",
      "layer progress, group 193 of 205 \n",
      "        time for training: 0.07999968528747559\n",
      "        actual verification time 0.22100162506103516\n",
      "        time for verification: 0.431011438369751\n",
      "layer progress, group 194 of 205 \n",
      "        time for training: 0.0839850902557373\n",
      "        actual verification time 0.0829923152923584\n",
      "        time for verification: 0.24500465393066406\n",
      "layer progress, group 195 of 205 \n",
      "        time for training: 0.08799457550048828\n",
      "        actual verification time 0.9370155334472656\n",
      "        time for verification: 1.140014886856079\n",
      "layer progress, group 196 of 205 \n",
      "        time for training: 0.07800126075744629\n",
      "        actual verification time 0.30263495445251465\n",
      "        time for verification: 0.4946310520172119\n",
      "layer progress, group 197 of 205 \n",
      "        time for training: 0.09800004959106445\n",
      "        actual verification time 0.25800108909606934\n",
      "        time for verification: 0.4589996337890625\n",
      "layer progress, group 198 of 205 \n",
      "        time for training: 0.07799816131591797\n",
      "        actual verification time 0.18500208854675293\n",
      "        time for verification: 0.3890037536621094\n",
      "layer progress, group 199 of 205 \n",
      "        time for training: 0.09599661827087402\n",
      "        actual verification time 0.15899920463562012\n",
      "        time for verification: 0.35300612449645996\n",
      "layer progress, group 200 of 205 \n",
      "        time for training: 0.08299517631530762\n",
      "        actual verification time 0.29900074005126953\n",
      "        time for verification: 0.4920015335083008\n",
      "layer progress, group 201 of 205 \n",
      "        time for training: 0.08099603652954102\n",
      "        actual verification time 1.1080124378204346\n",
      "        time for verification: 1.334191083908081\n",
      "layer progress, group 202 of 205 \n",
      "        time for training: 0.07999873161315918\n",
      "        actual verification time 0.477985143661499\n",
      "        time for verification: 0.69700026512146\n",
      "layer progress, group 203 of 205 \n",
      "        time for training: 0.09400463104248047\n",
      "        actual verification time 0.6901876926422119\n",
      "        time for verification: 0.9401853084564209\n",
      "layer progress, group 204 of 205 \n",
      "        time for training: 0.08199644088745117\n",
      "        actual verification time 0.83856201171875\n",
      "        time for verification: 1.0585591793060303\n",
      "\n",
      "approximation of layer: 1\n",
      "layer progress, group 0 of 103 \n",
      "        time for training: 0.08800005912780762\n",
      "        actual verification time 300.3516376018524\n",
      "        time for verification: 300.61664056777954\n",
      "aborting because of force break\n"
     ]
    }
   ],
   "source": [
    "group_size = 5\n",
    "eps = 0.01\n",
    "icnns = []\n",
    "for i in range((len(parameter_list) - 2) // 2):\n",
    "    layer_index = int(i / 2)\n",
    "    in_size = nn.layer_widths[layer_index + 1]\n",
    "    icnns.append([])\n",
    "    for k in range(in_size // group_size):\n",
    "        next_net = ICNNLogical([group_size, 10, 10, 10, 1], force_positive_init=False, with_two_layers=False, init_scaling=10,\n",
    "                                 init_all_with_zeros=False)\n",
    "        icnns[i].append(next_net)\n",
    "    if in_size % group_size > 0:\n",
    "        next_net = ICNNLogical([in_size % group_size, 10, 10, 10, 1], force_positive_init=False, with_two_layers=False,\n",
    "                               init_scaling=10,\n",
    "                               init_all_with_zeros=False)\n",
    "        icnns[i].append(next_net)\n",
    "\n",
    "print(math.ceil(nn.layer_widths[1] / group_size)+1)\n",
    "icnns, all_group_indices, fixed_neuron_per_layer_lower, fixed_neuron_per_layer_upper = \\\n",
    "    multidhov.start_verification(nn, test_image, icnns, group_size, eps=eps, icnn_epochs=10, icnn_batch_size=1000,\n",
    "                                 sample_count=100, sample_new=False, use_over_approximation=True, break_after=math.ceil(nn.layer_widths[1] / group_size)+1,\n",
    "                                 sample_over_input_space=False, sample_over_output_space=True, use_icnn_bounds=True, use_fixed_neurons=False,\n",
    "                                 force_inclusion_steps=0, preemptive_stop=False, even_gradient_training=False,\n",
    "                                 keep_ambient_space=True, data_grad_descent_steps=0, train_outer=False,\n",
    "                                 should_plot=\"none\", optimizer=\"SdLBFGS\", init_network=True, adapt_lambda=\"none\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounds affine out \n",
      " [[tensor([ 0.2088,  0.0196, -0.0026,  ..., -1.3163, -0.3677, -0.2236],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>), tensor([ 0.7791,  0.5886,  0.5620,  ..., -0.7273,  0.2118,  0.3357],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)], [tensor([-2.3678, -2.2506, -1.4631, -1.5480, -1.6997, -2.3157, -2.0312, -2.1657,\n",
      "        -2.4451, -2.1094, -2.5736, -1.5114, -1.7204, -1.6585, -1.9900, -2.2936,\n",
      "        -1.8326, -1.9801, -2.0940, -1.9852, -2.4245, -2.3254, -1.7885, -2.0473,\n",
      "        -1.7248, -2.0310, -2.1796, -1.5130, -2.1948, -1.2174, -2.3810, -1.6069,\n",
      "        -2.2250, -1.0840, -2.1734, -1.6119, -2.2030, -2.1282, -2.2584, -2.3525,\n",
      "        -1.9250, -2.2268, -1.9972, -1.8989, -2.1081, -1.8777, -2.4823, -2.0515,\n",
      "        -2.2419, -2.3808, -2.0566, -2.1669, -1.8904, -2.0341, -2.4128, -2.7350,\n",
      "        -2.8463, -1.6933, -2.4030, -2.0562, -1.9528, -2.1218, -2.4711, -2.3628,\n",
      "        -2.2642, -2.0658, -1.8225, -1.7588, -2.5546, -1.6129, -1.8245, -2.1414,\n",
      "        -1.9952, -1.9148, -2.2306, -2.0037, -2.5366, -1.4191, -2.1562, -1.9158,\n",
      "        -2.1424, -1.8178, -2.2539, -2.0352, -2.1833, -1.5824, -2.2810, -1.4759,\n",
      "        -2.3608, -1.8562, -2.4729, -2.1235, -2.2414, -1.7541, -2.2816, -2.0879,\n",
      "        -2.0146, -1.8970, -2.4248, -2.0457, -1.6711, -2.2117, -1.8608, -2.7619,\n",
      "        -1.7872, -1.3919, -1.9690, -1.9393, -2.2661, -1.6468, -2.1895, -2.1893,\n",
      "        -1.9798, -2.1747, -1.8322, -2.2181, -2.1823, -1.9345, -2.2441, -1.9113,\n",
      "        -2.1066, -2.3348, -1.8618, -2.3357, -1.8482, -2.2501, -2.1368, -1.9601,\n",
      "        -1.7689, -2.5784, -2.6144, -2.2968, -2.0713, -2.2545, -2.4273, -2.6481,\n",
      "        -1.8894, -2.2630, -1.9883, -1.8003, -1.3780, -1.8716, -2.0415, -2.0463,\n",
      "        -2.5830, -2.0505, -1.8829, -1.3248, -2.2755, -2.2885, -2.6692, -2.1592,\n",
      "        -1.9485, -1.7881, -1.9013, -2.4198, -1.8273, -1.7009, -1.7606, -1.8754,\n",
      "        -1.7755, -1.9315, -2.2627, -2.0458, -2.3787, -1.7453, -2.1708, -2.3769,\n",
      "        -1.7394, -2.0193, -1.3378, -2.1757, -1.9578, -2.4132, -2.0921, -2.1697,\n",
      "        -2.3222, -2.1388, -1.9731, -2.4500, -1.7567, -2.0712, -1.8797, -2.4587,\n",
      "        -2.4395, -2.0947, -1.4238, -1.6812, -2.0884, -2.0478, -2.1802, -2.1793,\n",
      "        -1.7242, -2.2525, -2.0815, -2.1800, -2.2343, -2.2170, -2.2868, -2.3326,\n",
      "        -2.0985, -1.9025, -2.6216, -2.6766, -2.8230, -2.0409, -1.9765, -2.5223,\n",
      "        -2.5186, -2.3216, -2.1099, -1.8069, -1.8001, -1.8937, -2.3844, -1.5554,\n",
      "        -1.7413, -1.9307, -1.7702, -2.1569, -2.5157, -1.9025, -2.8545, -2.3963,\n",
      "        -1.9962, -2.0257, -2.0677, -1.7343, -1.7432, -1.9814, -2.0761, -1.9112,\n",
      "        -1.9711, -2.5830, -1.7412, -2.0081, -1.8990, -2.3547, -1.9318, -1.6319,\n",
      "        -1.3847, -2.1291, -2.3581, -2.3676, -2.3591, -1.6119, -1.5264, -2.2582,\n",
      "        -1.9452, -2.0983, -1.5434, -2.4950, -2.3965, -2.1024, -2.1247, -2.0916,\n",
      "        -2.4071, -1.6716, -2.2409, -2.0783, -1.9700, -1.7985, -1.9317, -1.9193,\n",
      "        -2.8491, -2.1171, -2.0579, -2.2669, -1.9235, -1.8752, -2.1481, -1.7179,\n",
      "        -2.2722, -2.0011, -2.3476, -1.9064, -2.6052, -1.9573, -2.5701, -2.5449,\n",
      "        -2.2295, -2.4069, -1.8491, -1.6295, -2.2801, -2.3843, -1.8899, -2.2901,\n",
      "        -2.2081, -2.2685, -2.5606, -2.3657, -2.0694, -1.8586, -2.1898, -2.7850,\n",
      "        -2.6666, -2.2256, -1.8080, -2.3675, -2.0387, -1.7699, -1.7594, -1.9638,\n",
      "        -1.7930, -2.5955, -2.2309, -2.1528, -2.1117, -1.1386, -1.7030, -2.1813,\n",
      "        -2.1974, -2.0460, -2.0127, -2.1019, -1.7086, -1.7625, -1.2394, -1.9954,\n",
      "        -2.0407, -2.5292, -2.1938, -2.6148, -1.9193, -1.8724, -2.0353, -1.8261,\n",
      "        -1.7046, -1.8707, -1.7427, -2.3210, -2.0953, -2.0234, -1.8730, -1.9157,\n",
      "        -2.1633, -2.2956, -1.8241, -1.9183, -1.9252, -2.2855, -1.7693, -2.0694,\n",
      "        -2.2078, -2.2395, -1.8100, -1.8931, -2.4937, -1.6027, -1.7344, -2.4556,\n",
      "        -1.7214, -2.1970, -1.7753, -2.5441, -2.1143, -1.7223, -2.5505, -1.8186,\n",
      "        -2.3532, -1.9206, -2.3041, -2.0582, -1.8424, -1.8498, -2.1913, -2.2310,\n",
      "        -2.1394, -2.0301, -2.6459, -1.6225, -2.2951, -2.5787, -2.3691, -2.5596,\n",
      "        -2.5056, -2.1484, -1.7632, -2.2438, -2.3388, -2.1026, -2.3081, -1.9033,\n",
      "        -2.3444, -1.8191, -1.9034, -1.3551, -2.2204, -1.6438, -2.2685, -1.7940,\n",
      "        -1.6682, -2.2030, -2.1190, -2.3994, -2.0798, -2.8044, -1.7596, -2.6453,\n",
      "        -1.6814, -2.1698, -1.7821, -1.6353, -2.7215, -1.7791, -2.2148, -2.1106,\n",
      "        -1.8514, -2.5463, -2.1293, -1.9078, -2.0379, -2.4073, -2.1459, -2.1028,\n",
      "        -2.7059, -2.1078, -2.5884, -1.8202, -2.0828, -2.1631, -2.0025, -1.8010,\n",
      "        -1.8327, -2.1799, -1.9555, -1.9659, -2.4192, -1.6459, -1.8146, -1.9345,\n",
      "        -2.6203, -1.9685, -2.5791, -2.2627, -2.0145, -1.9692, -2.2245, -1.6481,\n",
      "        -1.9672, -2.0471, -2.0556, -2.2650, -2.1470, -2.2929, -2.2956, -1.7933,\n",
      "        -2.4848, -1.8552, -1.7189, -2.2088, -2.2806, -1.4828, -1.8546, -2.1495,\n",
      "        -2.3400, -2.2611, -1.9456, -2.0526, -2.1521, -2.4529, -1.5742, -2.0786,\n",
      "        -1.8988, -1.7005, -2.1786, -2.0611, -2.4032, -1.8272, -2.2149, -2.3349,\n",
      "        -2.3801, -2.3148, -1.7153, -2.4166, -1.9706, -2.0655, -2.4320, -1.9155,\n",
      "        -2.3920, -2.0351, -1.7001, -2.1501, -1.9242, -2.3359, -1.5724, -1.7956,\n",
      "        -2.7937, -1.9470, -2.2252, -2.0580, -2.5420, -2.0681, -1.8897, -1.9469,\n",
      "        -1.9611, -1.8518, -2.0844, -2.6111, -1.7594, -2.0141, -1.9591, -1.8939,\n",
      "        -2.2650, -1.9786, -1.4302, -2.2497, -2.2228, -2.7537, -2.2954, -2.2246],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>), tensor([2.1985, 2.2024, 3.5789, 3.2989, 3.1727, 2.7257, 3.1589, 2.9706, 2.3492,\n",
      "        2.3374, 2.2188, 3.5131, 2.9834, 3.2893, 2.7698, 2.7456, 3.0551, 2.7703,\n",
      "        2.4261, 2.7636, 2.3316, 2.5707, 3.1093, 2.7213, 3.2009, 2.8840, 2.6372,\n",
      "        3.2359, 2.7661, 3.7934, 1.9150, 3.2887, 2.6867, 3.5916, 2.4751, 3.0572,\n",
      "        2.5368, 2.8881, 2.4758, 2.3354, 2.7308, 2.2997, 2.9015, 2.8642, 2.6307,\n",
      "        2.6679, 2.1138, 2.7184, 2.5877, 2.4363, 2.8510, 2.2290, 2.7605, 2.9352,\n",
      "        2.5532, 2.4591, 2.0163, 3.2752, 2.3035, 2.7828, 2.5608, 2.5729, 2.1703,\n",
      "        2.6810, 2.4530, 2.5627, 2.7323, 3.0748, 2.3498, 3.0908, 2.9539, 2.4527,\n",
      "        2.4962, 2.8960, 2.6532, 2.6162, 2.2160, 3.6041, 3.0032, 2.8227, 2.6230,\n",
      "        3.2652, 2.3000, 2.5879, 2.6289, 3.2825, 2.4289, 3.2062, 2.0722, 2.9592,\n",
      "        2.0333, 2.4219, 2.9470, 3.5575, 2.5283, 2.6129, 2.5972, 2.9534, 2.9723,\n",
      "        2.5614, 2.8972, 2.7913, 2.9018, 1.8760, 3.3864, 3.4564, 2.7306, 3.0458,\n",
      "        2.2486, 3.0729, 2.5512, 2.5311, 2.8378, 2.2285, 3.0569, 2.5264, 2.6175,\n",
      "        2.5961, 2.5296, 2.6409, 2.6287, 2.5965, 2.9409, 2.4046, 2.7446, 2.3342,\n",
      "        2.9047, 2.5440, 3.0772, 1.9716, 2.1576, 2.7586, 2.4789, 2.6533, 2.2112,\n",
      "        1.8408, 2.9815, 2.7088, 2.7785, 2.7992, 3.3071, 3.1239, 2.4893, 3.1774,\n",
      "        2.4032, 2.8245, 2.6077, 3.3692, 2.4308, 2.2467, 1.9323, 2.7972, 2.7219,\n",
      "        3.2780, 2.9485, 1.9737, 2.9057, 3.7385, 3.2042, 2.6872, 2.8178, 2.6760,\n",
      "        2.4202, 2.7386, 2.2116, 2.8576, 3.0162, 2.2776, 3.1711, 2.4163, 3.9645,\n",
      "        2.4481, 2.7093, 2.1543, 2.6305, 2.5179, 2.1667, 2.6047, 2.6598, 2.0520,\n",
      "        3.2499, 2.4984, 3.2387, 1.9903, 2.1779, 2.6996, 3.1079, 3.0683, 2.8121,\n",
      "        2.5086, 2.6226, 2.2937, 2.8322, 2.4843, 2.4434, 2.6396, 2.6338, 2.3789,\n",
      "        2.7651, 2.4555, 2.8191, 2.7082, 1.9177, 1.8043, 2.0851, 2.5194, 2.5843,\n",
      "        2.2937, 2.0311, 2.0399, 2.4141, 2.8709, 2.6827, 3.2072, 2.4175, 2.9141,\n",
      "        2.7656, 2.7763, 2.8114, 2.5082, 1.9327, 2.6724, 2.2971, 2.3961, 2.4524,\n",
      "        2.7674, 2.5349, 3.2752, 2.6632, 2.7877, 2.4443, 2.6509, 2.4466, 2.1202,\n",
      "        2.9781, 2.3353, 2.5709, 2.1044, 2.5156, 2.9475, 3.4756, 2.5669, 2.3189,\n",
      "        2.3897, 2.2457, 3.0801, 3.5114, 2.4983, 2.5862, 2.5761, 3.1905, 2.3847,\n",
      "        2.0487, 2.6576, 2.6359, 3.1154, 2.4759, 2.8485, 3.0165, 2.8262, 2.6906,\n",
      "        2.8355, 2.7099, 2.5992, 1.6763, 2.7652, 2.6295, 2.3402, 2.8419, 2.9079,\n",
      "        2.4964, 2.8957, 2.8146, 2.8652, 2.3430, 2.9373, 1.6113, 2.4700, 1.9122,\n",
      "        2.3025, 2.5531, 2.2747, 2.6465, 2.9438, 2.1805, 2.2151, 3.0780, 2.2498,\n",
      "        2.4682, 2.1720, 1.9502, 2.3754, 3.0590, 2.9243, 2.5663, 2.1819, 1.9129,\n",
      "        2.4948, 2.9328, 2.1700, 2.6950, 2.9161, 3.1480, 2.9733, 2.6979, 1.7689,\n",
      "        2.1127, 2.9371, 2.5969, 3.9292, 3.1885, 2.4670, 2.7131, 2.7215, 2.7180,\n",
      "        2.5085, 3.2214, 3.0689, 3.8328, 2.5023, 2.7257, 2.1245, 2.3074, 2.0151,\n",
      "        2.5359, 2.9857, 2.3858, 2.7070, 2.9559, 2.5780, 2.9495, 2.1060, 2.3754,\n",
      "        2.7490, 2.9435, 2.4471, 2.6938, 2.2222, 2.7023, 2.6875, 2.6380, 2.3804,\n",
      "        2.8629, 2.6581, 2.5343, 2.1080, 3.1665, 2.9870, 2.4671, 3.0791, 2.9258,\n",
      "        2.0098, 2.9876, 2.4583, 3.1908, 1.8993, 2.4326, 3.2955, 2.3088, 2.7669,\n",
      "        2.3705, 2.6104, 2.2965, 2.8599, 3.0404, 3.1265, 2.3486, 2.6209, 2.5314,\n",
      "        2.9598, 2.1777, 3.2833, 2.4826, 2.1495, 2.1120, 2.6329, 2.0196, 2.5830,\n",
      "        2.9953, 2.7731, 2.1109, 2.6253, 2.6458, 3.1792, 2.3662, 2.9563, 2.5534,\n",
      "        3.6706, 2.4945, 3.0791, 2.2953, 2.7153, 3.2815, 2.2885, 2.4486, 2.0401,\n",
      "        3.1391, 2.0505, 3.0785, 2.2818, 2.9539, 2.3042, 2.9556, 2.9958, 1.6933,\n",
      "        2.8548, 2.2854, 2.5816, 3.0564, 2.0341, 2.3031, 2.5163, 2.3943, 2.1332,\n",
      "        2.5911, 2.6126, 2.3571, 2.4486, 1.9534, 3.2738, 2.5618, 2.5262, 2.7043,\n",
      "        2.9916, 3.1165, 2.2164, 3.1818, 2.5545, 2.2131, 3.1386, 3.0965, 2.8530,\n",
      "        1.9496, 2.5144, 2.0527, 2.6682, 2.6472, 2.7935, 2.5063, 3.1373, 3.1121,\n",
      "        2.6312, 2.4272, 2.1223, 2.9568, 2.5563, 2.5324, 3.5180, 2.0442, 2.8928,\n",
      "        3.0702, 2.2026, 2.4208, 3.1787, 2.5664, 2.6002, 2.0378, 2.5944, 2.5661,\n",
      "        2.8763, 2.4492, 2.1314, 3.1454, 2.7629, 3.0102, 3.0103, 2.5855, 2.3826,\n",
      "        2.2292, 2.7869, 2.7408, 1.9706, 2.4204, 2.4976, 3.1486, 2.0788, 2.7363,\n",
      "        2.4180, 2.0303, 2.9344, 2.0718, 2.6562, 3.4177, 3.0537, 2.7972, 2.2466,\n",
      "        3.6124, 3.4383, 1.8691, 2.8082, 2.1992, 2.7259, 1.9714, 2.4989, 2.9801,\n",
      "        3.0282, 2.6700, 2.6769, 2.3750, 2.2532, 3.5080, 2.4676, 2.6120, 2.4669,\n",
      "        2.5763, 2.6182, 3.6755, 2.8927, 2.4527, 1.9694, 3.1698, 2.4372],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)], [tensor([-35.7740, -45.8241, -38.7560, -31.5890, -35.1164, -38.4393, -42.1957,\n",
      "        -46.6409, -48.8005, -44.3439], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>), tensor([43.3247, 44.5450, 41.7424, 34.7020, 40.5605, 35.9051, 43.5192, 46.3586,\n",
      "        38.2935, 41.4184], dtype=torch.float64, grad_fn=<AddBackward0>)]]\n",
      "bounds layer out \n",
      " [[tensor([0.2088, 0.0196, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "       dtype=torch.float64, grad_fn=<MaximumBackward0>), tensor([0.7791, 0.5886, 0.5620,  ..., 0.0000, 0.2118, 0.3357],\n",
      "       dtype=torch.float64, grad_fn=<MaximumBackward0>)], [tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64,\n",
      "       grad_fn=<MaximumBackward0>), tensor([2.1985, 2.2024, 3.5789, 3.2989, 3.1727, 2.7257, 3.1589, 2.9706, 2.3492,\n",
      "        2.3374, 2.2188, 3.5131, 2.9834, 3.2893, 2.7698, 2.7456, 3.0551, 2.7703,\n",
      "        2.4261, 2.7636, 2.3316, 2.5707, 3.1093, 2.7213, 3.2009, 2.8840, 2.6372,\n",
      "        3.2359, 2.7661, 3.7934, 1.9150, 3.2887, 2.6867, 3.5916, 2.4751, 3.0572,\n",
      "        2.5368, 2.8881, 2.4758, 2.3354, 2.7308, 2.2997, 2.9015, 2.8642, 2.6307,\n",
      "        2.6679, 2.1138, 2.7184, 2.5877, 2.4363, 2.8510, 2.2290, 2.7605, 2.9352,\n",
      "        2.5532, 2.4591, 2.0163, 3.2752, 2.3035, 2.7828, 2.5608, 2.5729, 2.1703,\n",
      "        2.6810, 2.4530, 2.5627, 2.7323, 3.0748, 2.3498, 3.0908, 2.9539, 2.4527,\n",
      "        2.4962, 2.8960, 2.6532, 2.6162, 2.2160, 3.6041, 3.0032, 2.8227, 2.6230,\n",
      "        3.2652, 2.3000, 2.5879, 2.6289, 3.2825, 2.4289, 3.2062, 2.0722, 2.9592,\n",
      "        2.0333, 2.4219, 2.9470, 3.5575, 2.5283, 2.6129, 2.5972, 2.9534, 2.9723,\n",
      "        2.5614, 2.8972, 2.7913, 2.9018, 1.8760, 3.3864, 3.4564, 2.7306, 3.0458,\n",
      "        2.2486, 3.0729, 2.5512, 2.5311, 2.8378, 2.2285, 3.0569, 2.5264, 2.6175,\n",
      "        2.5961, 2.5296, 2.6409, 2.6287, 2.5965, 2.9409, 2.4046, 2.7446, 2.3342,\n",
      "        2.9047, 2.5440, 3.0772, 1.9716, 2.1576, 2.7586, 2.4789, 2.6533, 2.2112,\n",
      "        1.8408, 2.9815, 2.7088, 2.7785, 2.7992, 3.3071, 3.1239, 2.4893, 3.1774,\n",
      "        2.4032, 2.8245, 2.6077, 3.3692, 2.4308, 2.2467, 1.9323, 2.7972, 2.7219,\n",
      "        3.2780, 2.9485, 1.9737, 2.9057, 3.7385, 3.2042, 2.6872, 2.8178, 2.6760,\n",
      "        2.4202, 2.7386, 2.2116, 2.8576, 3.0162, 2.2776, 3.1711, 2.4163, 3.9645,\n",
      "        2.4481, 2.7093, 2.1543, 2.6305, 2.5179, 2.1667, 2.6047, 2.6598, 2.0520,\n",
      "        3.2499, 2.4984, 3.2387, 1.9903, 2.1779, 2.6996, 3.1079, 3.0683, 2.8121,\n",
      "        2.5086, 2.6226, 2.2937, 2.8322, 2.4843, 2.4434, 2.6396, 2.6338, 2.3789,\n",
      "        2.7651, 2.4555, 2.8191, 2.7082, 1.9177, 1.8043, 2.0851, 2.5194, 2.5843,\n",
      "        2.2937, 2.0311, 2.0399, 2.4141, 2.8709, 2.6827, 3.2072, 2.4175, 2.9141,\n",
      "        2.7656, 2.7763, 2.8114, 2.5082, 1.9327, 2.6724, 2.2971, 2.3961, 2.4524,\n",
      "        2.7674, 2.5349, 3.2752, 2.6632, 2.7877, 2.4443, 2.6509, 2.4466, 2.1202,\n",
      "        2.9781, 2.3353, 2.5709, 2.1044, 2.5156, 2.9475, 3.4756, 2.5669, 2.3189,\n",
      "        2.3897, 2.2457, 3.0801, 3.5114, 2.4983, 2.5862, 2.5761, 3.1905, 2.3847,\n",
      "        2.0487, 2.6576, 2.6359, 3.1154, 2.4759, 2.8485, 3.0165, 2.8262, 2.6906,\n",
      "        2.8355, 2.7099, 2.5992, 1.6763, 2.7652, 2.6295, 2.3402, 2.8419, 2.9079,\n",
      "        2.4964, 2.8957, 2.8146, 2.8652, 2.3430, 2.9373, 1.6113, 2.4700, 1.9122,\n",
      "        2.3025, 2.5531, 2.2747, 2.6465, 2.9438, 2.1805, 2.2151, 3.0780, 2.2498,\n",
      "        2.4682, 2.1720, 1.9502, 2.3754, 3.0590, 2.9243, 2.5663, 2.1819, 1.9129,\n",
      "        2.4948, 2.9328, 2.1700, 2.6950, 2.9161, 3.1480, 2.9733, 2.6979, 1.7689,\n",
      "        2.1127, 2.9371, 2.5969, 3.9292, 3.1885, 2.4670, 2.7131, 2.7215, 2.7180,\n",
      "        2.5085, 3.2214, 3.0689, 3.8328, 2.5023, 2.7257, 2.1245, 2.3074, 2.0151,\n",
      "        2.5359, 2.9857, 2.3858, 2.7070, 2.9559, 2.5780, 2.9495, 2.1060, 2.3754,\n",
      "        2.7490, 2.9435, 2.4471, 2.6938, 2.2222, 2.7023, 2.6875, 2.6380, 2.3804,\n",
      "        2.8629, 2.6581, 2.5343, 2.1080, 3.1665, 2.9870, 2.4671, 3.0791, 2.9258,\n",
      "        2.0098, 2.9876, 2.4583, 3.1908, 1.8993, 2.4326, 3.2955, 2.3088, 2.7669,\n",
      "        2.3705, 2.6104, 2.2965, 2.8599, 3.0404, 3.1265, 2.3486, 2.6209, 2.5314,\n",
      "        2.9598, 2.1777, 3.2833, 2.4826, 2.1495, 2.1120, 2.6329, 2.0196, 2.5830,\n",
      "        2.9953, 2.7731, 2.1109, 2.6253, 2.6458, 3.1792, 2.3662, 2.9563, 2.5534,\n",
      "        3.6706, 2.4945, 3.0791, 2.2953, 2.7153, 3.2815, 2.2885, 2.4486, 2.0401,\n",
      "        3.1391, 2.0505, 3.0785, 2.2818, 2.9539, 2.3042, 2.9556, 2.9958, 1.6933,\n",
      "        2.8548, 2.2854, 2.5816, 3.0564, 2.0341, 2.3031, 2.5163, 2.3943, 2.1332,\n",
      "        2.5911, 2.6126, 2.3571, 2.4486, 1.9534, 3.2738, 2.5618, 2.5262, 2.7043,\n",
      "        2.9916, 3.1165, 2.2164, 3.1818, 2.5545, 2.2131, 3.1386, 3.0965, 2.8530,\n",
      "        1.9496, 2.5144, 2.0527, 2.6682, 2.6472, 2.7935, 2.5063, 3.1373, 3.1121,\n",
      "        2.6312, 2.4272, 2.1223, 2.9568, 2.5563, 2.5324, 3.5180, 2.0442, 2.8928,\n",
      "        3.0702, 2.2026, 2.4208, 3.1787, 2.5664, 2.6002, 2.0378, 2.5944, 2.5661,\n",
      "        2.8763, 2.4492, 2.1314, 3.1454, 2.7629, 3.0102, 3.0103, 2.5855, 2.3826,\n",
      "        2.2292, 2.7869, 2.7408, 1.9706, 2.4204, 2.4976, 3.1486, 2.0788, 2.7363,\n",
      "        2.4180, 2.0303, 2.9344, 2.0718, 2.6562, 3.4177, 3.0537, 2.7972, 2.2466,\n",
      "        3.6124, 3.4383, 1.8691, 2.8082, 2.1992, 2.7259, 1.9714, 2.4989, 2.9801,\n",
      "        3.0282, 2.6700, 2.6769, 2.3750, 2.2532, 3.5080, 2.4676, 2.6120, 2.4669,\n",
      "        2.5763, 2.6182, 3.6755, 2.8927, 2.4527, 1.9694, 3.1698, 2.4372],\n",
      "       dtype=torch.float64, grad_fn=<MaximumBackward0>)], [tensor([-35.7740, -45.8241, -38.7560, -31.5890, -35.1164, -38.4393, -42.1957,\n",
      "        -46.6409, -48.8005, -44.3439], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>), tensor([43.3247, 44.5450, 41.7424, 34.7020, 40.5605, 35.9051, 43.5192, 46.3586,\n",
      "        38.2935, 41.4184], dtype=torch.float64, grad_fn=<AddBackward0>)]]\n"
     ]
    }
   ],
   "source": [
    "input_flattened = torch.flatten(test_image)\n",
    "bounds_affine_out, bounds_layer_out = nn.calculate_box_bounds([input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "print(\"bounds affine out \\n {}\".format(bounds_affine_out))\n",
    "print(\"bounds layer out \\n {}\".format(bounds_layer_out))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#milp_verifier = MILPVerifier(nn, test_image, eps, print_log=False)\n",
    "snv_verifier = SingleNeuronVerifier(nn, test_image, eps, print_log=False)\n",
    "#dhov_verifier = DHOVVerifier(icnns, group_size, nn, test_image, 1)\n",
    "\n",
    "#milp_verifier.generate_constraints_for_net()\n",
    "snv_verifier.generate_constraints_for_net()\n",
    "#dhov_verifier.generate_constraints_for_net()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "layer_index = 1\n",
    "neuron_index = 0\n",
    "#milp_model = milp_verifier.model\n",
    "snv_model = snv_verifier.model\n",
    "#dhov_model = dhov_verifier.model\n",
    "dhov_model = icnn_model(icnns[layer_index][0], nn, test_image, eps, layer_index, 0, 5, print_log=False)\n",
    "#milp_model.update()\n",
    "snv_model.update()\n",
    "dhov_model.update()\n",
    "\"\"\"all_var = milp_model.getVars()\n",
    "for var in all_var:\n",
    "    print(var)\"\"\"\n",
    "neuron_name = \"relu_var{}[{}]\".format(2*layer_index, neuron_index)\n",
    "icnn_neuron_name = \"icnn_var[{}]\".format(neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================\n",
      "opt value: 0.0\n",
      "===================================================================================\n",
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "#milp_copy = milp_model.copy()\n",
    "snv_copy = snv_model.copy()\n",
    "dhov_copy = dhov_model.copy()\n",
    "\n",
    "#milp_copy.Params.LogToConsole = 0\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "dhov_copy.Params.LogToConsole = 0\n",
    "\n",
    "#add_min_constr(milp_copy, neuron_name) #affine_var0[0]\n",
    "add_min_constr(snv_copy, neuron_name)\n",
    "add_min_constr(dhov_copy, icnn_neuron_name)\n",
    "\n",
    "#optimize_model(milp_copy, neuron_name)\n",
    "print(\"===================================================================================\")\n",
    "optimize_model(snv_copy, neuron_name)\n",
    "print(\"===================================================================================\")\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================\n",
      "opt value: 1.279494932358921\n",
      "===================================================================================\n",
      "opt value: 2.198499612885324\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "#milp_copy = milp_model.copy()\n",
    "snv_copy = snv_model.copy()\n",
    "dhov_copy = dhov_model.copy()\n",
    "\n",
    "#milp_copy.Params.LogToConsole = 0\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "dhov_copy.Params.LogToConsole = 0\n",
    "\n",
    "#add_max_constr(milp_copy, neuron_name)\n",
    "add_max_constr(snv_copy, neuron_name)\n",
    "add_max_constr(dhov_copy, icnn_neuron_name)\n",
    "\n",
    "#optimize_model(milp_copy, neuron_name)\n",
    "print(\"===================================================================================\")\n",
    "optimize_model(snv_copy, neuron_name)\n",
    "print(\"===================================================================================\")\n",
    "optimize_model(dhov_copy, icnn_neuron_name)\n",
    "print(\"===================================================================================\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}