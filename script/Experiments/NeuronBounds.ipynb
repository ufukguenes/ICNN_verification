{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from script.NeuralNets.Networks import SequentialNN, ICNN, ICNNApproxMax, ICNNLogical\n",
    "from script.settings import device, data_type\n",
    "import script.DHOV.MultiDHOV as multidhov\n",
    "from script.Verification.Verifier import SingleNeuronVerifier, MILPVerifier, DHOVVerifier\n",
    "import gurobipy as grp\n",
    "from torchvision.datasets import CIFAR10, MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from script.NeuralNets.ICNNFactory import ICNNFactory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def add_max_constr(model, neuron_name):\n",
    "    neuron_var = model.getVarByName(neuron_name)\n",
    "    model.setObjective(neuron_var, grp.GRB.MAXIMIZE)\n",
    "\n",
    "def add_min_constr(model, neuron):\n",
    "    neuron_var = model.getVarByName(neuron)\n",
    "    model.setObjective(neuron_var, grp.GRB.MINIMIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def optimize_model(model, neuron_name):\n",
    "    model.update()\n",
    "    model.optimize()\n",
    "    if model.Status == grp.GRB.OPTIMAL:\n",
    "        print(\"opt value: {}\".format(model.getVarByName(neuron_name).getAttr(\"x\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def icnn_model(icnn, nn, input_x, eps, layer_index, from_neuron, to_neuron, print_log=False):\n",
    "    m = grp.Model()\n",
    "    if not print_log:\n",
    "        m.Params.LogToConsole = 0\n",
    "\n",
    "    input_flattened = torch.flatten(input_x)\n",
    "    bounds_affine_out, bounds_layer_out = nn.calculate_box_bounds(\n",
    "        [input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "\n",
    "    parameter_list = list(nn.parameters())\n",
    "\n",
    "    input_size = len(parameter_list[2*(layer_index-1)])\n",
    "    lb = bounds_layer_out[layer_index-1][0].detach().cpu().numpy()\n",
    "    ub = bounds_layer_out[layer_index-1][1].detach().cpu().numpy()\n",
    "    in_var = m.addMVar(input_size, lb=-float(\"inf\"), ub=float(\"inf\"), name=\"icnn_var\")\n",
    "\n",
    "    low = bounds_layer_out[layer_index - 1][0][from_neuron: to_neuron]\n",
    "    up = bounds_layer_out[layer_index - 1][1][from_neuron: to_neuron]\n",
    "    low = torch.zeros_like(low, dtype=data_type).to(device) - 1000\n",
    "    up = torch.zeros_like(low, dtype=data_type).to(device) + 1000\n",
    "    constraint_bounds_affine_out, constraint_bounds_layer_out = icnn.calculate_box_bounds([low, up])\n",
    "    icnn.add_max_output_constraints(m, in_var[from_neuron: to_neuron], constraint_bounds_affine_out, constraint_bounds_layer_out)\n",
    "\n",
    "    return m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'nn = SequentialNN([50, 50, 50, 7])\\ntest_image = torch.zeros((1, 50), dtype=data_type).to(device)\\nparameter_list = list(nn.parameters())'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"W1 = [1. 1.; 1. -1.]\n",
    "    b1 = [0., 0.]\n",
    "    W2 = [1. 1.; 1. -1.]\n",
    "    b2 = [-0.5, 0.]\n",
    "    W3 = [-1. 1.; 1. 1.]\n",
    "    b3 = [3., 0.] \"\"\"\n",
    "\n",
    "\"\"\"nn = SequentialNN([2, 2, 2, 2])\n",
    "\n",
    "with torch.no_grad():\n",
    "    parameter_list = list(nn.parameters())\n",
    "    parameter_list[0].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[1].data = torch.tensor([0, 0], dtype=data_type).to(device)\n",
    "    parameter_list[2].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "    parameter_list[3].data = torch.tensor([-0.5, 0], dtype=data_type).to(device)\n",
    "    parameter_list[4].data = torch.tensor([[-1, 1], [1, 1]], dtype=data_type).to(device)\n",
    "    parameter_list[5].data = torch.tensor([3, 0], dtype=data_type).to(device)\n",
    "\n",
    "test_image = torch.tensor([[0, 0]], dtype=data_type).to(device)\"\"\"\n",
    "\n",
    "\"\"\"transform = Compose([ToTensor(),\n",
    "                         Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "                        )\n",
    "\n",
    "training_data = CIFAR10(root=\"../../cifar\", train=True, download=True, transform=transform)\n",
    "images, labels = training_data.__getitem__(0)\n",
    "test_image, test_label = torch.unsqueeze(images, 0).to(dtype=data_type).to(device), torch.unsqueeze(\n",
    "    torch.tensor(labels), 0).to(dtype=data_type).to(device)\n",
    "\n",
    "nn = SequentialNN([32 * 32 * 3, 1024, 512, 10])\n",
    "nn.load_state_dict(torch.load(\"../../cifar_fc.pth\", map_location=torch.device(device)), strict=False)\n",
    "\"\"\"\n",
    "\n",
    "transform = Compose([ToTensor(),\n",
    "                         Normalize(0.5, 0.5)]\n",
    "                        )\n",
    "\n",
    "training_data = MNIST(root=\"../../mnist\",\n",
    "                      train=True,\n",
    "                      download=True,\n",
    "                      transform=transform)\n",
    "images, labels = training_data.__getitem__(0)\n",
    "test_image, test_label = torch.unsqueeze(images, 0).to(dtype=data_type).to(device), torch.unsqueeze(\n",
    "    torch.tensor(labels), 0).to(dtype=data_type).to(device)\n",
    "\n",
    "nn = SequentialNN([28*28*1, 100, 30, 10])\n",
    "nn.load_state_dict(torch.load(\"../../mnist_fc.pth\", map_location=torch.device('cpu')), strict=False)\n",
    "\n",
    "parameter_list = list(nn.parameters())\n",
    "\n",
    "\n",
    "\"\"\"nn = SequentialNN([50, 50, 50, 7])\n",
    "test_image = torch.zeros((1, 50), dtype=data_type).to(device)\n",
    "parameter_list = list(nn.parameters())\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.5661,   1.4250,   0.4501,   9.2822, -12.7331,  10.6958,  -3.4634,\n",
      "           2.1465,  -3.7246,  -2.3831]], dtype=torch.float64,\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([5.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(nn(test_image))\n",
    "print(test_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "eps = 0.01"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for DHOV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-11-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ufuk\\Documents\\Programming\\ICNN_verification\\script\\DHOV\\MultiDHOV.py:76: UserWarning: keep_ambient_space is True and sampling method is per_group_sampling. Keeping previous samples is not supported when using per group sampling\n",
      "  warnings.warn(\"keep_ambient_space is True and sampling method is per_group_sampling. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "approximation of layer: 0\n",
      "    number of fixed neurons for current layer: 92\n",
      "    layer progress, group 1 of 4 \n",
      "        time for sampling for one group: 0.008031606674194336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ufuk\\Documents\\Programming\\ICNN_verification\\script\\Optimizer\\sdlbfgs.py:83: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1420.)\n",
      "  p.data.add_(step_size, update[offset:offset + numel].view_as(p.data))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time for training: 4.011852264404297\n",
      "        actual verification time 0.022167205810546875\n",
      "        time for verification: 0.1208944320678711\n",
      "    layer progress, group 2 of 4 \n",
      "        time for sampling for one group: 0.01005244255065918\n",
      "        time for training: 3.7841906547546387\n",
      "        actual verification time 0.030219316482543945\n",
      "        time for verification: 0.12119388580322266\n",
      "    layer progress, group 3 of 4 \n",
      "        time for sampling for one group: 0.008075714111328125\n",
      "        time for training: 3.5813701152801514\n",
      "        actual verification time 0.022216320037841797\n",
      "        time for verification: 0.14115452766418457\n",
      "    layer progress, group 4 of 4 \n",
      "        time for sampling for one group: 0.010082483291625977\n",
      "        time for training: 3.440850019454956\n",
      "        actual verification time 0.020176410675048828\n",
      "        time for verification: 0.1289839744567871\n",
      "    time for regrouping method: 0.0\n",
      "\n",
      "approximation of layer: 1\n",
      "        0, lower: new -0.0794514874905275, old -1.0272694263485382\n",
      "        0, upper: new 0.643550848351011, old 1.590265447932639\n",
      "        1, lower: new 5.620523851569262, old 4.891074441089023\n",
      "        1, upper: new 6.187799140520768, old 6.908179377487894\n",
      "        2, lower: new 1.1502432998178727, old 0.4758416777957901\n",
      "        2, upper: new 1.767337014498441, old 2.45705423241999\n",
      "        3, lower: new -3.614047854079837, old -4.154560614460519\n",
      "        3, upper: new -3.189998391406098, old -2.6379028626565093\n",
      "        4, lower: new 1.6299671317474718, old 0.6517725440588809\n",
      "        4, upper: new 2.3482488431211626, old 3.3335162230102693\n",
      "        5, lower: new -1.3138356192793397, old -2.143489793168459\n",
      "        5, upper: new -0.7421786736867847, old 0.0854374951093364\n",
      "        6, lower: new 0.5406088836969144, old -0.409115897681394\n",
      "        6, upper: new 1.2508085077160775, old 2.2013279327856976\n",
      "        7, lower: new -0.5323833408078734, old -1.194134963667596\n",
      "        7, upper: new -0.08827052522543509, old 0.5879126079003312\n",
      "        8, lower: new 1.9889764934828829, old 1.1517885635031728\n",
      "        8, upper: new 2.6031961060397957, old 3.4413901127827238\n",
      "        9, lower: new 0.741233783146717, old 0.053368456055829405\n",
      "        9, upper: new 1.2456213579170443, old 1.951150902106173\n",
      "        10, lower: new 1.2940614667933679, old 0.4474716841053148\n",
      "        10, upper: new 1.9282476535625626, old 2.7688675833083156\n",
      "        11, lower: new 3.1731688439874963, old 2.2823298654349804\n",
      "        11, upper: new 3.7100493702554407, old 4.599801049017392\n",
      "        12, lower: new 2.3159480125829197, old 1.6933718660848394\n",
      "        12, upper: new 2.8293188898545436, old 3.471459235031665\n",
      "        13, lower: new -1.3159888657440413, old -1.8334256175700663\n",
      "        13, upper: new -1.040304128141608, old -0.5237117713086965\n",
      "        14, lower: new -0.9978118384341189, old -1.466869389694395\n",
      "        14, upper: new -0.7671751749444522, old -0.30613013523807897\n",
      "        15, lower: new 5.665257315989262, old 4.668204914112108\n",
      "        15, upper: new 6.361582027031411, old 7.361566298400341\n",
      "        16, lower: new 0.26450905195590674, old -0.6847946385441421\n",
      "        16, upper: new 1.1290136233807109, old 2.0801847320655966\n",
      "        17, lower: new 2.9586714246056394, old 2.2004989456216055\n",
      "        17, upper: new 3.50770631861762, old 4.267971015539602\n",
      "        18, lower: new -0.9054087427456698, old -1.2830149131120172\n",
      "        18, upper: new -0.681098429506802, old -0.29468515782038596\n",
      "        19, lower: new 5.370781971627126, old 4.670984259366115\n",
      "        19, upper: new 5.960127821270818, old 6.657308087984413\n",
      "        20, lower: new 0.07062257344304564, old -0.6091871666301043\n",
      "        20, upper: new 0.5167098237943681, old 1.200720888753544\n",
      "        21, lower: new 6.1648457293234395, old 5.484337577617196\n",
      "        21, upper: new 6.746114779497837, old 7.413609163446834\n",
      "        22, lower: new 1.992448232671085, old 1.2427032510074483\n",
      "        22, upper: new 2.5697041276428356, old 3.320612581395128\n",
      "        23, lower: new 5.14017293422183, old 4.168817558547471\n",
      "        23, upper: new 5.804700303794081, old 6.780179104352769\n",
      "        24, lower: new 7.383306690199577, old 6.446242411024807\n",
      "        24, upper: new 8.047982748123484, old 8.971084931603443\n",
      "        25, lower: new -0.7410719391619013, old -1.1600468860809312\n",
      "        25, upper: new -0.46981082644935546, old -0.046419147582785314\n",
      "        26, lower: new 4.484397280266231, old 3.754943133455928\n",
      "        26, upper: new 4.980928581732177, old 5.711956539875997\n",
      "        27, lower: new 4.445889912077713, old 3.561375283453498\n",
      "        27, upper: new 5.1705096604460214, old 6.063069775488341\n",
      "        28, lower: new 1.3280592909159659, old 0.7072285143067245\n",
      "        28, upper: new 1.6730225103372882, old 2.2934821027747554\n",
      "        29, lower: new 3.7220998676374015, old 2.928185776482185\n",
      "        29, upper: new 4.318519267131344, old 5.094451979379954\n",
      "    time for icnn_bound calculation: 1.2328476905822754\n",
      "    number of fixed neurons for current layer: 29\n",
      "    layer progress, group 1 of 1 \n",
      "        time for sampling for one group: 42.93051600456238\n",
      "        time for training: 3.1355748176574707\n",
      "        actual verification time 0.03240013122558594\n",
      "        time for verification: 0.10285782814025879\n",
      "    time for regrouping method: 0.0\n",
      "        0, lower: new 0.00509347543601657, old -5.222328370466463\n",
      "        0, upper: new 1.1183649847797343, old 6.4550215091504075\n",
      "        1, lower: new 0.7538346373492655, old -4.918760822623748\n",
      "        1, upper: new 2.0945661612142152, old 7.295738312409591\n",
      "        2, lower: new -0.5752810815169753, old -6.658893474237098\n",
      "        2, upper: new 1.406667945958036, old 7.852218028790009\n",
      "        3, lower: new 8.448493402422029, old 2.644916692106161\n",
      "        3, upper: new 10.037365314591089, old 15.606944995777688\n",
      "        4, lower: new -13.539346267146255, old -18.618164387099664\n",
      "        4, upper: new -11.852555761828347, old -5.71679109540866\n",
      "        5, lower: new 9.90333100629903, old 3.640542770683016\n",
      "        5, upper: new 11.4839141813389, old 17.27910677198991\n",
      "        6, lower: new -4.102501674515271, old -9.56686692623975\n",
      "        6, upper: new -2.824367308704492, old 2.3780248928482886\n",
      "        7, lower: new 1.4745276237003235, old -4.352364636627183\n",
      "        7, upper: new 2.8411623632552, old 8.45344870964095\n",
      "        8, lower: new -4.455124225816431, old -10.968712675309703\n",
      "        8, upper: new -2.95359607753565, old 3.7082917227510546\n",
      "        9, lower: new -3.1309721102026025, old -9.135683286699116\n",
      "        9, upper: new -1.6293773188377916, old 4.336747007588861\n",
      "done...\n"
     ]
    }
   ],
   "source": [
    "group_size = 2\n",
    "icnn_factory = ICNNFactory(\"logical\", [10, 10, 1], force_positive_init=False, with_two_layers=False,\n",
    "                               init_scaling=10, init_all_with_zeros=False)\n",
    "#icnn_factory = ICNNFactory(\"standard\", [5, 5, 1])\n",
    "\n",
    "dhov_verifier = multidhov.MultiDHOV()\n",
    "dhov_verifier.start_verification(nn, test_image, icnn_factory, group_size, eps=eps, icnn_epochs=100,\n",
    "                                 icnn_batch_size=1000, sample_count=1000, sample_new=True, use_over_approximation=True, break_after=None,\n",
    "                                 sample_over_input_space=False, sample_over_output_space=True, use_icnn_bounds=True,\n",
    "                                 use_fixed_neurons=True, sampling_method=\"per_group_sampling\",\n",
    "                                 force_inclusion_steps=0, preemptive_stop=True, even_gradient_training=False,\n",
    "                                 keep_ambient_space=True, data_grad_descent_steps=0, opt_steps_gd=0,\n",
    "                                 train_outer=False, print_training_loss=False, print_new_bounds=True,\n",
    "                                 should_plot=\"none\", optimizer=\"SdLBFGS\", init_network=True, adapt_lambda=\"included\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "layer_index = 0\n",
    "neuron_index = 23\n",
    "neuron_name = \"relu_var{}[{}]\".format(2*layer_index, neuron_index)\n",
    "# neuron_name = \"last_affine_var[{}]\".format(neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1, 23], [25, 51], [60, 69], [86, 96]], [[0]]]\n"
     ]
    }
   ],
   "source": [
    "print(dhov_verifier.all_group_indices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5.0935e-03,  7.5383e-01, -5.7528e-01,  8.4485e+00, -1.3539e+01,\n",
      "         9.9033e+00, -4.1025e+00,  1.4745e+00, -4.4551e+00, -3.1310e+00],\n",
      "       dtype=torch.float64, grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "print(dhov_verifier.bounds_affine_out[layer_index][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.1184,   2.0946,   1.4067,  10.0374, -11.8526,  11.4839,  -2.8244,\n",
      "          2.8412,  -2.9536,  -1.6294], dtype=torch.float64,\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "print(dhov_verifier.bounds_affine_out[layer_index][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -5.2223,  -4.9188,  -6.6589,   2.6449, -18.6182,   3.6405,  -9.5669,\n",
      "         -4.3524, -10.9687,  -9.1357], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([ 6.4550,  7.2957,  7.8522, 15.6069, -5.7168, 17.2791,  2.3780,  8.4534,\n",
      "         3.7083,  4.3367], dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_flattened = torch.flatten(test_image)\n",
    "simple_bounds_affine_out, simple_bounds_layer_out = nn.calculate_box_bounds([input_flattened.add(-eps), input_flattened.add(eps)])\n",
    "print(simple_bounds_affine_out[layer_index][0])\n",
    "print(simple_bounds_affine_out[layer_index][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "icnn_neuron_name = \"output_layer_[{}]_[{}]\".format(layer_index, neuron_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.00509347543601657\n"
     ]
    }
   ],
   "source": [
    "dhov_copy = dhov_verifier.nn_encoding_model.copy()\n",
    "add_min_constr(dhov_copy, icnn_neuron_name)\n",
    "dhov_copy.update()\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 1.1183649847797343\n"
     ]
    }
   ],
   "source": [
    "dhov_copy = dhov_verifier.nn_encoding_model.copy()\n",
    "dhov_copy.Params.LogToConsole = 0\n",
    "add_max_constr(dhov_copy, icnn_neuron_name)\n",
    "optimize_model(dhov_copy, icnn_neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[87], line 17\u001B[0m\n\u001B[0;32m     14\u001B[0m     neuron_value_in_lp\u001B[38;5;241m.\u001B[39mappend(torch\u001B[38;5;241m.\u001B[39mtensor(current_layer_as_lp, dtype\u001B[38;5;241m=\u001B[39mdata_type)\u001B[38;5;241m.\u001B[39mto(device))\n\u001B[0;32m     16\u001B[0m true_out \u001B[38;5;241m=\u001B[39m nn(torch\u001B[38;5;241m.\u001B[39munsqueeze(nn_input_as_lp, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m))\n\u001B[1;32m---> 17\u001B[0m test \u001B[38;5;241m=\u001B[39m \u001B[43mtrue_out\u001B[49m \u001B[38;5;241m-\u001B[39m neuron_value_in_lp[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(test)\n",
      "Cell \u001B[1;32mIn[87], line 17\u001B[0m\n\u001B[0;32m     14\u001B[0m     neuron_value_in_lp\u001B[38;5;241m.\u001B[39mappend(torch\u001B[38;5;241m.\u001B[39mtensor(current_layer_as_lp, dtype\u001B[38;5;241m=\u001B[39mdata_type)\u001B[38;5;241m.\u001B[39mto(device))\n\u001B[0;32m     16\u001B[0m true_out \u001B[38;5;241m=\u001B[39m nn(torch\u001B[38;5;241m.\u001B[39munsqueeze(nn_input_as_lp, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m))\n\u001B[1;32m---> 17\u001B[0m test \u001B[38;5;241m=\u001B[39m \u001B[43mtrue_out\u001B[49m \u001B[38;5;241m-\u001B[39m neuron_value_in_lp[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(test)\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1095\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1053\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\221.5591.52\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_plugin.py:169\u001B[0m, in \u001B[0;36mstop\u001B[1;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[0;32m    167\u001B[0m     frame \u001B[38;5;241m=\u001B[39m suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[1;32m--> 169\u001B[0m         \u001B[43mmain_debugger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    170\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\221.5591.52\\plugins\\python\\helpers\\pydev\\pydevd.py:1155\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1152\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1154\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1155\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\221.5591.52\\plugins\\python\\helpers\\pydev\\pydevd.py:1170\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1167\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1169\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1170\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1172\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1174\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "nn_input_as_lp = []\n",
    "for i in range(parameter_list[0].shape[1]):\n",
    "    nn_input_as_lp.append(dhov_copy.getVarByName(\"output_layer_[-1]_[{}]\".format(i)).getAttr(\"x\"))\n",
    "nn_input_as_lp = torch.tensor(nn_input_as_lp, dtype=data_type).to(device)\n",
    "\n",
    "neuron_value_in_lp = []\n",
    "for layer_index in range(0, len(parameter_list) // 2):\n",
    "    current_layer_as_lp = []\n",
    "    for i in range(parameter_list[layer_index * 2].shape[0]):\n",
    "        current_layer_as_lp.append(dhov_copy.getVarByName(\"output_layer_[{}]_[{}]\".format(layer_index, i)).getAttr(\"x\"))\n",
    "    neuron_value_in_lp.append(torch.tensor(current_layer_as_lp, dtype=data_type).to(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for SNV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ layer 0 ===============\n",
      "================ layer 1 ===============\n",
      "        0, lower: new -0.01432710402877753, old -1.0272694263485382\n",
      "        0, upper: new 0.5730239543289277, old 1.590265447932639\n",
      "        1, lower: new 5.6693464021433, old 4.891074441089023\n",
      "        1, upper: new 6.142891226457357, old 6.908179377487894\n",
      "        2, lower: new 1.2133011004497163, old 0.4758416777957901\n",
      "        2, upper: new 1.6912240704039898, old 2.45705423241999\n",
      "        3, lower: new -3.5531681529549597, old -4.154560614460519\n",
      "        3, upper: new -3.2485968330353114, old -2.6379028626565093\n",
      "        4, lower: new 1.6869863275604329, old 0.6517725440588809\n",
      "        4, upper: new 2.2962018490677614, old 3.3335162230102693\n",
      "        5, lower: new -1.2584008138560365, old -2.143489793168459\n",
      "        5, upper: new -0.7834514746218495, old 0.0854374951093364\n",
      "        6, lower: new 0.5966294908309514, old -0.409115897681394\n",
      "        6, upper: new 1.1930418268841008, old 2.2013279327856976\n",
      "        7, lower: new -0.4892610328907936, old -1.194134963667596\n",
      "        7, upper: new -0.13095960622645006, old 0.5879126079003312\n",
      "        8, lower: new 2.0356361978186768, old 1.1517885635031728\n",
      "        8, upper: new 2.561740481911798, old 3.4413901127827238\n",
      "        9, lower: new 0.7842233193079005, old 0.053368456055829405\n",
      "        9, upper: new 1.1877108380058303, old 1.951150902106173\n",
      "        10, lower: new 1.353403284571138, old 0.4474716841053148\n",
      "        10, upper: new 1.8840624276678957, old 2.7688675833083156\n",
      "        11, lower: new 3.2188412323833653, old 2.2823298654349804\n",
      "        11, upper: new 3.662702853467106, old 4.599801049017392\n",
      "        12, lower: new 2.375283374142125, old 1.6933718660848394\n",
      "        12, upper: new 2.7778707936353286, old 3.471459235031665\n",
      "        13, lower: new -1.2864644942709138, old -1.8334256175700663\n",
      "        13, upper: new -1.0737754584158385, old -0.5237117713086965\n",
      "        14, lower: new -0.9703812861999057, old -1.466869389694395\n",
      "        14, upper: new -0.7968503421266155, old -0.30613013523807897\n",
      "        15, lower: new 5.70337570032894, old 4.668204914112108\n",
      "        15, upper: new 6.310730004592037, old 7.361566298400341\n",
      "        16, lower: new 0.36323414478794913, old -0.6847946385441421\n",
      "        16, upper: new 1.0488794811409567, old 2.0801847320655966\n",
      "        17, lower: new 2.9982262387778027, old 2.2004989456216055\n",
      "        17, upper: new 3.463293125902228, old 4.267971015539602\n",
      "        18, lower: new -0.8732047108126598, old -1.2830149131120172\n",
      "        18, upper: new -0.7131607867483153, old -0.29468515782038596\n",
      "        19, lower: new 5.402179189717583, old 4.670984259366115\n",
      "        19, upper: new 5.921021765009269, old 6.657308087984413\n",
      "        20, lower: new 0.11945108005953105, old -0.6091871666301043\n",
      "        20, upper: new 0.46614464815098255, old 1.200720888753544\n",
      "        21, lower: new 6.21709274542028, old 5.484337577617196\n",
      "        21, upper: new 6.715574300300016, old 7.413609163446834\n",
      "        22, lower: new 2.046269108299202, old 1.2427032510074483\n",
      "        22, upper: new 2.5240594663200646, old 3.320612581395128\n",
      "        23, lower: new 5.195436981534272, old 4.168817558547471\n",
      "        23, upper: new 5.752675977961834, old 6.780179104352769\n",
      "        24, lower: new 7.4089816508335335, old 6.446242411024807\n",
      "        24, upper: new 8.011940676409994, old 8.971084931603443\n",
      "        25, lower: new -0.6984294352393251, old -1.1600468860809312\n",
      "        25, upper: new -0.5112084575246876, old -0.046419147582785314\n",
      "        26, lower: new 4.514617094686428, old 3.754943133455928\n",
      "        26, upper: new 4.943238781024951, old 5.711956539875997\n",
      "        27, lower: new 4.513259124191934, old 3.561375283453498\n",
      "        27, upper: new 5.105436769681473, old 6.063069775488341\n",
      "        28, lower: new 1.3566519777355341, old 0.7072285143067245\n",
      "        28, upper: new 1.6433879043536983, old 2.2934821027747554\n",
      "        29, lower: new 3.7685734039083947, old 2.928185776482185\n",
      "        29, upper: new 4.285653767937648, old 5.094451979379954\n"
     ]
    }
   ],
   "source": [
    "snv_verifier = SingleNeuronVerifier(nn, test_image, eps, print_log=False)\n",
    "snv_verifier.generate_constraints_for_net()\n",
    "snv_model = snv_verifier.model\n",
    "snv_model.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.07810725344285707\n"
     ]
    }
   ],
   "source": [
    "snv_copy = snv_model.copy()\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "add_min_constr(snv_copy, neuron_name)\n",
    "optimize_model(snv_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 1.0446332572036505\n"
     ]
    }
   ],
   "source": [
    "snv_copy = snv_model.copy()\n",
    "snv_copy.Params.LogToConsole = 0\n",
    "add_max_constr(snv_copy, neuron_name)\n",
    "optimize_model(snv_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_var[0] : -1.01\n",
      "in_var[1] : -1.01\n",
      "in_var[2] : -0.99\n",
      "in_var[3] : -0.99\n",
      "in_var[4] : -1.01\n",
      "in_var[5] : -1.01\n",
      "in_var[6] : -0.99\n",
      "in_var[7] : -0.99\n",
      "in_var[8] : -0.99\n",
      "in_var[9] : -0.99\n",
      "in_var[10] : -0.99\n",
      "in_var[11] : -0.99\n",
      "in_var[12] : -1.01\n",
      "in_var[13] : -0.99\n",
      "in_var[14] : -0.99\n",
      "in_var[15] : -1.01\n",
      "in_var[16] : -0.99\n",
      "in_var[17] : -0.99\n",
      "in_var[18] : -1.01\n",
      "in_var[19] : -0.99\n",
      "in_var[20] : -0.99\n",
      "in_var[21] : -1.01\n",
      "in_var[22] : -1.01\n",
      "in_var[23] : -1.01\n",
      "in_var[24] : -1.01\n",
      "in_var[25] : -1.01\n",
      "in_var[26] : -0.99\n",
      "in_var[27] : -1.01\n",
      "in_var[28] : -1.01\n",
      "in_var[29] : -0.99\n",
      "in_var[30] : -1.01\n",
      "in_var[31] : -1.01\n",
      "in_var[32] : -1.01\n",
      "in_var[33] : -0.99\n",
      "in_var[34] : -1.01\n",
      "in_var[35] : -0.99\n",
      "in_var[36] : -1.01\n",
      "in_var[37] : -1.01\n",
      "in_var[38] : -1.01\n",
      "in_var[39] : -1.01\n",
      "in_var[40] : -1.01\n",
      "in_var[41] : -0.99\n",
      "in_var[42] : -0.99\n",
      "in_var[43] : -1.01\n",
      "in_var[44] : -1.01\n",
      "in_var[45] : -0.99\n",
      "in_var[46] : -1.01\n",
      "in_var[47] : -0.99\n",
      "in_var[48] : -1.01\n",
      "in_var[49] : -0.99\n",
      "in_var[50] : -1.01\n",
      "in_var[51] : -1.01\n",
      "in_var[52] : -0.99\n",
      "in_var[53] : -0.99\n",
      "in_var[54] : -0.99\n",
      "in_var[55] : -0.99\n",
      "in_var[56] : -1.01\n",
      "in_var[57] : -1.01\n",
      "in_var[58] : -1.01\n",
      "in_var[59] : -1.01\n",
      "in_var[60] : -0.99\n",
      "in_var[61] : -0.99\n",
      "in_var[62] : -1.01\n",
      "in_var[63] : -1.01\n",
      "in_var[64] : -1.01\n",
      "in_var[65] : -1.01\n",
      "in_var[66] : -1.01\n",
      "in_var[67] : -0.99\n",
      "in_var[68] : -1.01\n",
      "in_var[69] : -1.01\n",
      "in_var[70] : -1.01\n",
      "in_var[71] : -1.01\n",
      "in_var[72] : -1.01\n",
      "in_var[73] : -1.01\n",
      "in_var[74] : -0.99\n",
      "in_var[75] : -0.99\n",
      "in_var[76] : -0.99\n",
      "in_var[77] : -1.01\n",
      "in_var[78] : -0.99\n",
      "in_var[79] : -1.01\n",
      "in_var[80] : -1.01\n",
      "in_var[81] : -0.99\n",
      "in_var[82] : -1.01\n",
      "in_var[83] : -1.01\n",
      "in_var[84] : -1.01\n",
      "in_var[85] : -0.99\n",
      "in_var[86] : -0.99\n",
      "in_var[87] : -0.99\n",
      "in_var[88] : -0.99\n",
      "in_var[89] : -0.99\n",
      "in_var[90] : -0.99\n",
      "in_var[91] : -1.01\n",
      "in_var[92] : -1.01\n",
      "in_var[93] : -1.01\n",
      "in_var[94] : -1.01\n",
      "in_var[95] : -1.01\n",
      "in_var[96] : -1.01\n",
      "in_var[97] : -1.01\n",
      "in_var[98] : -1.01\n",
      "in_var[99] : -1.01\n",
      "in_var[100] : -1.01\n",
      "in_var[101] : -1.01\n",
      "in_var[102] : -0.99\n",
      "in_var[103] : -0.99\n",
      "in_var[104] : -0.99\n",
      "in_var[105] : -0.99\n",
      "in_var[106] : -0.99\n",
      "in_var[107] : -0.99\n",
      "in_var[108] : -1.01\n",
      "in_var[109] : -1.01\n",
      "in_var[110] : -0.99\n",
      "in_var[111] : -1.01\n",
      "in_var[112] : -0.99\n",
      "in_var[113] : -1.01\n",
      "in_var[114] : -0.99\n",
      "in_var[115] : -1.01\n",
      "in_var[116] : -0.99\n",
      "in_var[117] : -1.01\n",
      "in_var[118] : -1.01\n",
      "in_var[119] : -1.01\n",
      "in_var[120] : -1.01\n",
      "in_var[121] : -1.01\n",
      "in_var[122] : -1.01\n",
      "in_var[123] : -1.01\n",
      "in_var[124] : -1.01\n",
      "in_var[125] : -1.01\n",
      "in_var[126] : -1.01\n",
      "in_var[127] : -1.01\n",
      "in_var[128] : -1.01\n",
      "in_var[129] : -0.99\n",
      "in_var[130] : -0.99\n",
      "in_var[131] : -1.01\n",
      "in_var[132] : -0.99\n",
      "in_var[133] : -0.99\n",
      "in_var[134] : -0.99\n",
      "in_var[135] : -0.99\n",
      "in_var[136] : -0.99\n",
      "in_var[137] : -0.99\n",
      "in_var[138] : -1.01\n",
      "in_var[139] : -1.01\n",
      "in_var[140] : -1.01\n",
      "in_var[141] : -0.99\n",
      "in_var[142] : -0.99\n",
      "in_var[143] : -1.01\n",
      "in_var[144] : -1.01\n",
      "in_var[145] : -1.01\n",
      "in_var[146] : -1.01\n",
      "in_var[147] : -1.01\n",
      "in_var[148] : -1.01\n",
      "in_var[149] : -1.01\n",
      "in_var[150] : -1.01\n",
      "in_var[151] : -1.01\n",
      "in_var[152] : -0.9864705896377564\n",
      "in_var[153] : -0.8688235378265381\n",
      "in_var[154] : -0.8688235378265381\n",
      "in_var[155] : -0.8688235378265381\n",
      "in_var[156] : -0.001764705181121826\n",
      "in_var[157] : 0.056666722297668455\n",
      "in_var[158] : 0.38254905700683595\n",
      "in_var[159] : -0.7860784435272217\n",
      "in_var[160] : 0.311960825920105\n",
      "in_var[161] : 1.01\n",
      "in_var[162] : 0.9472549057006836\n",
      "in_var[163] : 0.006078431606292725\n",
      "in_var[164] : -0.99\n",
      "in_var[165] : -0.99\n",
      "in_var[166] : -1.01\n",
      "in_var[167] : -0.99\n",
      "in_var[168] : -0.99\n",
      "in_var[169] : -1.01\n",
      "in_var[170] : -1.01\n",
      "in_var[171] : -1.01\n",
      "in_var[172] : -0.99\n",
      "in_var[173] : -1.01\n",
      "in_var[174] : -1.01\n",
      "in_var[175] : -1.01\n",
      "in_var[176] : -0.7747058963775635\n",
      "in_var[177] : -0.7276470756530762\n",
      "in_var[178] : -0.27274508237838746\n",
      "in_var[179] : 0.19784318447113036\n",
      "in_var[180] : 0.3233333730697632\n",
      "in_var[181] : 0.9743137264251709\n",
      "in_var[182] : 0.9743137264251709\n",
      "in_var[183] : 0.9743137264251709\n",
      "in_var[184] : 0.9743137264251709\n",
      "in_var[185] : 0.9743137264251709\n",
      "in_var[186] : 0.7547058963775635\n",
      "in_var[187] : 0.3590196466445923\n",
      "in_var[188] : 0.9943137264251709\n",
      "in_var[189] : 0.9080392217636108\n",
      "in_var[190] : 0.539411792755127\n",
      "in_var[191] : -0.48803918600082397\n",
      "in_var[192] : -0.99\n",
      "in_var[193] : -0.99\n",
      "in_var[194] : -0.99\n",
      "in_var[195] : -1.01\n",
      "in_var[196] : -1.01\n",
      "in_var[197] : -0.99\n",
      "in_var[198] : -0.99\n",
      "in_var[199] : -1.01\n",
      "in_var[200] : -1.01\n",
      "in_var[201] : -1.01\n",
      "in_var[202] : -1.01\n",
      "in_var[203] : -0.625686297416687\n",
      "in_var[204] : 0.8566666746139526\n",
      "in_var[205] : 0.9743137264251709\n",
      "in_var[206] : 0.9743137264251709\n",
      "in_var[207] : 0.9743137264251709\n",
      "in_var[208] : 0.9743137264251709\n",
      "in_var[209] : 0.9743137264251709\n",
      "in_var[210] : 0.9743137264251709\n",
      "in_var[211] : 0.9743137264251709\n",
      "in_var[212] : 0.9743137264251709\n",
      "in_var[213] : 0.9586274528503418\n",
      "in_var[214] : -0.260588219165802\n",
      "in_var[215] : -0.36686272382736207\n",
      "in_var[216] : -0.34686272382736205\n",
      "in_var[217] : -0.5507843399047851\n",
      "in_var[218] : -0.6841176652908325\n",
      "in_var[219] : -0.99\n",
      "in_var[220] : -0.99\n",
      "in_var[221] : -0.99\n",
      "in_var[222] : -1.01\n",
      "in_var[223] : -1.01\n",
      "in_var[224] : -0.99\n",
      "in_var[225] : -1.01\n",
      "in_var[226] : -1.01\n",
      "in_var[227] : -1.01\n",
      "in_var[228] : -1.01\n",
      "in_var[229] : -1.01\n",
      "in_var[230] : -0.99\n",
      "in_var[231] : -0.8688235378265381\n",
      "in_var[232] : 0.7276470756530762\n",
      "in_var[233] : 0.9943137264251709\n",
      "in_var[234] : 0.9743137264251709\n",
      "in_var[235] : 0.9743137264251709\n",
      "in_var[236] : 0.9743137264251709\n",
      "in_var[237] : 0.9743137264251709\n",
      "in_var[238] : 0.5429412031173706\n",
      "in_var[239] : 0.4174510145187378\n",
      "in_var[240] : 0.9272549057006836\n",
      "in_var[241] : 0.8801960849761963\n",
      "in_var[242] : -0.99\n",
      "in_var[243] : -0.99\n",
      "in_var[244] : -0.99\n",
      "in_var[245] : -0.99\n",
      "in_var[246] : -0.99\n",
      "in_var[247] : -0.99\n",
      "in_var[248] : -0.99\n",
      "in_var[249] : -0.99\n",
      "in_var[250] : -0.99\n",
      "in_var[251] : -0.99\n",
      "in_var[252] : -0.99\n",
      "in_var[253] : -1.01\n",
      "in_var[254] : -1.01\n",
      "in_var[255] : -1.01\n",
      "in_var[256] : -1.01\n",
      "in_var[257] : -1.01\n",
      "in_var[258] : -1.01\n",
      "in_var[259] : -1.01\n",
      "in_var[260] : -0.38254899740219117\n",
      "in_var[261] : 0.21352945804595946\n",
      "in_var[262] : -0.1707843041419983\n",
      "in_var[263] : 0.9943137264251709\n",
      "in_var[264] : 0.9743137264251709\n",
      "in_var[265] : 0.5978431606292725\n",
      "in_var[266] : -0.92372549533844\n",
      "in_var[267] : -1.01\n",
      "in_var[268] : -0.6727451181411743\n",
      "in_var[269] : 0.21784318447113038\n",
      "in_var[270] : -0.99\n",
      "in_var[271] : -0.99\n",
      "in_var[272] : -0.99\n",
      "in_var[273] : -0.99\n",
      "in_var[274] : -0.99\n",
      "in_var[275] : -0.99\n",
      "in_var[276] : -0.99\n",
      "in_var[277] : -0.99\n",
      "in_var[278] : -0.99\n",
      "in_var[279] : -1.01\n",
      "in_var[280] : -1.01\n",
      "in_var[281] : -1.01\n",
      "in_var[282] : -1.01\n",
      "in_var[283] : -1.01\n",
      "in_var[284] : -0.99\n",
      "in_var[285] : -1.01\n",
      "in_var[286] : -0.99\n",
      "in_var[287] : -0.99\n",
      "in_var[288] : -0.99\n",
      "in_var[289] : -0.8801960849761963\n",
      "in_var[290] : -0.9821568632125854\n",
      "in_var[291] : 0.21784318447113038\n",
      "in_var[292] : 0.9943137264251709\n",
      "in_var[293] : -0.28411762952804565\n",
      "in_var[294] : -0.99\n",
      "in_var[295] : -1.01\n",
      "in_var[296] : -1.01\n",
      "in_var[297] : -1.01\n",
      "in_var[298] : -0.99\n",
      "in_var[299] : -0.99\n",
      "in_var[300] : -0.99\n",
      "in_var[301] : -0.99\n",
      "in_var[302] : -0.99\n",
      "in_var[303] : -0.99\n",
      "in_var[304] : -0.99\n",
      "in_var[305] : -0.99\n",
      "in_var[306] : -0.99\n",
      "in_var[307] : -0.99\n",
      "in_var[308] : -1.01\n",
      "in_var[309] : -0.99\n",
      "in_var[310] : -1.01\n",
      "in_var[311] : -1.01\n",
      "in_var[312] : -1.01\n",
      "in_var[313] : -0.99\n",
      "in_var[314] : -0.99\n",
      "in_var[315] : -0.99\n",
      "in_var[316] : -0.99\n",
      "in_var[317] : -0.99\n",
      "in_var[318] : -0.99\n",
      "in_var[319] : 0.1001961326599121\n",
      "in_var[320] : 0.9943137264251709\n",
      "in_var[321] : 0.5001961088180542\n",
      "in_var[322] : -0.9743137264251709\n",
      "in_var[323] : -0.99\n",
      "in_var[324] : -0.99\n",
      "in_var[325] : -1.01\n",
      "in_var[326] : -1.01\n",
      "in_var[327] : -1.01\n",
      "in_var[328] : -1.01\n",
      "in_var[329] : -1.01\n",
      "in_var[330] : -0.99\n",
      "in_var[331] : -0.99\n",
      "in_var[332] : -0.99\n",
      "in_var[333] : -0.99\n",
      "in_var[334] : -1.01\n",
      "in_var[335] : -0.99\n",
      "in_var[336] : -0.99\n",
      "in_var[337] : -0.99\n",
      "in_var[338] : -0.99\n",
      "in_var[339] : -1.01\n",
      "in_var[340] : -1.01\n",
      "in_var[341] : -0.99\n",
      "in_var[342] : -0.99\n",
      "in_var[343] : -0.99\n",
      "in_var[344] : -0.99\n",
      "in_var[345] : -0.99\n",
      "in_var[346] : -0.99\n",
      "in_var[347] : -0.9037254953384399\n",
      "in_var[348] : 0.5001961088180542\n",
      "in_var[349] : 0.9943137264251709\n",
      "in_var[350] : -0.4609803652763367\n",
      "in_var[351] : -0.99\n",
      "in_var[352] : -0.99\n",
      "in_var[353] : -1.01\n",
      "in_var[354] : -1.01\n",
      "in_var[355] : -1.01\n",
      "in_var[356] : -1.01\n",
      "in_var[357] : -0.99\n",
      "in_var[358] : -0.99\n",
      "in_var[359] : -0.99\n",
      "in_var[360] : -0.99\n",
      "in_var[361] : -1.01\n",
      "in_var[362] : -1.01\n",
      "in_var[363] : -1.01\n",
      "in_var[364] : -1.01\n",
      "in_var[365] : -0.99\n",
      "in_var[366] : -0.99\n",
      "in_var[367] : -1.01\n",
      "in_var[368] : -1.01\n",
      "in_var[369] : -0.99\n",
      "in_var[370] : -0.99\n",
      "in_var[371] : -0.99\n",
      "in_var[372] : -0.99\n",
      "in_var[373] : -0.99\n",
      "in_var[374] : -0.99\n",
      "in_var[375] : -0.99\n",
      "in_var[376] : -0.7154902124404907\n",
      "in_var[377] : 0.9001960849761963\n",
      "in_var[378] : 0.7547058963775635\n",
      "in_var[379] : 0.2649020051956177\n",
      "in_var[380] : -0.16294116735458375\n",
      "in_var[381] : -1.0021568632125855\n",
      "in_var[382] : -1.01\n",
      "in_var[383] : -1.01\n",
      "in_var[384] : -0.99\n",
      "in_var[385] : -1.01\n",
      "in_var[386] : -1.01\n",
      "in_var[387] : -0.99\n",
      "in_var[388] : -1.01\n",
      "in_var[389] : -1.01\n",
      "in_var[390] : -1.01\n",
      "in_var[391] : -0.99\n",
      "in_var[392] : -0.99\n",
      "in_var[393] : -1.01\n",
      "in_var[394] : -1.01\n",
      "in_var[395] : -1.01\n",
      "in_var[396] : -1.01\n",
      "in_var[397] : -0.99\n",
      "in_var[398] : -0.99\n",
      "in_var[399] : -0.99\n",
      "in_var[400] : -0.99\n",
      "in_var[401] : -0.99\n",
      "in_var[402] : -0.99\n",
      "in_var[403] : -0.99\n",
      "in_var[404] : -0.99\n",
      "in_var[405] : -0.3547058606147766\n",
      "in_var[406] : 0.8723529481887817\n",
      "in_var[407] : 0.9943137264251709\n",
      "in_var[408] : 0.9743137264251709\n",
      "in_var[409] : -0.05666666269302368\n",
      "in_var[410] : -0.8139215803146362\n",
      "in_var[411] : -0.99\n",
      "in_var[412] : -0.99\n",
      "in_var[413] : -1.01\n",
      "in_var[414] : -1.01\n",
      "in_var[415] : -1.01\n",
      "in_var[416] : -0.99\n",
      "in_var[417] : -1.01\n",
      "in_var[418] : -1.01\n",
      "in_var[419] : -1.01\n",
      "in_var[420] : -0.99\n",
      "in_var[421] : -1.01\n",
      "in_var[422] : -1.01\n",
      "in_var[423] : -1.01\n",
      "in_var[424] : -0.99\n",
      "in_var[425] : -0.99\n",
      "in_var[426] : -0.99\n",
      "in_var[427] : -0.99\n",
      "in_var[428] : -0.99\n",
      "in_var[429] : -0.99\n",
      "in_var[430] : -0.99\n",
      "in_var[431] : -0.99\n",
      "in_var[432] : -0.99\n",
      "in_var[433] : -1.01\n",
      "in_var[434] : -0.6370588445663452\n",
      "in_var[435] : 0.448823561668396\n",
      "in_var[436] : 0.9943137264251709\n",
      "in_var[437] : 0.9943137264251709\n",
      "in_var[438] : 0.18647063732147218\n",
      "in_var[439] : -0.7782353067398071\n",
      "in_var[440] : -1.01\n",
      "in_var[441] : -1.01\n",
      "in_var[442] : -0.99\n",
      "in_var[443] : -0.99\n",
      "in_var[444] : -1.01\n",
      "in_var[445] : -1.01\n",
      "in_var[446] : -1.01\n",
      "in_var[447] : -0.99\n",
      "in_var[448] : -1.01\n",
      "in_var[449] : -1.01\n",
      "in_var[450] : -1.01\n",
      "in_var[451] : -1.01\n",
      "in_var[452] : -1.01\n",
      "in_var[453] : -1.01\n",
      "in_var[454] : -0.99\n",
      "in_var[455] : -0.99\n",
      "in_var[456] : -0.99\n",
      "in_var[457] : -0.99\n",
      "in_var[458] : -1.01\n",
      "in_var[459] : -1.01\n",
      "in_var[460] : -0.99\n",
      "in_var[461] : -0.99\n",
      "in_var[462] : -0.99\n",
      "in_var[463] : -0.8645098114013672\n",
      "in_var[464] : -0.260588219165802\n",
      "in_var[465] : 0.9864705896377564\n",
      "in_var[466] : 0.9943137264251709\n",
      "in_var[467] : 0.47666669845581056\n",
      "in_var[468] : -0.99\n",
      "in_var[469] : -1.01\n",
      "in_var[470] : -1.01\n",
      "in_var[471] : -1.01\n",
      "in_var[472] : -1.01\n",
      "in_var[473] : -1.01\n",
      "in_var[474] : -1.01\n",
      "in_var[475] : -0.99\n",
      "in_var[476] : -1.01\n",
      "in_var[477] : -1.01\n",
      "in_var[478] : -1.01\n",
      "in_var[479] : -1.01\n",
      "in_var[480] : -1.01\n",
      "in_var[481] : -0.99\n",
      "in_var[482] : -0.99\n",
      "in_var[483] : -0.99\n",
      "in_var[484] : -0.99\n",
      "in_var[485] : -0.99\n",
      "in_var[486] : -1.01\n",
      "in_var[487] : -1.01\n",
      "in_var[488] : -1.01\n",
      "in_var[489] : -0.99\n",
      "in_var[490] : -0.99\n",
      "in_var[491] : -0.99\n",
      "in_var[492] : -0.99\n",
      "in_var[493] : 0.9629411792755127\n",
      "in_var[494] : 0.9943137264251709\n",
      "in_var[495] : 0.9429411792755127\n",
      "in_var[496] : -0.48803918600082397\n",
      "in_var[497] : -1.01\n",
      "in_var[498] : -0.99\n",
      "in_var[499] : -1.01\n",
      "in_var[500] : -1.01\n",
      "in_var[501] : -1.01\n",
      "in_var[502] : -1.01\n",
      "in_var[503] : -1.01\n",
      "in_var[504] : -1.01\n",
      "in_var[505] : -1.01\n",
      "in_var[506] : -1.01\n",
      "in_var[507] : -1.01\n",
      "in_var[508] : -0.99\n",
      "in_var[509] : -0.99\n",
      "in_var[510] : -0.99\n",
      "in_var[511] : -0.99\n",
      "in_var[512] : -0.99\n",
      "in_var[513] : -1.01\n",
      "in_var[514] : -0.9899999999985737\n",
      "in_var[515] : -0.99\n",
      "in_var[516] : -0.99\n",
      "in_var[517] : -0.99\n",
      "in_var[518] : -0.6292157077789307\n",
      "in_var[519] : 0.009607901573181152\n",
      "in_var[520] : 0.44529415130615235\n",
      "in_var[521] : 0.9743137264251709\n",
      "in_var[522] : 0.9743137264251709\n",
      "in_var[523] : 0.6135294342041016\n",
      "in_var[524] : -0.9943137264251709\n",
      "in_var[525] : -1.01\n",
      "in_var[526] : -1.01\n",
      "in_var[527] : -1.01\n",
      "in_var[528] : -1.01\n",
      "in_var[529] : -1.01\n",
      "in_var[530] : -1.01\n",
      "in_var[531] : -1.01\n",
      "in_var[532] : -0.99\n",
      "in_var[533] : -0.99\n",
      "in_var[534] : -1.01\n",
      "in_var[535] : -1.01\n",
      "in_var[536] : -1.01\n",
      "in_var[537] : -0.99\n",
      "in_var[538] : -0.99\n",
      "in_var[539] : -0.99\n",
      "in_var[540] : -0.99\n",
      "in_var[541] : -0.99\n",
      "in_var[542] : -0.99\n",
      "in_var[543] : -0.99\n",
      "in_var[544] : -0.6841176652908325\n",
      "in_var[545] : 0.17078436374664308\n",
      "in_var[546] : 0.8060784435272217\n",
      "in_var[547] : 0.9743137264251709\n",
      "in_var[548] : 0.9743137264251709\n",
      "in_var[549] : 0.9743137264251709\n",
      "in_var[550] : 0.9507843160629272\n",
      "in_var[551] : 0.4174510145187378\n",
      "in_var[552] : -1.01\n",
      "in_var[553] : -1.01\n",
      "in_var[554] : -1.01\n",
      "in_var[555] : -1.01\n",
      "in_var[556] : -1.01\n",
      "in_var[557] : -1.01\n",
      "in_var[558] : -0.99\n",
      "in_var[559] : -1.01\n",
      "in_var[560] : -0.99\n",
      "in_var[561] : -0.99\n",
      "in_var[562] : -1.01\n",
      "in_var[563] : -1.01\n",
      "in_var[564] : -1.01\n",
      "in_var[565] : -1.01\n",
      "in_var[566] : -1.01\n",
      "in_var[567] : -0.99\n",
      "in_var[568] : -0.99\n",
      "in_var[569] : -1.01\n",
      "in_var[570] : -0.8217647171020508\n",
      "in_var[571] : -0.09588234663009644\n",
      "in_var[572] : 0.7433333492279053\n",
      "in_var[573] : 0.9943137264251709\n",
      "in_var[574] : 0.9743137264251709\n",
      "in_var[575] : 0.9743137264251709\n",
      "in_var[576] : 0.9743137264251709\n",
      "in_var[577] : 0.5664706134796142\n",
      "in_var[578] : -0.3982352709770203\n",
      "in_var[579] : -1.01\n",
      "in_var[580] : -1.01\n",
      "in_var[581] : -1.01\n",
      "in_var[582] : -1.01\n",
      "in_var[583] : -1.01\n",
      "in_var[584] : -1.01\n",
      "in_var[585] : -1.01\n",
      "in_var[586] : -0.99\n",
      "in_var[587] : -1.01\n",
      "in_var[588] : -1.01\n",
      "in_var[589] : -1.01\n",
      "in_var[590] : -1.01\n",
      "in_var[591] : -1.01\n",
      "in_var[592] : -1.01\n",
      "in_var[593] : -1.01\n",
      "in_var[594] : -1.01\n",
      "in_var[595] : -1.01\n",
      "in_var[596] : -0.8096078538894653\n",
      "in_var[597] : -0.47235291242599486\n",
      "in_var[598] : 0.6805882549285889\n",
      "in_var[599] : 0.9943137264251709\n",
      "in_var[600] : 0.9943137264251709\n",
      "in_var[601] : 0.9743137264251709\n",
      "in_var[602] : 0.9743137264251709\n",
      "in_var[603] : 0.5429412031173706\n",
      "in_var[604] : -0.3747058606147766\n",
      "in_var[605] : -0.9943137264251709\n",
      "in_var[606] : -1.01\n",
      "in_var[607] : -1.01\n",
      "in_var[608] : -1.01\n",
      "in_var[609] : -1.01\n",
      "in_var[610] : -0.99\n",
      "in_var[611] : -1.01\n",
      "in_var[612] : -1.01\n",
      "in_var[613] : -0.99\n",
      "in_var[614] : -1.01\n",
      "in_var[615] : -0.99\n",
      "in_var[616] : -1.01\n",
      "in_var[617] : -0.99\n",
      "in_var[618] : -1.01\n",
      "in_var[619] : -1.01\n",
      "in_var[620] : -1.01\n",
      "in_var[621] : -1.01\n",
      "in_var[622] : -0.8688235378265381\n",
      "in_var[623] : 0.3311765098571777\n",
      "in_var[624] : 0.7076470756530762\n",
      "in_var[625] : 0.9943137264251709\n",
      "in_var[626] : 0.9743137264251709\n",
      "in_var[627] : 0.9943137264251709\n",
      "in_var[628] : 0.9943137264251709\n",
      "in_var[629] : 0.539411792755127\n",
      "in_var[630] : -0.36254899740219115\n",
      "in_var[631] : -0.919411768913269\n",
      "in_var[632] : -0.99\n",
      "in_var[633] : -1.01\n",
      "in_var[634] : -1.01\n",
      "in_var[635] : -1.01\n",
      "in_var[636] : -1.01\n",
      "in_var[637] : -1.01\n",
      "in_var[638] : -1.01\n",
      "in_var[639] : -1.01\n",
      "in_var[640] : -1.01\n",
      "in_var[641] : -0.99\n",
      "in_var[642] : -1.01\n",
      "in_var[643] : -1.01\n",
      "in_var[644] : -0.99\n",
      "in_var[645] : -1.01\n",
      "in_var[646] : -1.01\n",
      "in_var[647] : -1.01\n",
      "in_var[648] : -0.5786274766921997\n",
      "in_var[649] : 0.3390196466445923\n",
      "in_var[650] : 0.762549033164978\n",
      "in_var[651] : 0.9743137264251709\n",
      "in_var[652] : 0.9943137264251709\n",
      "in_var[653] : 0.9943137264251709\n",
      "in_var[654] : 0.9943137264251709\n",
      "in_var[655] : 0.92372549533844\n",
      "in_var[656] : 0.0331373119354248\n",
      "in_var[657] : -0.9037254953384399\n",
      "in_var[658] : -0.99\n",
      "in_var[659] : -0.99\n",
      "in_var[660] : -0.99\n",
      "in_var[661] : -1.01\n",
      "in_var[662] : -0.99\n",
      "in_var[663] : -0.99\n",
      "in_var[664] : -0.99\n",
      "in_var[665] : -1.01\n",
      "in_var[666] : -1.01\n",
      "in_var[667] : -1.01\n",
      "in_var[668] : -1.01\n",
      "in_var[669] : -1.01\n",
      "in_var[670] : -1.01\n",
      "in_var[671] : -0.99\n",
      "in_var[672] : -1.01\n",
      "in_var[673] : -0.99\n",
      "in_var[674] : -0.99\n",
      "in_var[675] : -0.99\n",
      "in_var[676] : 0.07666672229766845\n",
      "in_var[677] : 0.9743137264251709\n",
      "in_var[678] : 0.9743137264251709\n",
      "in_var[679] : 0.9743137264251709\n",
      "in_var[680] : 0.6527451181411743\n",
      "in_var[681] : 0.0688235855102539\n",
      "in_var[682] : 0.045294175148010256\n",
      "in_var[683] : -0.8645098114013672\n",
      "in_var[684] : -0.99\n",
      "in_var[685] : -0.99\n",
      "in_var[686] : -0.99\n",
      "in_var[687] : -0.99\n",
      "in_var[688] : -0.99\n",
      "in_var[689] : -1.01\n",
      "in_var[690] : -0.99\n",
      "in_var[691] : -0.99\n",
      "in_var[692] : -0.99\n",
      "in_var[693] : -1.01\n",
      "in_var[694] : -0.99\n",
      "in_var[695] : -0.99\n",
      "in_var[696] : -1.01\n",
      "in_var[697] : -1.01\n",
      "in_var[698] : -1.01\n",
      "in_var[699] : -1.01\n",
      "in_var[700] : -1.01\n",
      "in_var[701] : -0.99\n",
      "in_var[702] : -1.01\n",
      "in_var[703] : -0.99\n",
      "in_var[704] : -1.01\n",
      "in_var[705] : -0.99\n",
      "in_var[706] : -1.01\n",
      "in_var[707] : -1.01\n",
      "in_var[708] : -1.01\n",
      "in_var[709] : -1.01\n",
      "in_var[710] : -1.01\n",
      "in_var[711] : -1.01\n",
      "in_var[712] : -1.01\n",
      "in_var[713] : -1.01\n",
      "in_var[714] : -1.01\n",
      "in_var[715] : -0.99\n",
      "in_var[716] : -1.01\n",
      "in_var[717] : -1.01\n",
      "in_var[718] : -1.01\n",
      "in_var[719] : -0.99\n",
      "in_var[720] : -1.01\n",
      "in_var[721] : -0.99\n",
      "in_var[722] : -0.99\n",
      "in_var[723] : -1.01\n",
      "in_var[724] : -1.01\n",
      "in_var[725] : -0.99\n",
      "in_var[726] : -0.99\n",
      "in_var[727] : -0.99\n",
      "in_var[728] : -1.01\n",
      "in_var[729] : -0.99\n",
      "in_var[730] : -0.99\n",
      "in_var[731] : -1.01\n",
      "in_var[732] : -1.01\n",
      "in_var[733] : -1.01\n",
      "in_var[734] : -1.01\n",
      "in_var[735] : -0.99\n",
      "in_var[736] : -1.01\n",
      "in_var[737] : -1.01\n",
      "in_var[738] : -1.01\n",
      "in_var[739] : -1.01\n",
      "in_var[740] : -1.01\n",
      "in_var[741] : -1.01\n",
      "in_var[742] : -1.01\n",
      "in_var[743] : -1.01\n",
      "in_var[744] : -1.01\n",
      "in_var[745] : -1.01\n",
      "in_var[746] : -1.01\n",
      "in_var[747] : -1.01\n",
      "in_var[748] : -1.01\n",
      "in_var[749] : -0.99\n",
      "in_var[750] : -1.01\n",
      "in_var[751] : -0.99\n",
      "in_var[752] : -0.99\n",
      "in_var[753] : -1.01\n",
      "in_var[754] : -1.01\n",
      "in_var[755] : -1.01\n",
      "in_var[756] : -0.99\n",
      "in_var[757] : -0.99\n",
      "in_var[758] : -1.01\n",
      "in_var[759] : -1.01\n",
      "in_var[760] : -1.01\n",
      "in_var[761] : -1.01\n",
      "in_var[762] : -0.99\n",
      "in_var[763] : -1.01\n",
      "in_var[764] : -0.99\n",
      "in_var[765] : -1.01\n",
      "in_var[766] : -1.01\n",
      "in_var[767] : -0.99\n",
      "in_var[768] : -0.99\n",
      "in_var[769] : -1.01\n",
      "in_var[770] : -1.01\n",
      "in_var[771] : -1.01\n",
      "in_var[772] : -1.01\n",
      "in_var[773] : -1.01\n",
      "in_var[774] : -0.99\n",
      "in_var[775] : -0.99\n",
      "in_var[776] : -0.99\n",
      "in_var[777] : -1.01\n",
      "in_var[778] : -0.99\n",
      "in_var[779] : -0.99\n",
      "in_var[780] : -0.99\n",
      "in_var[781] : -1.01\n",
      "in_var[782] : -1.01\n",
      "in_var[783] : -1.01\n",
      "affine_var0[0] : 0.8743870716538487\n",
      "affine_var0[1] : -0.0036593140166037985\n",
      "affine_var0[2] : 2.7259820513630135\n",
      "affine_var0[3] : 1.4101405415486208\n",
      "affine_var0[4] : 0.7069504812578287\n",
      "affine_var0[5] : -0.6684707030813307\n",
      "affine_var0[6] : 2.459773019377948\n",
      "affine_var0[7] : 1.2401479120229122\n",
      "affine_var0[8] : 3.2657361327961385\n",
      "affine_var0[9] : 0.5634070439771975\n",
      "affine_var0[10] : 1.2308930835014606\n",
      "affine_var0[11] : -1.0540171469840893\n",
      "affine_var0[12] : 3.959477571121183\n",
      "affine_var0[13] : 3.2153587813038285\n",
      "affine_var0[14] : 2.461111643057541\n",
      "affine_var0[15] : -1.770686775513236\n",
      "affine_var0[16] : 1.6663524007610993\n",
      "affine_var0[17] : 4.02343254671761\n",
      "affine_var0[18] : -1.3445468870396522\n",
      "affine_var0[19] : 0.8078666924574757\n",
      "affine_var0[20] : 3.9667617561907824\n",
      "affine_var0[21] : 2.7521722404669013\n",
      "affine_var0[22] : 0.4862793498255957\n",
      "affine_var0[23] : 0.1566105826629305\n",
      "affine_var0[24] : 0.5019606604728145\n",
      "affine_var0[25] : 0.15233070297422907\n",
      "affine_var0[26] : 0.6812798626577794\n",
      "affine_var0[27] : 1.9901158691572312\n",
      "affine_var0[28] : 1.5275841848330265\n",
      "affine_var0[29] : 1.8194582009819487\n",
      "affine_var0[30] : -0.9163034811767976\n",
      "affine_var0[31] : -1.0891676757177962\n",
      "affine_var0[32] : 2.5696224572129314\n",
      "affine_var0[33] : -0.126361546812722\n",
      "affine_var0[34] : 1.8370024761423767\n",
      "affine_var0[35] : -2.841948115640435\n",
      "affine_var0[36] : 2.140900441363852\n",
      "affine_var0[37] : 1.8155571658543972\n",
      "affine_var0[38] : -0.930860402513621\n",
      "affine_var0[39] : 0.44568793675713\n",
      "affine_var0[40] : 2.345756507719361\n",
      "affine_var0[41] : 1.855150858454159\n",
      "affine_var0[42] : 0.5112576700205131\n",
      "affine_var0[43] : -1.4820228053402045\n",
      "affine_var0[44] : 0.41706638009641045\n",
      "affine_var0[45] : 0.9384047056138257\n",
      "affine_var0[46] : 0.41530648371379625\n",
      "affine_var0[47] : 1.2933100708281577\n",
      "affine_var0[48] : 0.859042488921271\n",
      "affine_var0[49] : 1.9709018762704853\n",
      "affine_var0[50] : 2.4541192493185795\n",
      "affine_var0[51] : 0.12364475688493942\n",
      "affine_var0[52] : -1.4034435375271492\n",
      "affine_var0[53] : 1.9388544313952005\n",
      "affine_var0[54] : -1.4391894879462355\n",
      "affine_var0[55] : 2.969362266730888\n",
      "affine_var0[56] : -1.3233110074515566\n",
      "affine_var0[57] : -0.14688346972022626\n",
      "affine_var0[58] : 1.374127323646139\n",
      "affine_var0[59] : -1.3044525220960679\n",
      "affine_var0[60] : 0.05649296326772035\n",
      "affine_var0[61] : 2.1496611591018975\n",
      "affine_var0[62] : 1.937547505814079\n",
      "affine_var0[63] : -0.6849984465973062\n",
      "affine_var0[64] : 4.388076628656733\n",
      "affine_var0[65] : 1.1852274327787737\n",
      "affine_var0[66] : -0.6746022336058309\n",
      "affine_var0[67] : -1.1259846834826381\n",
      "affine_var0[68] : -1.135087441834557\n",
      "affine_var0[69] : 0.08070880766476024\n",
      "affine_var0[70] : 2.3708504969388895\n",
      "affine_var0[71] : -0.38514055482475684\n",
      "affine_var0[72] : 0.3971340852215213\n",
      "affine_var0[73] : 3.016521343379816\n",
      "affine_var0[74] : 2.6376363604240645\n",
      "affine_var0[75] : -0.7140580373188453\n",
      "affine_var0[76] : -0.838119291506476\n",
      "affine_var0[77] : 0.17526638120864754\n",
      "affine_var0[78] : -0.14389342825443452\n",
      "affine_var0[79] : -1.0679415375728352\n",
      "affine_var0[80] : -0.6785747790745489\n",
      "affine_var0[81] : -0.7381382714981025\n",
      "affine_var0[82] : -2.148564946722322\n",
      "affine_var0[83] : 0.61339777743034\n",
      "affine_var0[84] : -1.1097439136517606\n",
      "affine_var0[85] : 0.7643342921700013\n",
      "affine_var0[86] : -0.07563315350460711\n",
      "affine_var0[87] : 1.8984584851499728\n",
      "affine_var0[88] : 1.9762044348219547\n",
      "affine_var0[89] : 2.4047548447545086\n",
      "affine_var0[90] : 0.7487464168484941\n",
      "affine_var0[91] : -0.5763743520834821\n",
      "affine_var0[92] : 1.1052743227843334\n",
      "affine_var0[93] : -1.217103510079685\n",
      "affine_var0[94] : 0.20462925274665936\n",
      "affine_var0[95] : 1.0977650418981164\n",
      "affine_var0[96] : 0.07156625402458122\n",
      "affine_var0[97] : 0.24107393543984013\n",
      "affine_var0[98] : -0.7322122327756014\n",
      "affine_var0[99] : 0.417233347355738\n",
      "relu_var0[0] : 0.8743870716538487\n",
      "relu_var0[1] : 0.0\n",
      "relu_var0[2] : 2.7259820513630135\n",
      "relu_var0[3] : 1.4101405415486208\n",
      "relu_var0[4] : 0.7069504812578287\n",
      "relu_var0[5] : 0.0\n",
      "relu_var0[6] : 2.459773019377948\n",
      "relu_var0[7] : 1.2401479120229122\n",
      "relu_var0[8] : 3.2657361327961385\n",
      "relu_var0[9] : 0.5634070439771975\n",
      "relu_var0[10] : 1.2308930835014606\n",
      "relu_var0[11] : 0.0\n",
      "relu_var0[12] : 3.959477571121183\n",
      "relu_var0[13] : 3.2153587813038285\n",
      "relu_var0[14] : 2.461111643057541\n",
      "relu_var0[15] : 0.0\n",
      "relu_var0[16] : 1.6663524007610993\n",
      "relu_var0[17] : 4.02343254671761\n",
      "relu_var0[18] : 0.0\n",
      "relu_var0[19] : 0.8078666924574757\n",
      "relu_var0[20] : 3.9667617561907824\n",
      "relu_var0[21] : 2.7521722404669013\n",
      "relu_var0[22] : 0.4862793498255957\n",
      "relu_var0[23] : 0.1566105826629305\n",
      "relu_var0[24] : 0.5019606604728145\n",
      "relu_var0[25] : 0.18988176761405542\n",
      "relu_var0[26] : 0.6812798626577794\n",
      "relu_var0[27] : 1.9901158691572312\n",
      "relu_var0[28] : 1.5275841848330265\n",
      "relu_var0[29] : 1.8194582009819487\n",
      "relu_var0[30] : 0.0\n",
      "relu_var0[31] : 0.0\n",
      "relu_var0[32] : 2.5696224572129314\n",
      "relu_var0[33] : 0.0\n",
      "relu_var0[34] : 1.8370024761423767\n",
      "relu_var0[35] : 0.0\n",
      "relu_var0[36] : 2.140900441363852\n",
      "relu_var0[37] : 1.8155571658543972\n",
      "relu_var0[38] : 0.0\n",
      "relu_var0[39] : 0.44568793675713\n",
      "relu_var0[40] : 2.345756507719361\n",
      "relu_var0[41] : 1.855150858454159\n",
      "relu_var0[42] : 0.5112576700205131\n",
      "relu_var0[43] : 0.0\n",
      "relu_var0[44] : 0.41706638009641045\n",
      "relu_var0[45] : 0.9384047056138257\n",
      "relu_var0[46] : 0.41530648371379625\n",
      "relu_var0[47] : 1.2933100708281577\n",
      "relu_var0[48] : 0.859042488921271\n",
      "relu_var0[49] : 1.9709018762704853\n",
      "relu_var0[50] : 2.4541192493185795\n",
      "relu_var0[51] : 0.12364475688493941\n",
      "relu_var0[52] : 0.0\n",
      "relu_var0[53] : 1.9388544313952005\n",
      "relu_var0[54] : 0.0\n",
      "relu_var0[55] : 2.969362266730888\n",
      "relu_var0[56] : 0.0\n",
      "relu_var0[57] : 0.0\n",
      "relu_var0[58] : 1.374127323646139\n",
      "relu_var0[59] : 0.0\n",
      "relu_var0[60] : 0.05649296326772036\n",
      "relu_var0[61] : 2.1496611591018975\n",
      "relu_var0[62] : 1.937547505814079\n",
      "relu_var0[63] : 0.0\n",
      "relu_var0[64] : 4.388076628656733\n",
      "relu_var0[65] : 1.1852274327787737\n",
      "relu_var0[66] : 0.0\n",
      "relu_var0[67] : 0.0\n",
      "relu_var0[68] : 0.0\n",
      "relu_var0[69] : 0.12373578174424402\n",
      "relu_var0[70] : 2.3708504969388895\n",
      "relu_var0[71] : 0.0\n",
      "relu_var0[72] : 0.3971340852215213\n",
      "relu_var0[73] : 3.016521343379816\n",
      "relu_var0[74] : 2.6376363604240645\n",
      "relu_var0[75] : 0.0\n",
      "relu_var0[76] : 0.0\n",
      "relu_var0[77] : 0.17526638120864754\n",
      "relu_var0[78] : 0.0\n",
      "relu_var0[79] : 0.0\n",
      "relu_var0[80] : 0.0\n",
      "relu_var0[81] : 0.0\n",
      "relu_var0[82] : 0.0\n",
      "relu_var0[83] : 0.61339777743034\n",
      "relu_var0[84] : 0.0\n",
      "relu_var0[85] : 0.7643342921700013\n",
      "relu_var0[86] : 0.040254639573601064\n",
      "relu_var0[87] : 1.8984584851499728\n",
      "relu_var0[88] : 1.9762044348219547\n",
      "relu_var0[89] : 2.4047548447545086\n",
      "relu_var0[90] : 0.7487464168484941\n",
      "relu_var0[91] : 0.0\n",
      "relu_var0[92] : 1.1052743227843334\n",
      "relu_var0[93] : 0.0\n",
      "relu_var0[94] : 0.20462925274665936\n",
      "relu_var0[95] : 1.0977650418981164\n",
      "relu_var0[96] : 0.07156625402458122\n",
      "relu_var0[97] : 0.24107393543984013\n",
      "relu_var0[98] : 0.0\n",
      "relu_var0[99] : 0.417233347355738\n",
      "affine_var2[0] : 0.5730239543289279\n",
      "affine_var2[1] : 5.8775091515006785\n",
      "affine_var2[2] : 1.534652970014724\n",
      "affine_var2[3] : -3.3744972114149148\n",
      "affine_var2[4] : 1.987318748434435\n",
      "affine_var2[5] : -0.9418430757434093\n",
      "affine_var2[6] : 0.7451570455512413\n",
      "affine_var2[7] : -0.2496344699306643\n",
      "affine_var2[8] : 2.2348439245422775\n",
      "affine_var2[9] : 1.0285426713797374\n",
      "affine_var2[10] : 1.7480909209164814\n",
      "affine_var2[11] : 3.4964644085771646\n",
      "affine_var2[12] : 2.4618837257162136\n",
      "affine_var2[13] : -1.154546373967916\n",
      "affine_var2[14] : -0.894833078988216\n",
      "affine_var2[15] : 5.953025665556767\n",
      "affine_var2[16] : 0.609876462426524\n",
      "affine_var2[17] : 3.345054915814223\n",
      "affine_var2[18] : -0.815482765553903\n",
      "affine_var2[19] : 5.6408402808842295\n",
      "affine_var2[20] : 0.25610122560058657\n",
      "affine_var2[21] : 6.411874215682816\n",
      "affine_var2[22] : 2.1197816486160894\n",
      "affine_var2[23] : 5.3501195244874085\n",
      "affine_var2[24] : 7.693084634714262\n",
      "affine_var2[25] : -0.5895371798024206\n",
      "affine_var2[26] : 4.685314230558751\n",
      "affine_var2[27] : 4.806512577590137\n",
      "affine_var2[28] : 1.4743600461853679\n",
      "affine_var2[29] : 4.015905078058068\n",
      "relu_var2[0] : 0.5730239543289277\n",
      "relu_var2[1] : 5.8775091515006785\n",
      "relu_var2[2] : 1.534652970014724\n",
      "relu_var2[3] : 0.0\n",
      "relu_var2[4] : 1.987318748434435\n",
      "relu_var2[5] : 0.0\n",
      "relu_var2[6] : 0.7451570455512414\n",
      "relu_var2[7] : 0.0\n",
      "relu_var2[8] : 2.2348439245422775\n",
      "relu_var2[9] : 1.0285426713797374\n",
      "relu_var2[10] : 1.7480909209164814\n",
      "relu_var2[11] : 3.4964644085771646\n",
      "relu_var2[12] : 2.4618837257162136\n",
      "relu_var2[13] : 0.0\n",
      "relu_var2[14] : 0.0\n",
      "relu_var2[15] : 5.953025665556767\n",
      "relu_var2[16] : 0.6098764624265239\n",
      "relu_var2[17] : 3.345054915814223\n",
      "relu_var2[18] : 0.0\n",
      "relu_var2[19] : 5.6408402808842295\n",
      "relu_var2[20] : 0.2561012256005866\n",
      "relu_var2[21] : 6.411874215682816\n",
      "relu_var2[22] : 2.1197816486160894\n",
      "relu_var2[23] : 5.3501195244874085\n",
      "relu_var2[24] : 7.693084634714262\n",
      "relu_var2[25] : 0.0\n",
      "relu_var2[26] : 4.685314230558751\n",
      "relu_var2[27] : 4.806512577590137\n",
      "relu_var2[28] : 1.4743600461853679\n",
      "relu_var2[29] : 4.015905078058068\n",
      "last_affine_var[0] : 0.563372517621036\n",
      "last_affine_var[1] : 1.1998200804624037\n",
      "last_affine_var[2] : 0.01960639424171262\n",
      "last_affine_var[3] : 8.83940551528907\n",
      "last_affine_var[4] : -12.37087515289809\n",
      "last_affine_var[5] : 10.895581637537596\n",
      "last_affine_var[6] : -3.3004797553502394\n",
      "last_affine_var[7] : 1.8987540880413771\n",
      "last_affine_var[8] : -3.377321673437918\n",
      "last_affine_var[9] : -2.3098863667390166\n"
     ]
    }
   ],
   "source": [
    "all_vars = snv_copy.getVars()\n",
    "for var in all_vars:\n",
    "    print(\"{} : {}\".format(var.getAttr(\"varname\"), var.getAttr(\"x\")))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for MILP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'all_var = milp_model.getVars()\\nfor var in all_var:\\n    print(var)'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milp_verifier = MILPVerifier(nn, test_image, eps, print_log=False)\n",
    "milp_verifier.generate_constraints_for_net(until_layer_neuron=[layer_index, neuron_index])\n",
    "milp_model = milp_verifier.model\n",
    "milp_model.update()\n",
    "\n",
    "\"\"\"all_var = milp_model.getVars()\n",
    "for var in all_var:\n",
    "    print(var)\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.0\n"
     ]
    }
   ],
   "source": [
    "milp_copy = milp_model.copy()\n",
    "milp_copy.Params.LogToConsole = 0\n",
    "add_min_constr(milp_copy, neuron_name)\n",
    "optimize_model(milp_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt value: 0.5622137652362753\n"
     ]
    }
   ],
   "source": [
    "milp_copy = milp_model.copy()\n",
    "milp_copy.Params.LogToConsole = 0\n",
    "add_max_constr(milp_copy, neuron_name)\n",
    "optimize_model(milp_copy, neuron_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}