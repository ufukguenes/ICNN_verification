{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import script.DHOV.DataSampling as ds\n",
    "import script.DHOV.DHOV as dhov\n",
    "from torch.utils.data import DataLoader\n",
    "from script.NeuralNets.Networks import SequentialNN, ICNN, ICNNApproxMax, ICNNLogical\n",
    "from script.Verification.Verifier import SingleNeuronVerifier, MILPVerifier, DHOVVerifier\n",
    "from script.dataInit import Rhombus, ConvexDataset\n",
    "import polytope as pc\n",
    "from script.settings import device, data_type\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def net_2d():\n",
    "    batch_size = 10\n",
    "    epochs = 30\n",
    "    number_of_train_samples = 10000\n",
    "    hyper_lambda = 1\n",
    "    x_range = [-1.5, 1.5]\n",
    "    y_range = [-1.5, 1.5]\n",
    "\n",
    "    included_space, ambient_space = Rhombus().get_uniform_samples(number_of_train_samples, x_range,\n",
    "                                                                  y_range)  # samples will be split in inside and outside the rhombus\n",
    "\n",
    "    dataset_in = ConvexDataset(data=included_space)\n",
    "    train_loader = DataLoader(dataset_in, batch_size=batch_size, shuffle=True)\n",
    "    dataset = ConvexDataset(data=ambient_space)\n",
    "    ambient_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    \"\"\"W1 = [1. 1.; 1. -1.]\n",
    "    b1 = [0., 0.]\n",
    "    W2 = [1. 1.; 1. -1.]\n",
    "    b2 = [-0.5, 0.]\n",
    "    W3 = [-1. 1.; 1. 1.]\n",
    "    b3 = [3., 0.] \"\"\"\n",
    "\n",
    "    nn = SequentialNN([2, 2, 2, 2])\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        parameter_list = list(nn.parameters())\n",
    "        parameter_list[0].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "        parameter_list[1].data = torch.tensor([0, 0], dtype=data_type).to(device)\n",
    "        parameter_list[2].data = torch.tensor([[1, 1], [1, -1]], dtype=data_type).to(device)\n",
    "        parameter_list[3].data = torch.tensor([-0.5, 0], dtype=data_type).to(device)\n",
    "        parameter_list[4].data = torch.tensor([[-1, 1], [1, 1]], dtype=data_type).to(device)\n",
    "        parameter_list[5].data = torch.tensor([3, 0], dtype=data_type).to(device)\n",
    "\n",
    "    # nn.load_state_dict(torch.load(\"nn_2x2.pt\"), strict=False)\n",
    "    # train_sequential_2(nn, train_loader, ambient_loader, epochs=epochs)\n",
    "\n",
    "\n",
    "    # matplotlib.use('TkAgg')\n",
    "\n",
    "    # torch.save(nn.state_dict(), \"nn_2x2.pt\")\n",
    "\n",
    "\n",
    "    test_image = torch.tensor([[0, 0]], dtype=data_type).to(device)\n",
    "\n",
    "\n",
    "    icnns = []\n",
    "    for i in range((len(parameter_list) - 2) // 2):\n",
    "        layer_index = int(i / 2)\n",
    "        icnn_input_size = nn.layer_widths[layer_index + 1]\n",
    "        #next_net = ICNN([icnn_input_size, 10, 10, 10, 2 * icnn_input_size, 1], force_positive_init=False, init_scaling=10, init_all_with_zeros=False)\n",
    "        next_net = ICNNLogical([icnn_input_size, 10, 10, 10, 1], force_positive_init=False, with_two_layers=False, init_scaling=10, init_all_with_zeros=False)\n",
    "        #next_net = ICNNApproxMax([icnn_input_size, 10, 10, 10, 1], maximum_function=\"SMU\", function_parameter=0.1, force_positive_init=False, init_scaling=10, init_all_with_zeros=False)\n",
    "\n",
    "        icnns.append(next_net)\n",
    "\n",
    "\n",
    "    icnns = \\\n",
    "        dhov.start_verification(nn, test_image, icnns, eps=1, icnn_epochs=100, icnn_batch_size=1000, sample_count=1000, sample_new=True, use_over_approximation=True,\n",
    "                                sample_over_input_space=False, sample_over_output_space=True, force_inclusion_steps=0,\n",
    "                                keep_ambient_space=False, data_grad_descent_steps=0, train_outer=False, preemptive_stop=False,\n",
    "                                even_gradient_training=False,\n",
    "                                should_plot=\"none\", optimizer=\"SdLBFGS\", init_network=True, adapt_lambda=\"none\")\n",
    "\n",
    "    milp_verifier = MILPVerifier(nn, test_image, 1)\n",
    "    snv_verifier = SingleNeuronVerifier(nn, test_image, 1)\n",
    "    dhov_verifier = DHOVVerifier(icnns, nn, test_image, 1)\n",
    "    dhov_affine_verifier = DHOVVerifier(icnns, nn, test_image, 1, with_affine=True)\n",
    "\n",
    "    milp_verifier.generate_constraints_for_net()\n",
    "    snv_verifier.generate_constraints_for_net()\n",
    "    dhov_verifier.generate_constraints_for_net()\n",
    "    dhov_affine_verifier.generate_constraints_for_net()\n",
    "\n",
    "    input_flattened = torch.flatten(test_image)\n",
    "    input_size = input_flattened.size(0)\n",
    "    bounds = nn.calculate_box_bounds([input_flattened.add(-1), input_flattened.add(1)], with_relu=True)\n",
    "\n",
    "    test_space = torch.empty((0, input_flattened.size(0)), dtype=data_type).to(device)\n",
    "    box_bound_output_space = ds.samples_uniform_over(test_space, 1000, bounds[-1])\n",
    "\n",
    "    in_snv = []\n",
    "    in_milp = []\n",
    "    in_dhov = []\n",
    "    in_dhov_affine = []\n",
    "    for i, sample in enumerate(box_bound_output_space):\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        in_milp.append(milp_verifier.test_feasibility(sample))\n",
    "        in_snv.append(snv_verifier.test_feasibility(sample))\n",
    "        in_dhov.append(dhov_verifier.test_feasibility(sample))\n",
    "        in_dhov_affine.append(dhov_affine_verifier.test_feasibility(sample))\n",
    "\n",
    "    plt_inc_amb(\"milp\", box_bound_output_space.detach().numpy(), in_milp)\n",
    "    plt_inc_amb(\"snv\", box_bound_output_space.detach().numpy(), in_snv)\n",
    "    plt_inc_amb(\"dhov\", box_bound_output_space.detach().numpy(), in_dhov)\n",
    "    plt_inc_amb(\"dhov with affine\", box_bound_output_space.detach().numpy(), in_dhov_affine)\n",
    "\n",
    "    \"\"\"A_snv, b_snv = to_A_b(snv_model)\n",
    "    A_icnn, b_icnn = to_A_b(icnn_model)\n",
    "\n",
    "    snv_polytope = pc.Polytope(A_snv, b_snv)\n",
    "    icnn_polytope = pc.Polytope(A_icnn, b_icnn)\n",
    "\n",
    "    snv_convex = pc.is_convex(pc.Region([snv_polytope]))\n",
    "    icnn_convex = pc.is_convex(pc.Region([icnn_polytope]))\n",
    "\n",
    "    snv_volume = pc.volume(pc.Region([snv_polytope]))\n",
    "    icnn_volume = pc.volume(pc.Region([icnn_polytope]))\n",
    "    snv_extreme = pc.extreme(snv_polytope)\n",
    "    icnn_extreme = pc.extreme(icnn_polytope)\n",
    "\n",
    "    print(snv_polytope)\n",
    "    print(icnn_volume)\"\"\"\n",
    "\n",
    "\n",
    "def to_A_b(model):\n",
    "    #print(model.display())\n",
    "    matrix_a = model.getA().toarray()\n",
    "    constr = model.getConstrs()\n",
    "    con_by_name = model.getConstrByName(\"lb_const0[0]\")\n",
    "\n",
    "    lhs = []\n",
    "    rhs = []\n",
    "    #print(\"==============================\")\n",
    "    for i, elem in enumerate(constr):\n",
    "        #print(elem.ConstrName)\n",
    "        if elem.Sense == \"<\":\n",
    "            lhs.append(matrix_a[i])\n",
    "            rhs.append(elem.RHS)\n",
    "        elif elem.Sense == \">\":\n",
    "            lhs.append(-1 * matrix_a[i])\n",
    "            rhs.append(-1 * elem.RHS)\n",
    "        elif elem.Sense == \"=\":\n",
    "            lhs.append(matrix_a[i])\n",
    "            rhs.append(elem.RHS)\n",
    "            lhs.append(-1 * matrix_a[i])\n",
    "            rhs.append(-1 * elem.RHS)\n",
    "\n",
    "\n",
    "    lhs = np.array(lhs)\n",
    "    rhs = np.array(rhs)\n",
    "    lhs[-0 == lhs] = 0\n",
    "    rhs[-0 == rhs] = 0\n",
    "    return lhs, rhs\n",
    "\n",
    "def plt_inc_amb(caption, points, is_true):\n",
    "    true_points = []\n",
    "    false_points = []\n",
    "    for i in range(len(points)):\n",
    "        if is_true[i]:\n",
    "            true_points.append(points[i])\n",
    "        else:\n",
    "            false_points.append(points[i])\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.scatter(list(map(lambda x: x[0], false_points)), list(map(lambda x: x[1], false_points)), c=\"#ff7f0e\")\n",
    "    plt.scatter(list(map(lambda x: x[0], true_points)), list(map(lambda x: x[1], true_points)), c=\"#1f77b4\")\n",
    "    plt.title(caption)\n",
    "    plt.show()\n",
    "\n",
    "net_2d()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
