{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training und Verifikation mittels MILP von Netz auf CIFAR10 Datensatz\n",
    "Es sollte bereits ein trainiertes Netz existieren."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from script.NeuralNets.Networks import *\n",
    "from script.NeuralNets.trainFunction import train_sequential\n",
    "from script.Verification.Verifier import MILPVerifier\n",
    "import time\n",
    "from jupyterthemes import jtplot\n",
    "import gurobipy as grp\n",
    "\n",
    "load_model = True\n",
    "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform = Compose([ToTensor(),\n",
    "                     Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "                    )\n",
    "\n",
    "training_data = CIFAR10(root=\"../../cifar\",\n",
    "                        train=True,\n",
    "                        download=True,\n",
    "                        transform=transform)\n",
    "\n",
    "test_data = CIFAR10(root=\"../../cifar\",\n",
    "                    train=False,  # test set, 10k images\n",
    "                    download=True,\n",
    "                    transform=transform)\n",
    "\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(training_data,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "test_dataloader = DataLoader(test_data,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True)\n",
    "\n",
    "classes = training_data.classes\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + .05  # revert normalization for viewing\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(32 * 32 * 3, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 10)\n",
    ")\n",
    "model.load_state_dict(torch.load(\"../cifar_fc.pth\", map_location=torch.device('cpu')), strict=False)\n",
    "\"\"\"\n",
    "\n",
    "model = SequentialNN([32 * 32 * 3, 1024, 512, 10])\n",
    "\n",
    "if load_model:\n",
    "    model.load_state_dict(torch.load(\"../../cifar_fc.pth\", map_location=torch.device('cpu')), strict=False)\n",
    "else:\n",
    "    train_sequential(model, train_dataloader, test_dataloader, epochs=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images, labels = training_data.__getitem__(0)\n",
    "testimage, testlabel = torch.unsqueeze(images, 0).to(torch.float64), torch.unsqueeze(torch.tensor(labels), 0).to(torch.float64)\n",
    "imshow(images)\n",
    "print(\"label is {} with index {}\".format(classes[labels], labels))\n",
    "pred = model(testimage)\n",
    "\n",
    "print(\"prediction is {} with output {} \".format(classes[pred.argmax()], pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_relu_constr(model, input_vars, number_of_out_features, lb, ub, i=0):\n",
    "    a = model.addMVar(number_of_out_features, vtype=grp.GRB.BINARY, name=\"a\" + str(i))\n",
    "    relu_vars = model.addMVar(number_of_out_features, lb=lb, name=\"relu_var\" + str(i))\n",
    "    model.update()\n",
    "    relu_const_0 = model.addConstrs((var >= 0) for var in relu_vars.tolist())\n",
    "    relu_const_1 = model.addConstrs((var >= x) for var, x in zip(relu_vars.tolist(), input_vars.tolist()))\n",
    "    # relu_const_if1 = model.addConstrs((var <= a_i * ub) for var, a_i in zip(relu_vars.tolist(), a.tolist()))\n",
    "    relu_const_if1 = model.addConstrs(\n",
    "        (relu_vars.tolist()[k] <= a.tolist()[k] * ub[k]) for k in range(number_of_out_features))\n",
    "    # relu_const_if0 = model.addConstrs((var <= x - lb * (1 - a_i)) for var, x, a_i in zip(relu_vars.tolist(), input_vars.tolist(), a.tolist()))\n",
    "    relu_const_if0 = model.addConstrs(\n",
    "        (relu_vars.tolist()[k] <= input_vars.tolist()[k] - lb[k] * (1 - a.tolist()[k])) for k in\n",
    "        range(number_of_out_features))\n",
    "    return relu_vars"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_constr_for_sequential_icnn(model, predictor, input_vars, output_vars, bounds):\n",
    "    parameter_list = list(predictor.parameters())\n",
    "\n",
    "    in_var = input_vars\n",
    "    for i in range(0, len(parameter_list), 2):\n",
    "        lb = bounds[int(i / 2)][0]\n",
    "        ub = bounds[int(i / 2)][1]\n",
    "        W, b = parameter_list[i].detach().numpy(), parameter_list[i + 1].detach().numpy()\n",
    "\n",
    "        out_fet = len(b)\n",
    "        out_vars = model.addMVar(out_fet, lb=lb, ub=ub, name=\"affine_var\" + str(i))\n",
    "        const = model.addConstrs((W[i] @ in_var + b[i] == out_vars[i] for i in range(len(W))))\n",
    "        in_var = out_vars\n",
    "\n",
    "        if i < len(parameter_list) - 2:\n",
    "            # relu_vars = add_relu_constr(model, in_var, out_fet, [-10000 for i in range(len(W))], [10000 for i in range(len(W))], i)\n",
    "            relu_vars = add_relu_constr(model, in_var, out_fet, lb, ub, i)\n",
    "            # relu_vars = add_relu_constr(model, in_var, out_fet, lb, ub, i)\n",
    "            in_var = relu_vars\n",
    "            out_vars = relu_vars\n",
    "\n",
    "    const = model.addConstrs(out_vars[i] == output_vars[i] for i in range(out_fet))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_box_bounds(nn, input_bounds, is_sequential=True, with_ReLU=True):\n",
    "    parameter_list = list(nn.parameters())\n",
    "    # todo for now this only works for sequential nets\n",
    "\n",
    "    if input_bounds is None:\n",
    "        bounds_per_layer = [([torch.tensor([-5000 for k in range(len(parameter_list[i]))]),\n",
    "                              torch.tensor([5000 for k in range(len(parameter_list[i]))])]) for i in\n",
    "                            range(0, len(parameter_list), 2)]\n",
    "        return bounds_per_layer  # todo None entfernen aus aufrufen und durch sinnvolle eingabe ersetzen\n",
    "\n",
    "    next_lower_bounds = input_bounds[0]\n",
    "    next_upper_bounds = input_bounds[1]\n",
    "    bounds_per_layer = []\n",
    "    for i in range(0, len(parameter_list), 2):\n",
    "        W, b = parameter_list[i], parameter_list[i + 1]\n",
    "        W_plus = torch.maximum(W, torch.tensor(0, dtype=torch.float64))\n",
    "        W_minus = torch.minimum(W, torch.tensor(0, dtype=torch.float64))\n",
    "        lb = torch.matmul(W_plus, next_lower_bounds).add(torch.matmul(W_minus, next_upper_bounds)).add(b)\n",
    "        ub = torch.matmul(W_plus, next_upper_bounds).add(torch.matmul(W_minus, next_lower_bounds)).add(b)\n",
    "        if not is_sequential and i != 0:\n",
    "            U = nn.us[i / 2 - 1]\n",
    "            U_plus = torch.maximum(U, torch.tensor(0, dtype=torch.float64))\n",
    "            U_minus = torch.minimum(U, torch.tensor(0, dtype=torch.float64))\n",
    "            lb = lb.add(torch.matmul(U_plus, next_lower_bounds).add(torch.matmul(U_minus, next_upper_bounds)))\n",
    "            ub = ub.add(torch.matmul(U_plus, next_upper_bounds).add(torch.matmul(U_minus, next_lower_bounds)))\n",
    "        if with_ReLU:\n",
    "            next_upper_bounds = torch.maximum(torch.tensor(0, dtype=torch.float64), ub)\n",
    "            next_lower_bounds = torch.maximum(torch.tensor(0, dtype=torch.float64), lb)\n",
    "        else:\n",
    "            next_upper_bounds = ub\n",
    "            next_lower_bounds = lb\n",
    "\n",
    "        bounds_per_layer.append([next_lower_bounds, next_upper_bounds])\n",
    "\n",
    "    return bounds_per_layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sequential(predictor, input, output_size, label, eps=0.01, time_limit=None, bound=None):\n",
    "    m = grp.Model()\n",
    "    input_flattened = torch.flatten(input)\n",
    "    input_size = input_flattened.size(0)\n",
    "    bounds = calculate_box_bounds(predictor, [input_flattened.add(-eps), input_flattened.add(eps)], with_ReLU=False)\n",
    "\n",
    "    bounds = [[elem[0].detach().tolist(), elem[1].detach().tolist()] for elem in bounds]\n",
    "\n",
    "    input_flattened = input_flattened.numpy()\n",
    "\n",
    "    if time_limit is not None:\n",
    "        m.setParam(\"TimeLimit\", time_limit)\n",
    "\n",
    "    if bound is not None:\n",
    "        m.setParam(\"BestObjStop\", bound)\n",
    "\n",
    "    input_var = m.addMVar(input_size, lb=[elem - eps for elem in input_flattened], ub=[elem + eps for elem in input_flattened], name=\"in_var\")\n",
    "    output_var = m.addMVar(output_size, lb=bounds[-1][0], ub=bounds[-1][1], name=\"output_var\")\n",
    "\n",
    "    m.addConstrs(input_var[i] <= input_flattened[i] + eps for i in range(input_size))\n",
    "    m.addConstrs(input_var[i] >= input_flattened[i] - eps for i in range(input_size))\n",
    "\n",
    "    add_constr_for_sequential_icnn(m, predictor,  input_var, output_var, bounds)\n",
    "\n",
    "    lower_diff_bound = [lb - bounds[-1][1][label] for lb in bounds[-1][0]]\n",
    "    upper_diff_bound = [ub - bounds[-1][0][label] for ub in bounds[-1][1]]\n",
    "\n",
    "    lower_diff_bound.pop(label)\n",
    "    upper_diff_bound.pop(label)\n",
    "\n",
    "    difference = m.addVars(output_size - 1, lb=lower_diff_bound, ub=upper_diff_bound)\n",
    "    m.addConstrs(difference[i] == output_var.tolist()[i] - output_var.tolist()[label] for i in range(0, label))\n",
    "    m.addConstrs(\n",
    "        difference[i - 1] == output_var.tolist()[i] - output_var.tolist()[label] for i in range(label + 1, output_size))\n",
    "\n",
    "    max_var = m.addVar(lb=-float(\"inf\"))\n",
    "    m.addConstr(max_var == grp.max_(difference))\n",
    "\n",
    "    m.update()\n",
    "    m.setObjective(max_var, grp.GRB.MAXIMIZE)\n",
    "    m.optimize()\n",
    "\n",
    "    if m.Status == grp.GRB.OPTIMAL or m.Status == grp.GRB.TIME_LIMIT or m.Status == grp.GRB.USER_OBJ_LIMIT:\n",
    "        inp = input_var.getAttr(\"x\")\n",
    "        for o in difference.select():\n",
    "            print(o.getAttr(\"x\"))\n",
    "        print(\"optimum solution with value \\n {}\".format(output_var.getAttr(\"x\")))\n",
    "        print(\"max_var {}\".format(max_var.getAttr(\"x\")))\n",
    "        test_inp = torch.tensor([inp], dtype=torch.float64)\n",
    "        return test_inp, output_var"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_size = len(classes)\n",
    "alt_pic, alt_out = sequential(model, testimage, 10, labels, eps=0.1, bound=0+0.001)\n",
    "print(\"=================\")\n",
    "print(\"\")\n",
    "print(alt_pic)\n",
    "out = model(alt_pic)\n",
    "print(\"prediction is {} with output {} \".format(classes[out.argmax()], out))\n",
    "\n",
    "reshaped = np.reshape(alt_pic, (3, 32, 32))\n",
    "imshow(reshaped)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"print(\"=================\")\n",
    "start = time.time()\n",
    "output_size = len(classes)\n",
    "alt_pic, alt_out = milp.sequential(model, images, labels, eps=0.1, bound=0+0.001)\n",
    "end = time.time() - start\n",
    "print(\"=================\")\n",
    "print(\"\")\n",
    "print(\"time to solve {} s.\".format(end))\n",
    "print(alt_pic)\n",
    "out = model(alt_pic)\n",
    "print(\"prediction is {} with output {} \".format(classes[out.argmax()], out))\n",
    "\n",
    "reshaped = np.reshape(alt_pic, (3, 32, 32))\n",
    "imshow(reshaped)\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "milp_verifier = MILPVerifier(model, testimage, 1, solver_bound=-1, print_log=True)\n",
    "milp_verifier.generate_constraints_for_net()\n",
    "m = milp_verifier.model\n",
    "out_var = milp_verifier.output_vars\n",
    "in_var = milp_verifier.input_vars\n",
    "\n",
    "m.setObjective(out_var[0], grp.GRB.MAXIMIZE)\n",
    "m.update()\n",
    "m.optimize()\n",
    "\n",
    "if m.Status == grp.GRB.OPTIMAL or m.Status == grp.GRB.USER_OBJ_LIMIT:\n",
    "    alt_img = torch.tensor(in_var.getAttr(\"x\"), dtype=torch.float64)\n",
    "    output = out_var.getAttr(\"x\")\n",
    "    print(\"output: {}\".format(output))\n",
    "    reshaped = np.reshape(alt_img, (3, 32, 32))\n",
    "    imshow(reshaped)\n",
    "    out_pred = model(alt_img)\n",
    "    print(\"prediction is: {}\".format(out_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def add_constr_for_sequential_icnn(model, predictor, input_vars, output_vars, bounds):\n",
    "    parameter_list = list(predictor.parameters())\n",
    "\n",
    "    in_var = input_vars\n",
    "    for i in range(0, len(parameter_list), 2):\n",
    "        lb = bounds[int(i / 2)][0]\n",
    "        ub = bounds[int(i / 2)][1]\n",
    "        W, b = parameter_list[i].detach().numpy(), parameter_list[i + 1].detach().numpy()\n",
    "\n",
    "        out_fet = len(b)\n",
    "        out_vars = model.addMVar(out_fet, lb=lb, ub=ub, name=\"affine_var\" + str(i))\n",
    "        const = model.addConstrs((W[i] @ in_var + b[i] == out_vars[i] for i in range(len(W))))\n",
    "        in_var = out_vars\n",
    "\n",
    "        if i < len(parameter_list) - 2:\n",
    "            # relu_vars = add_relu_constr(model, in_var, out_fet, [-10000 for i in range(len(W))], [10000 for i in range(len(W))], i)\n",
    "            relu_vars = add_relu_constr(model, in_var, out_fet, lb, ub, i)\n",
    "            # relu_vars = add_relu_constr(model, in_var, out_fet, lb, ub, i)\n",
    "            in_var = relu_vars\n",
    "            out_vars = relu_vars\n",
    "\n",
    "    const = model.addConstrs(out_vars[i] == output_vars[i] for i in range(out_fet))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def calculate_box_bounds(nn, input_bounds, is_sequential=True, with_ReLU=True):\n",
    "    parameter_list = list(nn.parameters())\n",
    "    # todo for now this only works for sequential nets\n",
    "\n",
    "    if input_bounds is None:\n",
    "        bounds_per_layer = [([torch.tensor([-5000 for k in range(len(parameter_list[i]))]),\n",
    "                              torch.tensor([5000 for k in range(len(parameter_list[i]))])]) for i in\n",
    "                            range(0, len(parameter_list), 2)]\n",
    "        return bounds_per_layer  # todo None entfernen aus aufrufen und durch sinnvolle eingabe ersetzen\n",
    "\n",
    "    next_lower_bounds = input_bounds[0]\n",
    "    next_upper_bounds = input_bounds[1]\n",
    "    bounds_per_layer = []\n",
    "    for i in range(0, len(parameter_list), 2):\n",
    "        W, b = parameter_list[i], parameter_list[i + 1]\n",
    "        W_plus = torch.maximum(W, torch.tensor(0, dtype=torch.float64))\n",
    "        W_minus = torch.minimum(W, torch.tensor(0, dtype=torch.float64))\n",
    "        lb = torch.matmul(W_plus, next_lower_bounds).add(torch.matmul(W_minus, next_upper_bounds)).add(b)\n",
    "        ub = torch.matmul(W_plus, next_upper_bounds).add(torch.matmul(W_minus, next_lower_bounds)).add(b)\n",
    "        if not is_sequential and i != 0:\n",
    "            U = nn.us[i / 2 - 1]\n",
    "            U_plus = torch.maximum(U, torch.tensor(0, dtype=torch.float64))\n",
    "            U_minus = torch.minimum(U, torch.tensor(0, dtype=torch.float64))\n",
    "            lb = lb.add(torch.matmul(U_plus, next_lower_bounds).add(torch.matmul(U_minus, next_upper_bounds)))\n",
    "            ub = ub.add(torch.matmul(U_plus, next_upper_bounds).add(torch.matmul(U_minus, next_lower_bounds)))\n",
    "        if with_ReLU:\n",
    "            next_upper_bounds = torch.maximum(torch.tensor(0, dtype=torch.float64), ub)\n",
    "            next_lower_bounds = torch.maximum(torch.tensor(0, dtype=torch.float64), lb)\n",
    "        else:\n",
    "            next_upper_bounds = ub\n",
    "            next_lower_bounds = lb\n",
    "\n",
    "        bounds_per_layer.append([next_lower_bounds, next_upper_bounds])\n",
    "\n",
    "    return bounds_per_layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def sequential(predictor, input, output_size, label, eps=0.01, time_limit=None, bound=None):\n",
    "    m = grp.Model()\n",
    "    input_flattened = torch.flatten(input)\n",
    "    input_size = input_flattened.size(0)\n",
    "    bounds = calculate_box_bounds(predictor, [input_flattened.add(-eps), input_flattened.add(eps)], with_ReLU=False)\n",
    "\n",
    "    bounds = [[elem[0].detach().tolist(), elem[1].detach().tolist()] for elem in bounds]\n",
    "\n",
    "    input_flattened = input_flattened.numpy()\n",
    "\n",
    "    if time_limit is not None:\n",
    "        m.setParam(\"TimeLimit\", time_limit)\n",
    "\n",
    "    if bound is not None:\n",
    "        m.setParam(\"BestObjStop\", bound)\n",
    "\n",
    "    input_var = m.addMVar(input_size, lb=[elem - eps for elem in input_flattened], ub=[elem + eps for elem in input_flattened], name=\"in_var\")\n",
    "    output_var = m.addMVar(output_size, lb=bounds[-1][0], ub=bounds[-1][1], name=\"output_var\")\n",
    "\n",
    "    m.addConstrs(input_var[i] <= input_flattened[i] + eps for i in range(input_size))\n",
    "    m.addConstrs(input_var[i] >= input_flattened[i] - eps for i in range(input_size))\n",
    "\n",
    "    add_constr_for_sequential_icnn(m, predictor,  input_var, output_var, bounds)\n",
    "\n",
    "    lower_diff_bound = [lb - bounds[-1][1][label] for lb in bounds[-1][0]]\n",
    "    upper_diff_bound = [ub - bounds[-1][0][label] for ub in bounds[-1][1]]\n",
    "\n",
    "    lower_diff_bound.pop(label)\n",
    "    upper_diff_bound.pop(label)\n",
    "\n",
    "    difference = m.addVars(output_size - 1, lb=lower_diff_bound, ub=upper_diff_bound)\n",
    "    m.addConstrs(difference[i] == output_var.tolist()[i] - output_var.tolist()[label] for i in range(0, label))\n",
    "    m.addConstrs(\n",
    "        difference[i - 1] == output_var.tolist()[i] - output_var.tolist()[label] for i in range(label + 1, output_size))\n",
    "\n",
    "    max_var = m.addVar(lb=-float(\"inf\"))\n",
    "    m.addConstr(max_var == grp.max_(difference))\n",
    "\n",
    "    m.update()\n",
    "    m.setObjective(max_var, grp.GRB.MAXIMIZE)\n",
    "    m.optimize()\n",
    "\n",
    "    if m.Status == grp.GRB.OPTIMAL or m.Status == grp.GRB.TIME_LIMIT or m.Status == grp.GRB.USER_OBJ_LIMIT:\n",
    "        inp = input_var.getAttr(\"x\")\n",
    "        for o in difference.select():\n",
    "            print(o.getAttr(\"x\"))\n",
    "        print(\"optimum solution with value \\n {}\".format(output_var.getAttr(\"x\")))\n",
    "        print(\"max_var {}\".format(max_var.getAttr(\"x\")))\n",
    "        test_inp = torch.tensor([inp], dtype=torch.float64)\n",
    "        return test_inp, output_var"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-11-12\n",
      "Set parameter BestObjStop to value 0.001\n",
      "Gurobi Optimizer version 10.0.0 build v10.0.0rc2 (win64)\n",
      "\n",
      "CPU model: AMD Ryzen 7 5800H with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Optimize a model with 13853 rows, 7710 columns and 3695161 nonzeros\n",
      "Model fingerprint: 0x09ffdde3\n",
      "Model has 1 general constraint\n",
      "Variable types: 6174 continuous, 1536 integer (1536 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [9e-11, 6e+01]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [2e-03, 3e+03]\n",
      "  RHS range        [3e-05, 6e+01]\n",
      "Presolve removed 7712 rows and 31 columns (presolve time = 5s) ...\n",
      "Presolve removed 7684 rows and 4 columns\n",
      "Presolve time: 5.45s\n",
      "Presolved: 6169 rows, 7706 columns, 3683818 nonzeros\n",
      "Variable types: 6162 continuous, 1544 integer (1544 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    3.4221425e+03   7.354863e+03   0.000000e+00      7s\n",
      "    3332    2.9772583e+03   3.099833e+02   0.000000e+00     10s\n",
      "    4807    2.9768667e+03   0.000000e+00   0.000000e+00     15s\n",
      "\n",
      "Root relaxation: objective 2.976867e+03, 4807 iterations, 8.91 seconds (18.68 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2976.86674    0  879          - 2976.86674      -     -   18s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32m~\\miniconda3\\envs\\torchCPU\\lib\\site-packages\\ipykernel\\iostream.py:526\u001B[0m, in \u001B[0;36mOutStream.write\u001B[1;34m(self, string)\u001B[0m\n\u001B[0;32m    517\u001B[0m         content \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m: data}\n\u001B[0;32m    518\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession\u001B[38;5;241m.\u001B[39msend(\n\u001B[0;32m    519\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpub_thread,\n\u001B[0;32m    520\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    523\u001B[0m             ident\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtopic,\n\u001B[0;32m    524\u001B[0m         )\n\u001B[1;32m--> 526\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrite\u001B[39m(\u001B[38;5;28mself\u001B[39m, string: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[\u001B[38;5;28mint\u001B[39m]:  \u001B[38;5;66;03m# type:ignore[override]\u001B[39;00m\n\u001B[0;32m    527\u001B[0m     \u001B[38;5;124;03m\"\"\"Write to current stream after encoding if necessary\u001B[39;00m\n\u001B[0;32m    528\u001B[0m \n\u001B[0;32m    529\u001B[0m \u001B[38;5;124;03m    Returns\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    533\u001B[0m \n\u001B[0;32m    534\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m    536\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(string, \u001B[38;5;28mstr\u001B[39m):\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gurobipy.logcallbackstub'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ufuk\\miniconda3\\envs\\torchCPU\\lib\\site-packages\\ipykernel\\iostream.py\", line 526, in write\n",
      "    def write(self, string: str) -> Optional[int]:  # type:ignore[override]\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0     0 1264.93083    0  969          - 1264.93083      -     -   70s\n"
     ]
    }
   ],
   "source": [
    "output_size = len(classes)\n",
    "alt_pic, alt_out = sequential(model, testimage, 10, labels, eps=0.1, bound=0+0.001)\n",
    "print(\"=================\")\n",
    "print(\"\")\n",
    "print(alt_pic)\n",
    "out = model(alt_pic)\n",
    "print(\"prediction is {} with output {} \".format(classes[out.argmax()], out))\n",
    "\n",
    "reshaped = np.reshape(alt_pic, (3, 32, 32))\n",
    "imshow(reshaped)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'print(\"=================\")\\nstart = time.time()\\noutput_size = len(classes)\\nalt_pic, alt_out = milp.sequential(model, images, labels, eps=0.1, bound=0+0.001)\\nend = time.time() - start\\nprint(\"=================\")\\nprint(\"\")\\nprint(\"time to solve {} s.\".format(end))\\nprint(alt_pic)\\nout = model(alt_pic)\\nprint(\"prediction is {} with output {} \".format(classes[out.argmax()], out))\\n\\nreshaped = np.reshape(alt_pic, (3, 32, 32))\\nimshow(reshaped)'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(\"=================\")\n",
    "start = time.time()\n",
    "output_size = len(classes)\n",
    "alt_pic, alt_out = milp.sequential(model, images, labels, eps=0.1, bound=0+0.001)\n",
    "end = time.time() - start\n",
    "print(\"=================\")\n",
    "print(\"\")\n",
    "print(\"time to solve {} s.\".format(end))\n",
    "print(alt_pic)\n",
    "out = model(alt_pic)\n",
    "print(\"prediction is {} with output {} \".format(classes[out.argmax()], out))\n",
    "\n",
    "reshaped = np.reshape(alt_pic, (3, 32, 32))\n",
    "imshow(reshaped)\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 10\n",
      "Set parameter BestObjStop to value -10\n",
      "Gurobi Optimizer version 10.0.0 build v10.0.0rc2 (win64)\n",
      "\n",
      "CPU model: AMD Ryzen 7 5800H with Radeon Graphics, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "\n",
      "Optimize a model with 13834 rows, 7690 columns and 3693578 nonzeros\n",
      "Model fingerprint: 0x35407d85\n",
      "Variable types: 6154 continuous, 1536 integer (1536 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [9e-11, 3e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [2e-02, 5e+03]\n",
      "  RHS range        [3e-05, 2e+00]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Presolve removed 12298 rows and 3082 columns\n",
      "Presolve time: 2.20s\n",
      "Presolved: 1536 rows, 4608 columns, 3671545 nonzeros\n",
      "Variable types: 4608 continuous, 0 integer (0 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    1074    3.1035279e+02   1.687757e+04   0.000000e+00      5s\n",
      "\n",
      "Root relaxation: time limit, 1976 iterations, 7.13 seconds (13.68 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0          -    0               - 4201.76398      -     -   10s\n",
      "\n",
      "Explored 1 nodes (1976 simplex iterations) in 10.03 seconds (16.99 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 0\n",
      "\n",
      "Time limit reached\n",
      "Best objective -, best bound 4.201763982489e+03, gap -\n"
     ]
    },
    {
     "ename": "GurobiError",
     "evalue": "Unable to retrieve attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mGurobiError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m m\u001B[38;5;241m.\u001B[39moptimize()\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m m\u001B[38;5;241m.\u001B[39mStatus \u001B[38;5;241m==\u001B[39m grp\u001B[38;5;241m.\u001B[39mGRB\u001B[38;5;241m.\u001B[39mOPTIMAL \u001B[38;5;129;01mor\u001B[39;00m m\u001B[38;5;241m.\u001B[39mStatus \u001B[38;5;241m==\u001B[39m grp\u001B[38;5;241m.\u001B[39mGRB\u001B[38;5;241m.\u001B[39mUSER_OBJ_LIMIT \u001B[38;5;129;01mor\u001B[39;00m m\u001B[38;5;241m.\u001B[39mStatus \u001B[38;5;241m==\u001B[39m grp\u001B[38;5;241m.\u001B[39mGRB\u001B[38;5;241m.\u001B[39mTIME_LIMIT:\n\u001B[1;32m---> 12\u001B[0m     alt_img \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[43min_var\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetAttr\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[0;32m     13\u001B[0m     output \u001B[38;5;241m=\u001B[39m out_var\u001B[38;5;241m.\u001B[39mgetAttr(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(output))\n",
      "File \u001B[1;32msrc\\gurobipy\\mvar.pxi:552\u001B[0m, in \u001B[0;36mgurobipy.MVar.getAttr\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32msrc\\gurobipy\\attrutil.pxi:148\u001B[0m, in \u001B[0;36mgurobipy.__gettypedattrlist\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mGurobiError\u001B[0m: Unable to retrieve attribute 'x'"
     ]
    }
   ],
   "source": [
    "milp_verifier = MILPVerifier(model, testimage, 1, solver_bound=-1, print_log=True)\n",
    "milp_verifier.generate_constraints_for_net()\n",
    "m = milp_verifier.model\n",
    "out_var = milp_verifier.output_vars\n",
    "in_var = milp_verifier.input_vars\n",
    "\n",
    "m.setObjective(out_var[0], grp.GRB.MAXIMIZE)\n",
    "m.update()\n",
    "m.optimize()\n",
    "\n",
    "if m.Status == grp.GRB.OPTIMAL or m.Status == grp.GRB.USER_OBJ_LIMIT:\n",
    "    alt_img = torch.tensor(in_var.getAttr(\"x\"), dtype=torch.float64)\n",
    "    output = out_var.getAttr(\"x\")\n",
    "    print(\"output: {}\".format(output))\n",
    "    reshaped = np.reshape(alt_img, (3, 32, 32))\n",
    "    imshow(reshaped)\n",
    "    out_pred = model(alt_img)\n",
    "    print(\"prediction is: {}\".format(out_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}