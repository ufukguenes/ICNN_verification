{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:05:23.149319183Z",
     "start_time": "2024-04-21T18:05:22.302040428Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from script.NeuralNets.Networks import SequentialNN\n",
    "from script.settings import device, data_type\n",
    "import script.DHOV.MultiDHOV as multidhov\n",
    "from script.Verification.Verifier import SingleNeuronVerifier, MILPVerifier\n",
    "import gurobipy as grp\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from script.NeuralNets.ICNNFactory import ICNNFactory\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from script.DHOV.Sampling.PerGroupLineSearchSampling import PerGroupLineSearchSamplingStrategy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx2pytorch import ConvertModel\n",
    "from auto_LiRPA import BoundedModule, BoundedTensor, PerturbationLpNorm\n",
    "\n",
    "from vnnlib.compat import read_vnnlib_simple\n",
    "from collections import OrderedDict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:05:23.377897588Z",
     "start_time": "2024-04-21T18:05:23.149485894Z"
    }
   },
   "id": "c4a3e68fb6c5c5e1",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ufuk/miniconda3/envs/autolirpa_icnn/lib/python3.10/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n"
     ]
    },
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model = onnx.load(\"../Experiments/mnist-net_256x4.onnx\")\n",
    "pytorch_model = ConvertModel(onnx_model)\n",
    "\n",
    "nn = SequentialNN([28 * 28 * 1, 256, 256, 256, 256, 10])\n",
    "state_dict = pytorch_model.state_dict()\n",
    "my_state_dict = {}\n",
    "for i, key in enumerate(state_dict):\n",
    "    actual_index = i * 2\n",
    "    my_state_dict[f\"{actual_index}.bias\"] = state_dict[f\"_initializer_layers_{actual_index}_bias\"]\n",
    "    my_state_dict[f\"{actual_index}.weight\"] = state_dict[f\"_initializer_layers_{actual_index}_weight\"]\n",
    "    if actual_index == 8:\n",
    "        break\n",
    "    \n",
    "nn.load_state_dict(my_state_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:05:23.651033371Z",
     "start_time": "2024-04-21T18:05:23.630285966Z"
    }
   },
   "id": "36d4eeb205ae0e44",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "SequentialNN(\n  (0): Linear(in_features=784, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=256, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=256, out_features=256, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): Linear(in_features=256, out_features=10, bias=True)\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:05:24.474170979Z",
     "start_time": "2024-04-21T18:05:24.471799801Z"
    }
   },
   "id": "6fc336065b0584ac",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + .05  # revert normalization for viewing\n",
    "    npimg = img.to(\"cpu\").numpy()\n",
    "    plt.imshow(npimg, cmap=\"gray\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:05:25.195555223Z",
     "start_time": "2024-04-21T18:05:25.193521467Z"
    }
   },
   "id": "f39dc795be182c84",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transform = Compose([ToTensor()])\n",
    "training_data = MNIST(root=\"../../mnist\", train=True, download=True, transform=transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:05:25.487821461Z",
     "start_time": "2024-04-21T18:05:25.455886442Z"
    }
   },
   "id": "d385d0ee6ce97d69",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label is 3\n",
      "NN classifies image correctly as 3\n"
     ]
    }
   ],
   "source": [
    "image_index = 10\n",
    "\n",
    "# epsilon radius\n",
    "eps = 0.1\n",
    "\n",
    "# whether a verification attempt should be done using just MILP encoding for comparison (can take long)\n",
    "use_milp = False\n",
    "\n",
    "image, label = training_data[image_index]\n",
    "torch_image = torch.unsqueeze(image, 0).to(dtype=data_type).to(device)\n",
    "imshow(torch_image[0][0])\n",
    "print(f\"The label is {label}\")\n",
    "if torch.argmax(nn(torch_image)).item() == label:\n",
    "    print(\"NN classifies image correctly as {}\".format(label))\n",
    "else:\n",
    "    print(\"NN classifies image wrong\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:05:31.702326408Z",
     "start_time": "2024-04-21T18:05:31.660267690Z"
    }
   },
   "id": "28b1a784b3dbec3c",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "center = torch.flatten(torch_image)\n",
    "input_bounds = [center - eps, center + eps]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:06:30.128406471Z",
     "start_time": "2024-04-21T18:06:30.084541304Z"
    }
   },
   "id": "13f8720ff6dad3f1",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sampling_strategy = PerGroupLineSearchSamplingStrategy(center, input_bounds, nn, keep_ambient_space=True, sample_new=False, sample_count=1000)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:06:36.203103340Z",
     "start_time": "2024-04-21T18:06:36.200849515Z"
    }
   },
   "id": "270f22ebd5ed0107",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bounds_affine_out, bounds_layer_out = nn.calculate_box_bounds(input_bounds)\n",
    "current_layer_index = 0\n",
    "group_size = 20\n",
    "parameter_list = list(nn.parameters())\n",
    "affine_w, affine_b = parameter_list[0], parameter_list[0 + 1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:06:52.871815645Z",
     "start_time": "2024-04-21T18:06:52.819370796Z"
    }
   },
   "id": "c01bc495d78ddddb",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    number of fixed neurons for current layer: 66\n"
     ]
    }
   ],
   "source": [
    "number_of_fixed_neurons = 0\n",
    "fixed_neuron_per_layer_lower = []\n",
    "fixed_neuron_per_layer_upper = []\n",
    "num_fixed_neurons_layer = []\n",
    "fix_upper = []\n",
    "fix_lower = []\n",
    "for neuron_index, (lb, ub) in enumerate(\n",
    "        zip(bounds_affine_out[current_layer_index][0], bounds_affine_out[current_layer_index][1])):\n",
    "    if ub <= 0:\n",
    "        fix_upper.append(neuron_index)\n",
    "        number_of_fixed_neurons += 1\n",
    "    elif lb >= 0:\n",
    "        fix_lower.append(neuron_index)\n",
    "        number_of_fixed_neurons += 1\n",
    "fixed_neuron_per_layer_lower.append(fix_lower)\n",
    "fixed_neuron_per_layer_upper.append(fix_upper)\n",
    "num_fixed_neurons_layer.append(len(fix_lower) + len(fix_upper))\n",
    "print(\"    number of fixed neurons for current layer: {}\".format(len(fix_lower) + len(fix_upper)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:06:53.854402040Z",
     "start_time": "2024-04-21T18:06:53.848676527Z"
    }
   },
   "id": "45068356f4f47323",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_num_of_groups(layer_size, group_size):\n",
    "    number_of_groups = layer_size / group_size\n",
    "    if number_of_groups < 0:\n",
    "        number_of_groups *= -1\n",
    "    number_of_groups = math.ceil(number_of_groups)\n",
    "    return number_of_groups"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:06:54.655369241Z",
     "start_time": "2024-04-21T18:06:54.651911064Z"
    }
   },
   "id": "ae8c7e49a41c9f93",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_current_group_indices(num_neurons, group_size, fixed_neurons_lower, fixed_neurons_upper):\n",
    "    group_indices = []\n",
    "    current_group = []\n",
    "    fixed_neuron_index = (fixed_neurons_lower + fixed_neurons_upper)\n",
    "    for index in range(num_neurons):\n",
    "        if index in fixed_neuron_index:\n",
    "            continue\n",
    "        else:\n",
    "            current_group.append(index)\n",
    "            if len(current_group) == group_size:\n",
    "                group_indices.append(current_group)\n",
    "                current_group = []\n",
    "\n",
    "    if len(current_group) > 0:\n",
    "        group_indices.append(current_group)\n",
    "    return group_indices"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:06:55.219850681Z",
     "start_time": "2024-04-21T18:06:55.216032052Z"
    }
   },
   "id": "dbe712933b204004",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "all_group_indices = []\n",
    "\n",
    "number_of_groups = get_num_of_groups(len(affine_b) - num_fixed_neurons_layer[current_layer_index],\n",
    "                                     group_size)\n",
    "group_indices = get_current_group_indices(len(affine_b), group_size,fixed_neuron_per_layer_lower[current_layer_index],fixed_neuron_per_layer_upper[current_layer_index])\n",
    "\n",
    "all_group_indices.append(group_indices)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:06:56.570001871Z",
     "start_time": "2024-04-21T18:06:56.566634793Z"
    }
   },
   "id": "4d056b32a8bc5ef4",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "group_i = 0\n",
    "list_of_icnns = []\n",
    "net_size = [5, 1]\n",
    "icnn_batch_size=10000\n",
    "icnn_factory = ICNNFactory(\"logical\", net_size, always_use_logical_layer=False)\n",
    "\n",
    "list_of_icnns.append([])\n",
    "index_to_select = torch.tensor(group_indices[group_i]).to(device)\n",
    "size_of_icnn_input = len(index_to_select)\n",
    "current_icnn = icnn_factory.get_new_icnn(size_of_icnn_input)\n",
    "list_of_icnns[current_layer_index].append(current_icnn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:06:57.280382194Z",
     "start_time": "2024-04-21T18:06:57.276551535Z"
    }
   },
   "id": "34bfd4c371014897",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "included_space, ambient_space = sampling_strategy.sampling_by_round(affine_w, affine_b, all_group_indices, None, current_layer_index, bounds_affine_out, bounds_layer_out, list_of_icnns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:06:57.595229359Z",
     "start_time": "2024-04-21T18:06:57.558175497Z"
    }
   },
   "id": "1edcb6e9750be983",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from script.dataInit import ConvexDataset\n",
    "import script.DHOV.Normalisation as norm\n",
    "from script.NeuralNets.trainFunction import train_icnn\n",
    "\n",
    "group_inc_space = included_space[group_i]\n",
    "group_amb_space = ambient_space[group_i]\n",
    "\n",
    "\n",
    "mean = norm.get_mean(group_inc_space, group_amb_space)\n",
    "std = norm.get_std(group_inc_space, group_amb_space)\n",
    "group_norm_included_space, group_norm_ambient_space = norm.normalize_data(group_inc_space, group_amb_space, mean, std)\n",
    "\n",
    "dataset = ConvexDataset(data=group_norm_included_space)\n",
    "train_loader = DataLoader(dataset, batch_size=icnn_batch_size)\n",
    "dataset = ConvexDataset(data=group_norm_ambient_space)\n",
    "ambient_loader = DataLoader(dataset, batch_size=icnn_batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:06:59.050074471Z",
     "start_time": "2024-04-21T18:06:59.046742704Z"
    }
   },
   "id": "6e4ca0a60c9fb7b2",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(group_size)\n",
    "print(len(group_inc_space))\n",
    "print(len(group_amb_space))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:06:59.916109538Z",
     "start_time": "2024-04-21T18:06:59.913979913Z"
    }
   },
   "id": "51b099061b79be4f",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:07:13.376841165Z",
     "start_time": "2024-04-21T18:07:13.373696129Z"
    }
   },
   "id": "389c7fbf91c55763",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17528724670410156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ufuk/Documents/Programming/ICNN_verification/script/Optimizer/sdlbfgs.py:83: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)\n",
      "  p.data.add_(step_size, update[offset:offset + numel].view_as(p.data))\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "train_icnn(current_icnn, train_loader, ambient_loader, epochs=100, hyper_lambda=1,\n",
    "                                       optimizer=\"SdLBFGS\", adapt_lambda=\"included\",preemptive_stop=True, verbose=False, print_last_loss=False)\n",
    "\n",
    "print(time.time() - t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:07:13.975283993Z",
     "start_time": "2024-04-21T18:07:13.798112306Z"
    }
   },
   "id": "af5de0eb9ca47674",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3325710682.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[24], line 6\u001B[0;36m\u001B[0m\n\u001B[0;31m    10 000\u001B[0m\n\u001B[0m       ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "group_size = 20\n",
    "100\n",
    "cpu =  0.03320741653442383\n",
    "cuda = 0.03522849082946777\n",
    "\n",
    "10 000\n",
    "cpu = 2.72\n",
    "cuda = 2.65\n",
    "\n",
    "20 000\n",
    "cpu = 6.43\n",
    "cuda = 5.73\n",
    "\n",
    "50 000\n",
    "cpu = 29.34\n",
    "cuda = 21.33\n",
    "\n",
    "100 000\n",
    "cpu = 81.32830286026001\n",
    "cuda = 66.44864082336426\n",
    "\n",
    "\n",
    "group_size = 100\n",
    "\n",
    "100\n",
    "cpu = 0.04\n",
    "cuda = 0.07\n",
    "\n",
    "10 000\n",
    "cpu = 5.39\n",
    "cuda = 4.66\n",
    "\n",
    "\n",
    "group_size = 200\n",
    "cpu = 0.41\n",
    "cuda = 0.31\n",
    "\n",
    "\n",
    "group_size = 300\n",
    "\n",
    "1 000\n",
    "cpu = 0.37\n",
    "cuda = 0.30"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:07:16.923609801Z",
     "start_time": "2024-04-21T18:07:16.919657262Z"
    }
   },
   "id": "1db928677dd5d995",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test sampling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6674691829c9981e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m t \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m group \u001B[38;5;129;01min\u001B[39;00m group_indices:\n\u001B[0;32m----> 6\u001B[0m     sample_space_a \u001B[38;5;241m=\u001B[39m \u001B[43mds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample_per_group\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample_space\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mincluded_sample_count\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maffine_w\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcenter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrand_samples_percent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrand_sample_alternation_percent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(time\u001B[38;5;241m.\u001B[39mtime()\u001B[38;5;241m-\u001B[39mt)\n",
      "File \u001B[0;32m~/Documents/Programming/ICNN_verification/script/DHOV/DataSampling.py:502\u001B[0m, in \u001B[0;36msample_per_group\u001B[0;34m(data_samples, amount, affine_w, input_bounds, index_to_select, keep_samples, rand_samples_percent, rand_sample_alternation_percent, with_noise, with_sign_swap)\u001B[0m\n\u001B[1;32m    500\u001B[0m upper \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    501\u001B[0m lower \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 502\u001B[0m cs_temp \u001B[38;5;241m=\u001B[39m (upper \u001B[38;5;241m-\u001B[39m lower) \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand((samples_per_bound, \u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mindex_to_select\u001B[49m\u001B[43m)\u001B[49m),\n\u001B[1;32m    503\u001B[0m                                   dtype\u001B[38;5;241m=\u001B[39mdata_type)\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;241m+\u001B[39m lower\n\u001B[1;32m    505\u001B[0m cs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros((samples_per_bound, affine_w\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)), dtype\u001B[38;5;241m=\u001B[39mdata_type)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m    507\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(samples_per_bound):\n",
      "\u001B[0;31mTypeError\u001B[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "import script.DHOV.DataSampling as ds\n",
    "included_sample_count = 10000\n",
    "sample_space = torch.empty((0, affine_w.size(1)), dtype=data_type).to(device)\n",
    "t = time.time()\n",
    "for group in group_indices:\n",
    "    sample_space_a = ds.sample_per_group(sample_space, included_sample_count, affine_w, center, eps, group, rand_samples_percent=0.2, rand_sample_alternation_percent=0.2)\n",
    "\n",
    "print(time.time()-t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:07:18.189645904Z",
     "start_time": "2024-04-21T18:07:17.801260876Z"
    }
   },
   "id": "ec8d44db732229a4",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m sample_space \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mempty((\u001B[38;5;28mlen\u001B[39m(group_indices), \u001B[38;5;241m0\u001B[39m, affine_w\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m)), dtype\u001B[38;5;241m=\u001B[39mdata_type)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      2\u001B[0m t \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m----> 3\u001B[0m sample_space_b \u001B[38;5;241m=\u001B[39m \u001B[43mds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample_per_group_all_groups\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample_space\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mincluded_sample_count\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maffine_w\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcenter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_indices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrand_samples_percent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrand_sample_alternation_percent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(time\u001B[38;5;241m.\u001B[39mtime()\u001B[38;5;241m-\u001B[39mt)\n",
      "File \u001B[0;32m~/Documents/Programming/ICNN_verification/script/DHOV/DataSampling.py:579\u001B[0m, in \u001B[0;36msample_per_group_all_groups\u001B[0;34m(data_samples, amount, affine_w, input_bounds, group_indices, keep_samples, rand_samples_percent, rand_sample_alternation_percent, with_noise, with_sign_swap)\u001B[0m\n\u001B[1;32m    576\u001B[0m num_rand_samples \u001B[38;5;241m=\u001B[39m math\u001B[38;5;241m.\u001B[39mfloor(amount \u001B[38;5;241m*\u001B[39m rand_samples_percent)\n\u001B[1;32m    577\u001B[0m alternations_per_sample \u001B[38;5;241m=\u001B[39m math\u001B[38;5;241m.\u001B[39mfloor(affine_w\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m*\u001B[39m rand_sample_alternation_percent)\n\u001B[0;32m--> 579\u001B[0m cs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mgroup_indices\u001B[49m\u001B[43m)\u001B[49m, samples_per_bound, affine_w\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)), dtype\u001B[38;5;241m=\u001B[39mdata_type)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m    580\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(group_indices):\n\u001B[1;32m    581\u001B[0m     cs[i] \u001B[38;5;241m=\u001B[39m cs[i]\u001B[38;5;241m.\u001B[39mindex_fill(\u001B[38;5;241m1\u001B[39m, torch\u001B[38;5;241m.\u001B[39mLongTensor(group), \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "sample_space = torch.empty((len(group_indices), 0, affine_w.size(1)), dtype=data_type).to(device)\n",
    "t = time.time()\n",
    "sample_space_b = ds.sample_per_group_all_groups(sample_space, included_sample_count, affine_w, center, eps, group_indices, rand_samples_percent=0.2, rand_sample_alternation_percent=0.2)\n",
    "\n",
    "print(time.time()-t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T18:07:18.854746841Z",
     "start_time": "2024-04-21T18:07:18.835195101Z"
    }
   },
   "id": "68431a84870c24ea",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[34], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m t\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n",
      "Cell \u001B[0;32mIn[34], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m t\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/pycharm-professional/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:755\u001B[0m, in \u001B[0;36mPyDBFrame.trace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    753\u001B[0m \u001B[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001B[39;00m\n\u001B[1;32m    754\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info\u001B[38;5;241m.\u001B[39mpydev_state \u001B[38;5;241m==\u001B[39m STATE_SUSPEND:\n\u001B[0;32m--> 755\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    756\u001B[0m     \u001B[38;5;66;03m# No need to reset frame.f_trace to keep the same trace function.\u001B[39;00m\n\u001B[1;32m    757\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrace_dispatch\n",
      "File \u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/pycharm-professional/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:412\u001B[0m, in \u001B[0;36mPyDBFrame.do_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    411\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_wait_suspend\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 412\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_args\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/pycharm-professional/plugins/python/helpers/pydev/pydevd.py:1184\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1181\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1183\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1184\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/JetBrains/Toolbox/apps/pycharm-professional/plugins/python/helpers/pydev/pydevd.py:1199\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1196\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1198\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1199\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1201\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1203\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "t=1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T14:56:33.523301237Z",
     "start_time": "2024-04-19T14:55:47.600804461Z"
    }
   },
   "id": "197bd3c4f410cde8",
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
